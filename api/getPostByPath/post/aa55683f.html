{"type":"getPostByPath","data":{"title":"JUC","date":"2023-09-13T15:46:00.000Z","description":"面试精选","categories":[{"name":"FaceToFace","_id":"clmhxgjfz000tp70pg45khpkv"}],"tags":[{"name":"JUC","_id":"clmhxgjfz000up70pg6go25ny"}],"content":"<meta name=\"referrer\" content=\"no-referrer\">\n<h1>JUC</h1>\n<h3 id=\"1、进程\">1、进程</h3>\n<p>1、<strong>管程：</strong> 是一种同步机制，可以保证同一时间只有一个线程可以访问代码或者数据，也就是我们所说的锁；管程内定义的操作在一个时刻只会被一个进程调用</p>\n<p>2、**同步异步：**如果<code>需要等待结果返回</code>才能继续运行的话就是同步，如果<code>不需要等待</code>就是异步</p>\n<p>3、<strong>创建线程的三种方式：</strong></p>\n<p>​\t3.1、继承 <code>Thread</code>类</p>\n<p>​\t3.2、实现 <code>Runnable  </code>接口，无返回值</p>\n<p>​\t3.3、实现<code>Callable</code>接口，有返回值</p>\n<p>4、 <strong>Thread 线程的方法</strong></p>\n<p>​\t1、start()  异步调用重写的run 方法，直接调用会启动新的线程，用于启动线程的执行。</p>\n<p>​\t2、run()    同步调用重写的run 方法，直接调用不会启动新的线程,用于执行线程的任务</p>\n<p>​\t3、sleep() 线程从运行进入阻塞状态，可以使用 interrupt()  打断，睡眠结束的线程不会立刻执行，该线程结束睡眠才可能被分配到cpu中</p>\n<p>​\t4、yield()  用于提示调度器将当前线程让出 CPU，线程从运行进入就绪状态，可以只用cpu调用其他线程，该线程也可能被分配到cpu</p>\n<p>​\t5、join()   用于等待指定的线程执行完毕，会阻塞；主要作用是<code>实现线程的同步，即等待其他线程完成后再进行后续操作</code></p>\n<p>​\t6、<code>interrupt () </code> 可以打断   <code>sleep，wait，join</code> 的线程(这三个都是都是<code>阻塞状态</code>的线程),可以中断该线程。<code>interrupt()</code> 方法只是发送一个中断信号给线程，而不会立即停止线程的执行。</p>\n<p>​\t7、<code>isInterrupted()</code> 可以获取当前线程的中断状态。如果线程被中断，则返回 <code>true</code>；否则返回 <code>false</code>。只是返回线程的中断状态，并不会清除线程的中断状态。</p>\n<p>​\t8、<code>interrupted()</code>： 用于检查当前线程是否被中断，并清除线程的中断状态,返回当前线程的状态，将当前线程的中断状态这是为 <code>false</code></p>\n<blockquote>\n<p>Object的方法</p>\n<p>​\t11、<code>notify()</code>:唤醒正在等待对象监视器的单个线程,随机唤醒</p>\n<p>​\t12、<code>notifyAll():</code>唤醒正在等待对象监视器的所有线程,全部唤醒</p>\n<p>​\t13、<code>wait():</code>导致当前线程等待，直到另一个线程调用该对象的 notify() 方法或 notifyAll()方法</p>\n<p>​\t14、<code>wait(long timeout)</code>:有时限的等待, 到n毫秒后结束等待，或是被唤醒</p>\n<p>**sleep  VS   wait **</p>\n<p><code>sleep(long n)</code> <strong>和</strong> <code>wait(long n) </code>的区别</p>\n<ul>\n<li>\n<p><code>sleep</code> 是 Thread 方法，而 <code>wait</code> 是 Object 的方法</p>\n</li>\n<li>\n<p>sleep 不需要强制和 <code>synchronized</code> 配合使用，但 wait 需要和 <code>synchronized</code> 一起用</p>\n</li>\n<li>\n<p>sleep 在睡眠的同时，不会释放对象锁的，但 <code>wait 在等待的时候会释放对象锁 </code></p>\n</li>\n<li>\n<p>不管进入哪一个方法，线程的状态都是<code> TIMED_WAITING</code></p>\n</li>\n<li>\n<p>如果需要是线程进行等待，应该使用<code>wait </code>而不是<code>sleep</code></p>\n</li>\n<li>\n<p>它们都可以被 interrupted 方法中断</p>\n</li>\n</ul>\n</blockquote>\n<p>​</p>\n<p>5、<strong>守护线程</strong></p>\n<p>​\t\t在<strong>后台默默地完成一些系统性的服务</strong>；默认情况下，java进程需要等待所有的线程结束后才会停止；在其他线程<code>全部结束</code>的时候即使<code>守护线程</code> 还未结束,代码未执行完，java进程也会停止。但是一旦当前 运行的线程 都是 守护线程,没有用户进程时，Java 虚拟机将退出，因为普通线程执行完后，JVM 是守护线程，不会继续运行下去</p>\n<p>6、<strong>线程状态</strong></p>\n<p>​\t五态：1、初始态（只是创建了一个线程）   +  2、就绪态（等待CPU分配时间片） + 3、运行态（CPU分配了时间片，正在运行）  +  4、阻塞态（调用阻塞API,比如BIO方式的操作，只要不调用CPU就不会分配时间片） + 5、终止态（线程执行完毕，生命周期结束）</p>\n<p>​\t七态：1、<strong>New（新建）</strong>：（当创建了一个 <code>Thread</code> 对象时，线程处于新建状态，没有调用线程的 <code>start()</code> 方法。）+  2、<strong>Runnable（可运行）</strong>：(当调用线程的 <code>start()</code> 方法后等待分配时间片)  + 3、<strong>Running（运行）</strong>：（当线程被调度器选中并执行时，线程处于运行状态。） + 4、<strong>Blocked（阻塞）</strong>：（线程在某些情况下会进入阻塞状态，此时线程暂时停止执行，并等待满足某些条件后才能继续执行。）+ 5、<strong>Waiting（等待）</strong>：（线程在某些情况下会进入等待状态，例如调用 <code>wait()</code>、<code>join()</code>、<code>sleep()</code> 等方法。在等待状态下，线程会一直等待，直到满足特定的条件才能继续执行。）+ 6、<strong>Timed Waiting（计时等待）</strong>：（线程在某些情况下会进入计时等待状态，等待一段指定的时间，或者直到满足某些条件才能继续执行。）+  7、<strong>Terminated（终止）</strong>：（线程执行完毕或出现异常时，线程进入终止状态）</p>\n<p>7、中断:</p>\n<p>​\t7.1、一种用于停止线程的机制</p>\n<p>​\t7.2、如何停止线程</p>\n<p>​\t\t1、通过一个<code>volatile</code>变量实现；在线程执行的过程中，通过修改一个<code>volatile</code>变量的状态来控制线程的运行状态。</p>\n<p>​\t\t2、使用<code>AtomicBoolean</code>作为标识变量，通过修改其值来控制线程的运行状态</p>\n<p>​\t\t3、通过Thread类自带的<code>中断API</code>方法(见上)实现</p>\n<h3 id=\"2、LockSupport\">2、LockSupport</h3>\n<p>1、 创建锁和其他同步类的基本线程<code>阻塞原语</code></p>\n<p>2、主要的方法：</p>\n<p>​\t2.1、<code>park()</code>: 打断 park 线程，不会清空打断状态（true）,如果<code>打断标记</code>已经是 true, 则 park 会失效,线程不会阻塞； <strong>阻塞线程</strong></p>\n<p>​\t2.2、<code>unpark()</code>: 只要有 这个方法，不管是先<code>park() </code> 还是 后<code>park() </code>，线程都不会进行阻塞 ；<strong>解除阻塞线程</strong></p>\n<p>3、3种让线程等待和唤醒的方法</p>\n<p>​\t方式1：使用<code>Object</code>中的<code>wait()</code>方法让线程等待，使用<code>Object</code>中的<code>notify()</code>方法唤醒线程   ——结合  <code>synchronized</code>使用， <code>wait</code> <code>notify</code> 的顺序不能颠倒</p>\n<p>​\t方式2：使用<code>JUC</code>包中<code>Condition</code>的<code>await()</code>方法让线程等待，使用<code>signal()</code>方法唤醒线程       ——结合  <code>reentrantlock</code>使用, <code>await</code> <code>signal</code> 的顺序不能颠倒</p>\n<p>​\t方式3：<code>LockSupport</code>类中的<code>park</code>等待和<code>unpark</code>唤醒</p>\n<p>4、park 和  unpark 的 原理</p>\n<p>​\t1、调用<code>LockSupport.park()</code>时：<strong>permit默认是零</strong>，<strong>所以一开始调用park()方法，当前线程就会阻塞，直到别的线程将当前线程的permit设置为1时，park方法会被唤醒，然后会将permit再次设置为零并返回。</strong></p>\n<p>​\t2、调用<code>LockSupport.unpark()</code>时: 调用<code>unpark(thread)</code>方法后，就会将thread线程的许可<code>permit</code>设置成<code>1</code>(注意多次调用<code>unpark</code>方法，不会累加，<code>permit</code>值还是<code>1</code>)会自动唤醒<code>thread</code>线程，即之前阻塞中的<code>LockSupport.park()</code>方法会立即返回。</p>\n<p>5、本质上这两个方法是通过调用Unsafe类实现的；通过使用<code>Unsafe</code>类的本地方法，<code>LockSupport</code>能够实现线程的阻塞和唤醒操作，而无需依赖于特定的对象锁。</p>\n<blockquote>\n<p>注意：<code>LockSupport</code>类使用了一种名为<code>Permit(许可)</code>的概念来做到阻塞和唤醒线程的功能，每个线程都有一个<code>许可(permit),permit</code>只有两个值1和零，默认是零。所以可以把<code>Permit 许可</code>看成是一种(0,1)<code>信号量(Semaphore)</code>,但与<code>Semaphore</code>不同的是，许可的累加<code>上限</code>是1。</p>\n</blockquote>\n<h3 id=\"3、Lock接口\">3、Lock接口</h3>\n<p>​\t1、方法 <code>Condition  newCondition()</code></p>\n<p>​\t\t1.1、Condition 类也可以实现等待/通知模式。效果等价于   <code>synchronized +  wait()/notify()</code></p>\n<p>​\t\t1.2、用 <code>notify()</code>通知时，<code>JVM</code> 会随机唤醒某个等待的线程， 使用 <code>Condition</code> 类可以进行<code>选择性通知</code>， Condition 比较常用的<code>两个方法</code>：</p>\n<p>​\t\t\t\t<code>await()</code>会使当前线程等待,同时会释放锁,当其他线程调用<code> signal()</code>时,线程会重新获得锁并继续执行。</p>\n<p>​\t\t\t\t<code>signal()</code>用于唤醒一个等待的线程。</p>\n<p>==注意：在调用 Condition 的 <code>await()/signal()</code>方法前，也需要线程持有相关的 <code>Lock</code> 锁，调用<code> await()</code>后线程会释放这个锁，在 <code>singal()</code>调用后会从当前<code>Condition</code> 对象的等待队列中，唤醒 一个线程，唤醒的线程尝试获得锁， 一旦获得锁成功就继续执行。==</p>\n<blockquote>\n<p>ReentrantLock 是<code>唯一</code>实现了 <code>Lock 接口</code>的类</p>\n</blockquote>\n<p><strong>Lock 和Synchronized 的对比</strong></p>\n<p>1、Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言实现</p>\n<p>2、synchronized 在发生异常会<code>自动释放</code>线程占有的锁，不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁就可能造成<code>死锁现象</code></p>\n<p>3、 <code>Lock</code> 接口可通过响应中断的方式获取锁；而 synchronized 却不行，<code>会等待的线程会一直等待下去</code>，不能够响应中断</p>\n<p>4、通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到</p>\n<p>5、Lock 可以提高多个线程进行读操作的效率。尤其在有大量线程同时竞争，此时 Lock 的性能要远远优于synchronized。</p>\n<h3 id=\"4、ReadWriteLock接口\">4、ReadWriteLock接口</h3>\n<p>将文件的<code>读写</code>操作分开，线程分别获取读锁和写锁，从而使得多个线程之间同时实现<code>读</code>的操作,但是<code>sychronized</code>只能获取一把锁，并且只有等其他线程释放掉之后才能获取想要的锁</p>\n<h4 id=\"读写锁\">读写锁</h4>\n<blockquote>\n<p>ReentrantReadWriteLock</p>\n</blockquote>\n<p>1、介绍：它表示两个锁，一个是读操作相关的锁，称为共享锁；一个是写相关的锁，称为排他锁；</p>\n<p>2、线程<code>进入读锁</code>前提条件：没有其他线程的写锁  或者  没有写请求, 或者即使==有写请求，但调用线程和持有锁的线程是同一个(可重入锁)。==</p>\n<p>3、线程<code>进入写锁</code>的前提条件：没有其他线程的读锁   或者   没有其他线程的写锁</p>\n<p>4、特点：</p>\n<p>​\t1、公平选择性：支持非公平（默认）和公平的锁获取方式，吞吐量还是非公平优于公平。</p>\n<p>​\t2、可重入：读锁和写锁都支持线程重进入。</p>\n<p>​\t3、锁降级：遵循<code>获取写锁</code>、<code>获取读锁再释放写锁</code>的次序，写锁能够降级成为读锁</p>\n<p>5、获取关系</p>\n<p>​\t在线程<code>持有读锁</code>的情况下，该线程<code>不能取得写锁</code>；在线程<code>持有写锁</code>的情况下，该线程可以继续获取读锁；</p>\n<p>​\t原因: 当线程获取读锁的时候，可能有其他线程同时也在持有读锁，因此不能把获取读锁的线程“升级”为写锁；而对于获得写锁的线程，它一定独占了读写锁；因此可以继续让它获取读锁，当它同时获取了写锁和读锁后，还可以<code>先释放写锁继续持有读锁</code>，这样一个写锁就<code>降级</code>为了<code>读锁</code></p>\n<p><strong>特性</strong></p>\n<p>​\t1、公平选择性：支持非公平（默认）和公平的锁获取方式，吞吐量也是非公平优于公平。</p>\n<p>​\t2、重入：读锁和写锁都支持线程重入。</p>\n<p>​\t3、锁降级：遵循获取写锁、获取读锁再释放写锁的次序，写锁能够降级成为读锁</p>\n<p>基于 AQS（AbstractQueuedSynchronizer），通过维护状态变量和等待队列来管理读锁和写锁的竞争关系。</p>\n<p>读写锁的原理是基于共享锁和独占锁的组合实现的。它维护了两个锁：读锁和写锁。</p>\n<ul>\n<li>读锁：多个线程可以同时持有读锁，实现并发读取共享资源的能力。当没有线程持有写锁时，任意数量的线程可以同时获取读锁。</li>\n<li>写锁：写锁是独占的，只允许一个线程持有写锁。当有线程持有写锁时，其他线程无法获取读锁或写锁，保证了写操作的独占性。</li>\n</ul>\n<p><strong>读写锁的演变过程</strong></p>\n<p><code>无锁无序-&gt;加锁-&gt;读写锁</code></p>\n<p>1、无锁时期一旦多线程,肯定会<code>出现线程安全</code>问题</p>\n<p>2、加锁时期<code>读读操作</code>也只能单线程操作-----<code>解决了线程安全问题但是性能太低</code></p>\n<p>3、读写锁时期:高并发的情况下大部分的请求都是查询请求,即<code>读多写少</code>的情况,如果读读也互斥了那么效率极低,而且读操作不会影响数据一致性可以不互斥—读写锁诞生.</p>\n<p>​\t缺点:</p>\n<p>​\t因为<code>读写锁读写互斥</code>,假设100个线程99个都是读线程只有一个写线程,写线程很难抢到机会,就会出现锁<code>饥饿问题</code></p>\n<p>​\t<code>锁降级</code>:为了让当前线程感知到数据的变化，目的是保证数据可见性,写锁会降级为读锁(写后立刻读)</p>\n<p><strong>读写锁降级</strong></p>\n<p>规则：<code>锁降级</code>：遵循获取<code>写锁→再获取读锁→再释放写锁</code>的次序，<code>写锁</code>能够<code>降级</code>成为<code>读锁</code>；如果一个线程占有了写锁，在不释放写锁的情况下，它还能占有读锁，即<code>写锁降级为读锁</code></p>\n<p>作用：为了让当前线程感知到数据的变化，目的是<code>保证数据可见性</code></p>\n<p><strong>读写锁的不可升级</strong></p>\n<p>线程获取读锁是不能直接升级为写锁的，所以在<code>ReentrantReadWriteLock</code>中，当读锁被使用时，如果有线程尝试获取写锁，该写线程会被阻塞。<br>\n所以，需要<code>释放所有读锁</code>，才可<code>获取写锁</code></p>\n<p><strong>总结</strong></p>\n<p>1、写锁和读锁是互斥的（这里的互斥是指线程间的互斥，当前线程可以获取到写锁又获取到读锁，但是获取到了读锁不能继续获取写锁），这是因为读写锁要保持写操作的可见性。因为，<strong>如果允许读锁在被获取的情况下对写锁的获取，那么正在运行的其他读线程无法感知到当前写线程的操作。</strong></p>\n<p>2、如果有线程正在读，写线程需要等待读线程释放锁后<code>才能</code>获取写锁;即<code>ReadWriteLock</code> <code>读的过程中不允许写</code>，只有等待线程都<code>释放了读锁</code>，当前线程才能<code>获取写锁</code>，也就是<code>写入必须等待</code>，这是一种<code>悲观的读锁</code></p>\n<h3 id=\"5、处理异步任务\">5、处理异步任务</h3>\n<p>1、<code>Future</code> 接口、<code>FutureTask</code> 类和 <code>CompletableFuture</code> 类都是 Java 中用于处理异步任务的类和接口。</p>\n<p>​\t<strong>1、==Future== 接口</strong></p>\n<p>​\t\t功能： 可以判断任务是否完成；是否能够中断任务；是否能够获取任务执行结果。可以继续执行自己的任务，并且能够异步的获取耗时的子线程的任务处理的结果或者任务的状态；就是说：如果<code>主线程</code>需要执行一个很耗时的计算任务，我们就可以通过<code>Future</code>把这个<code>任务放进异步线程</code>中执行，<code>主线程继续处理其他任务</code>或者<code>先行结束</code>，再通过<code>Future</code>获取计算结果。</p>\n<p>​\t缺点：</p>\n<p>​\t1、不支持手动完成：提交了一个任务，但是执行太慢了，我通过其他路径已经获取到了任务结果，现在没法把这个任务<code>结果通知</code>到正在执行的线程，所以必须主动取消或者一直等待它执行完成</p>\n<p>​\t2、不支持进一步的非阻塞调用；通过 Future 的 <code>get</code> 方法会一直阻塞到任务完成，现在想在获取任务之后执行额外的任务，但是由于 Future 不支持回调函数，所以无法实现这个功能</p>\n<p>​\t3、不支持链式调用：对于 Future 的执行结果，我们想继续传到下一个 Future 处理使用，从而形成一个<code>链式</code>的 pipline 调用，这在 Future 中是没法实现的。</p>\n<p>​\t4、不支持多个 Future 合并：比如我们有 10 个 Future 并行执行，我们想在所有的 Future 运行完毕之后，执行某些函数，是没法通过 Future 实现的。</p>\n<p>​\t5、不支持异常处理: Future 的 API 没有任何的异常处理的 api，所以在异步运行时，如果出了问题是不好定位的。</p>\n<p>​\t解决：引出了 <code>CompletableFuture</code></p>\n<p>​\t<strong>2、==FutureTask==类</strong></p>\n<p><code>FutureTask</code> 类是 <code>Future</code> 接口的一个实现类，它同时实现了 <code>Runnable</code> 接口。通过 <code>FutureTask</code>，我们可以异步地执行任务，并通过 <code>get()</code> 方法获取任务的结果。主要用于在后台执行计算任务；</p>\n<p>有三个特点：<code>多线程(实现 Runnable接口(多线程))</code>,<code>异步任务(实现Future接口(异步任务))</code>,<code>返回值(构造时参数注入Callable接口(有返回值))</code></p>\n<p>核心原理</p>\n<p>​\t\t1、在主线程中需要执行比较耗时的操作时，但又不想阻塞主线程时，可以把这些作业交给 <code>Future</code> 对象在后台完成</p>\n<p>​\t\t2、主线程可以在完成自己的任务后，再通过 <code>Future</code> 对象 获取 后台运行的结果</p>\n<p>​\t\t3、只有在运行完之后才会调用 <code>get()</code> 方法来获取任务的结果，要是没有计算完就会阻塞</p>\n<p>​\t\t4、也可以通过调用 <code>cancel()</code> 方法来取消任务的执行。一旦任务被取消，要是再去调用的话就会抛出异常</p>\n<p>​\t缺点：</p>\n<p>​\t1、<code>get()阻塞</code>—一旦调用get()方法求结果，一旦调用，非要等到结果才会离开，不管你是否计算完成，都可能会<code>导致程序堵塞</code>。</p>\n<p>​\t2、<code>isDone()轮询</code>—轮询的方式会<code>耗费cpu资源</code>，如果想要异步获取结果，通常会以轮询的方式去获取结果，<code>尽量不发生阻塞</code>。</p>\n<p>解决：引出了 <code>CompletableFuture</code></p>\n<p>​\t<strong>3、==CompletableFuture== 类</strong></p>\n<p>​\t\t1、主要用于异步编程，即非阻塞的，将此任务和主线程任务进行分离，通过<code>回调函数的方式</code>得到异步任务的执行状态；它可以通过各种方法链式地组合多个异步任务，并在任务完成时执行回调函数。</p>\n<p>​\t\t2、<code>CompletableFuture</code> 类  实现了 <code>Future</code> 接口和 <code>CompletionStage</code> 接口。 <code>Future</code>接口就可以兼容现在有线程池框架，而 <code>CompletionStage</code> 接口才是异步编程的接口抽象，里面定义多种异步方法。</p>\n<p>2、应用场景：</p>\n<p>​\t\t需要简单的异步计算和结果获取，可以使用 <code>Future</code> 接口和 <code>FutureTask</code> 类。如果需要更复杂的异步编程任务组合和处理，可以使用 <code>CompletableFuture</code> 类。</p>\n<p>3、特点</p>\n<p>​\t1、异步任务<strong>结束</strong>时，会<code>自动回调</code>某个对象的方法</p>\n<p>​\t2、主线程设置好回调后，不用关心异步任务的执行，<code>异步任务之间可以顺序执行</code></p>\n<p>​\t3、异步任务<strong>出错</strong>时，会<code>自动回调</code>某个对象的方法</p>\n<h3 id=\"6、JUC-常用的辅助类\">6、<code>JUC 常用的辅助类</code></h3>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306062001482.png\" alt=\"image-20230606200147311\">\n<h4 id=\"AQS\">AQS</h4>\n<p>1、介绍：抽象队列同步器；是<code>阻塞式锁和相关的同步器工具的框架</code>  ;它提供了底层的<code>同步机制和状态管理</code>，可以用于实现各种类型的同步器</p>\n<p>2、原理：</p>\n<p>​\t\t简单说：通过<code>同步状态的管理</code>和<code>等待队列</code>的维护来实现线程的协调与同步。它维护一个同步状态变量和一个等待队列，通过 acquire 和 release 方法实现线程的获取和释放同步资源。</p>\n<p>​\t\t详细说：</p>\n<ol>\n<li>同步状态：AQS 内部维护了一个<code>同步状态的变量，通过这个变量</code>来表示同步资源的状态。不同类型的同步器可以根据自身需求定义不同的状态含义。</li>\n<li>等待队列：AQS 内部维护了一个等待队列，用于<code>管理等待获取同步资源的线程</code>。当一个线程无法获取同步资源时，它会被加入到等待队列中，并进入等待状态。</li>\n<li>Node 节点：等待队列中的每个线程都会被封装成一个 Node 节点，用于表示等待线程。Node 节点包含了线程本身以及一些标记位，用于表示节点状态和等待条件。</li>\n<li>acquire 方法：当一个线程<code>需要获取同步资源</code>时，它会调用 AQS 的 acquire 相关方法。这些方法<code>首先尝试直接获取同步资源，如果成功则直接返回；否则，线程会被加入到等待队列中，并进入等待状态。</code></li>\n<li>release 方法：当一个线程<code>释放同步资源</code>时，它会调用 AQS 的 release 相关方法。这些方法<code>首先释放同步资源，并唤醒等待队列中的一个或多个线程，使它们能够竞争获取同步资源。</code></li>\n</ol>\n<p>3、特点：灵活性、可扩展性和高效性</p>\n<p>4、底层数据结构:  CLH（Craig, Landin, and Hagersten）队列的变体作为<code>等待队列</code>的底层数据结构。CLH 队列是一种基于链表的队列，通过自旋和 CAS 操作来实现线程的排队和唤醒。</p>\n<p>5、使用场景：适用于需要进行线程协调和同步的场景，可以用于构建各种类型的同步器，如独占锁（ReentrantLock）、共享锁（Semaphore）、计时器（CountDownLatch）等</p>\n<h4 id=\"ReentrantLock-原理\">ReentrantLock 原理</h4>\n<p>ReentrantLock 是基于 AQS（AbstractQueuedSynchronizer）的同步器实现的可重入锁。</p>\n<p><strong>1、非公平锁实现原理</strong></p>\n<p>在非公平锁模式下，默认情况下，ReentrantLock 是非公平的。这意味着获取锁的线程不会考虑其他等待线程的顺序，而是直接尝试获取锁。如果锁是可用的，线程就会成功获取锁；否则，它会进入 AQS 队列尝试排队等待锁的释放。</p>\n<p><strong>2、可重入的原理</strong></p>\n<p>ReentrantLock 是可重入的，也就是说，同一个线程可以多次获取同一个锁而不会出现死锁。ReentrantLock 内部维护了一个计数器，记录了线程获取锁的次数。只有当计数器归零时，锁才会被完全释放。</p>\n<p><strong>3、可打断原理</strong></p>\n<p>在可打断模式下，线程在等待获取锁时可以被打断。如果一个线程在等待锁的过程中被打断，它会收到一个中断信号，但线程仍会保持在 AQS 队列中，直到获取锁后才会知道自己被打断了。</p>\n<p><strong>4、公平锁实现原理</strong></p>\n<p>公平锁模式下，ReentrantLock 会按照线程的等待顺序来获取锁。当一个线程尝试获取锁时，如果锁是可用的，它就可以获取锁；否则，它会进入 AQS 队列排队等待获取锁，按照先来先服务的原则。</p>\n<p><strong>5、条件变量实现原理</strong></p>\n<p>ReentrantLock 还提供了条件变量（Condition）的功能，用于线程之间的等待和通知机制。条件变量是通过 ReentrantLock.newCondition() 方法创建的。条件变量的实现基于 AQS 的等待队列机制，可以让线程在特定条件下等待（await）或被唤醒（signal）。</p>\n<h4 id=\"ReentrantReadWriteLock-原理\">ReentrantReadWriteLock 原理</h4>\n<p><strong>ReentrantReadWriteLock 的原理如下：</strong></p>\n<ol>\n<li>读锁的获取：当一个线程请求获取读锁时，如果当前没有线程持有写锁，那么它可以直接获取读锁，并增加读锁的计数器。如果有线程持有写锁，那么该线程会进入等待状态，直到写锁被释放。</li>\n<li>写锁的获取：当一个线程请求获取写锁时，如果当前没有线程持有读锁或写锁，那么它可以直接获取写锁，并将写锁的计数器设置为1。如果已经有线程持有读锁或写锁，那么该线程会进入等待状态，直到读锁和写锁都被释放。</li>\n<li>读锁的释放：当一个线程释放读锁时，会将读锁的计数器减1。如果读锁的计数器归零，表示没有线程持有读锁，那么其他等待获取写锁的线程可以继续竞争获取写锁。</li>\n<li>写锁的释放：当一个线程释放写锁时，会将写锁的计数器设置为0，表示写锁被完全释放。此时，等待获取读锁或写锁的线程可以继续竞争获取锁。</li>\n</ol>\n<blockquote>\n<p>可以使用 戳<code>StampedLock</code>；进一步优化读性能，在读锁、写锁时配合【戳】使用，以一种乐观读的方式实现的。</p>\n</blockquote>\n<h4 id=\"StampedLock：邮戳锁\"><code>StampedLock</code>：邮戳锁</h4>\n<p>1、也叫票据锁；是JDK1.8中新增的一个读写锁，也是对JDK1.5中的<strong>读写锁<code>ReentrantReadWriteLock</code>的优化</strong></p>\n<p>2、原理 ：</p>\n<p><code>stamp</code>（戳记，long类型） ：代表了锁的状态。<strong>当stamp返回零时，表示线程获取锁失败</strong>。并且，<strong>当释放锁或者转换锁的时候，都要传入最初获取的stamp值</strong></p>\n<ol>\n<li>StampedLock 使用一个 long 类型的变量作为锁的标记（stamp），它的高32位表示写锁的状态，低32位表示读锁的状态。</li>\n<li>读锁（乐观读）：读取操作可以直接进行，不需要获取锁。读锁的获取使用 <code>tryOptimisticRead()</code> 方法，该方法返回一个非零的 stamp 值，表示读锁的状态。读取后，需要使用 <code>validate(stamp)</code> 方法验证 stamp 是否仍然有效，如果有效则表示读取成功，否则需要重新获取锁。</li>\n<li>写锁（悲观写）：写操作需要获取悲观写锁，通过 <code>writeLock()</code> 方法获取写锁，该方法返回一个非零的 stamp 值，表示写锁的状态。写锁的获取会阻塞其他线程的读锁和写锁，保证数据的一致性。写锁释放使用 <code>unlockWrite(stamp)</code> 方法。</li>\n<li>读锁升级为写锁：StampedLock 还提供了将读锁升级为写锁的功能，通过 <code>tryConvertToWriteLock(stamp)</code> 方法可以将读锁转换为写锁。如果转换成功，会返回一个非零的新的 stamp 值，表示写锁的状态，否则需要显式地释放读锁。</li>\n<li>乐观读与悲观读的冲突检测：当一个线程获取了写锁时，其他线程无法获取读锁，这是悲观读。当一个线程获取了乐观读锁时，其他线程仍然可以获取读锁，但需要在操作前通过 <code>validate(stamp)</code> 方法验证 stamp 的有效性，以检测到写锁的存在。</li>\n</ol>\n<p><strong>3、特点</strong></p>\n<p>​\t1、所有获取锁的方法，都返回一个<code>邮戳（Stamp）</code>，Stamp为<code>零</code>表示获取<code>失败</code>，其余都表示成功；</p>\n<p>​\t2、所有释放锁的方法，都需要一个<code>邮戳（Stamp）</code>，这个Stamp必须是和成功获取锁时得到的Stamp一致；</p>\n<p>​\t3、StampedLock是不可重入的，危险  (如果一个线程已经持有了写锁，再去获取写锁的话就会造成死锁)</p>\n<p>​\t4、StampedLock有三种访问模式</p>\n<p>​\t  ①Reading（读模式）：功能和<code>ReentrantReadWriteLock</code>的<code>读锁</code>类似</p>\n<p>​\t  ②Writing（写模式）：功能和<code>ReentrantReadWriteLock</code>的<code>写锁</code>类似</p>\n<p>​\t  ③Optimistic reading（乐观读模式）：<code>无锁机制</code>，类似于数据库中的<code>乐观锁</code>，支持<code>读写并发</code>，很乐观认为读取时没人修改，假如被修改再实现升级为悲观读模式</p>\n<p><strong>4、缺点</strong></p>\n<p>1、<code>StampedLock</code> 不支持重入，没有Re开头</p>\n<p>2、<code>StampedLock</code> 的悲观读锁和写锁都不支持条件变量（<code>Condition</code>）</p>\n<p>3、使用 <code>StampedLock</code>一定不要调用中断操作，即不要调用<code>interrupt() </code>方法</p>\n<p><strong>5、锁饥饿问题</strong></p>\n<p><code>ReentrantReadWriteLock</code>实现了读写分离，但是一旦读操作比较多的时候，想要获取写锁就变得比较困难了；</p>\n<p>假如当前1000个线程，999个读，1个写，有可能999个读取线程长时间抢到了锁，那1个写线程就悲剧了 因为当前有可能会一直存在读锁，而无法获得写锁，根本没机会写</p>\n<p><strong>6、如何缓解锁饥饿问题？</strong></p>\n<p>1、使用<code>“公平”策略</code>可以一定程度上缓解这个问题;但是“公平”策略是<code>以牺牲系统吞吐量为代价</code>的</p>\n<p>2、<code>邮戳锁: </code>     乐观读来解决问题</p>\n<p><strong>7、 <code>StampedLock</code> 和<code>ReentrantReadWriteLock</code>的区别</strong></p>\n<p>​\t1、<code>ReentrantReadWriteLock</code>：允许<code>多个线程同时读</code>，但是<code>只允许一个线程写</code>，在线程获取到写锁的时候，其他写操作和读操作都会处于阻塞状态，读锁和写锁也是互斥的，所以在读的时候是不允许写的，读写锁比传统的<code>synchronized</code>速度要快很多，原因就是在于<code>ReentrantReadWriteLock</code>支持<code>读并发</code></p>\n<p>​\t2、<code>StampedLock</code>：<code>ReentrantReadWriteLock</code>的读锁被占用的时候，其他线程尝试获取写锁的时候会被阻塞。但是，<code>StampedLock</code>采取乐观获取锁后，其他线程尝试获取写锁时不会被阻塞，这其实是对读锁的优化，所以，在获取乐观读锁后，还需要对结果进行校验。</p>\n<h4 id=\"CountDownLatch-倒计时锁\">CountDownLatch: 倒计时锁</h4>\n<p>1、主要思想就是：通过设置一个计数器，然后通过 <code>countDown</code> 方法来进行减 1 的操作，使用 <code>await</code> 方法等待,只要计数器<code>不大于 0</code>，然后继续执行 <code>await</code> 方法之后的语句。</p>\n<p>2、具体流程：</p>\n<p>​\t\t1、<code>CountDownLatch</code> 主要有两个方法，当一个或多个线程调用 <code>await</code> 方法时，这些线程会阻塞</p>\n<p>​\t\t2、其它线程调用 <code>countDown</code> 方法会将计数器<code>减 1</code>(调用 <code>countDown</code> 方法的线程不会阻塞)</p>\n<p>​\t\t3、当计数器的值变为 0 时， <code>await</code> 方法阻塞的线程会被唤醒，继续执行</p>\n<p>3、CountDownLatch 的原理：基于 AQS（AbstractQueuedSynchronizer），通过维护状态变量和等待队列来管理等待线程的阻塞和释放。</p>\n<p>​\t\t1、初始化：CountDownLatch 在创建时需要指定初始计数器的值，表示需要等待的线程数量。</p>\n<p>​\t\t2、等待：等待的线程调用 CountDownLatch 的 await() 方法，进入等待状态。如果计数器的值大于0，线程被阻塞等待；如果计数器的值为0，线程可以继续执行。</p>\n<p>​\t\t3、完成任务：每个线程完成自己的任务后，调用 CountDownLatch 的 countDown() 方法，将计数器减1。</p>\n<p>​\t\t4、释放等待线程：当计数器的值归零时，所有等待的线程将被释放，可以继续执行。</p>\n<p>4、CountDownLatch 的特点：</p>\n<p>​\t\t1、用于等待一组线程完成某个任务。</p>\n<p>​\t\t2、可以实现线程之间的协调和同步。</p>\n<p>​\t\t3、一旦计数器归零，就无法重置，需要重新创建新的 CountDownLatch 对象</p>\n<h4 id=\"CyclicBarrier-循环栅栏\">CyclicBarrier: 循环栅栏</h4>\n<p>1、循环阻塞思想：每次执行 CyclicBarrier 一次障碍数会<code>+1</code>，如果达到了目标障碍数，才会执行 await()之后的语句。可以将 CyclicBarrier 理解为加 1 操作</p>\n<p>2、CyclicBarrier 的原理：基于 ReentrantLock 和 Condition，通过维护等待线程的计数器和等待队列来实现。</p>\n<ol>\n<li>初始化：CyclicBarrier 在创建时需要指定等待的线程数量和可选的屏障动作（Runnable）。等待的线程数量表示需要等待的线程数量。</li>\n<li>等待：每个线程执行自己的任务，然后调用 CyclicBarrier 的 await() 方法。该方法会使线程进入等待状态，并等待其他线程到达栅栏点。</li>\n<li>栅栏点：当所有等待的线程都调用了 await() 方法后，它们将会在栅栏点上阻塞等待。</li>\n<li>屏障动作（可选）：当最后一个到达栅栏点的线程调用了 await() 方法后，如果设置了屏障动作，该动作将被执行。屏障动作可以用于在所有线程到达栅栏点后执行一些额外的操作。</li>\n<li>继续执行：当栅栏点上的所有线程都被释放后，它们可以继续执行后续的任务。</li>\n</ol>\n<p>3、CyclicBarrier 的特点：</p>\n<ul>\n<li>用于等待一组线程到达栅栏点，然后同时继续执行。</li>\n<li>可以用于将多个线程分阶段地并发执行。</li>\n<li>可以选择是否执行屏障动作。</li>\n</ul>\n<h4 id=\"Semaphore-信号量\">Semaphore: 信号量</h4>\n<p>1、思想：每个信号量初始化为一个最多只能分发一个许可证。使用 <code>acquire</code> 方法获得许可证，<code>release</code> 方法释放许可</p>\n<p>2、原理： 基于 AQS（AbstractQueuedSynchronizer），通过维护状态变量和等待队列来管理许可的获取和释放。</p>\n<p>​\t1、初始化：Semaphore 在创建时需要指定初始许可数量。许可数量表示同时允许的线程数量。</p>\n<p>​\t2、获取许可：当一个线程需要访问共享资源时，它必须先调用 Semaphore 的 acquire() 方法来获取许可。如果许可数量大于0，线程将获取一个许可，并将许可数量减1；如果许可数量为0，线程将被阻塞等待，直到有许可可用。</p>\n<p>​\t3、释放许可：当一个线程使用完共享资源后，必须调用 Semaphore 的 release() 方法来释放许可。释放许可会将许可数量加1，使得其他等待许可的线程可以继续获取许可。</p>\n<p>3、特点:</p>\n<p>​\t1、可以用于限制同时访问某个资源的线程数量。</p>\n<p>​\t2、可以用于实现某种资源池的管理。</p>\n<p>​\t3、可以用于实现线程的同步和互斥。</p>\n<h3 id=\"7、阻塞队列\">7、阻塞队列</h3>\n<h4 id=\"BlockingQueue\"><code>BlockingQueue</code></h4>\n<p>1、是一种高效并且线程安全的队列类，是一个队列，数据可以一端输入一端输出；队空，从队列中取数据的操作被阻塞；队满，放数据到队列中的操作被阻塞，此时需要其他队列放数据或者取数据才会才会解除阻塞。<code>阻塞是指在某些情况下会挂起线程，一旦条件满足，被挂起的线程又会自动被唤起</code></p>\n<p>2、使用<code>BlockingQueue</code>不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切<code>BlockingQueue</code> 都给已经解决好了</p>\n<p>3、分类</p>\n<p>​\t1、<strong>ArrayBlockingQueue(常用)</strong> ： 基于数组的<code>阻塞队列</code>实现，在 <code>ArrayBlockingQueue</code> 内部，维护了一个定长数组可以缓存队列中的数据对象，ArrayBlockingQueue<code> 内部还保存着两个整形变量，</code>分别标识着队列的<code>头部</code>和<code>尾部</code>在数组中的位置。==<strong>是由数组结构组成的有界阻塞队列。</strong>==</p>\n<p>​\t<s>注意的是 <code>ArrayBlockingQueue</code> 在<code>生产者放入数据</code>和<code>消费者获取数据</code>，都是<code>共用同一个锁对象</code>，由此也意味着<code>两者无法真正并行运行</code>，这点尤其不同于<code>LinkedBlockingQueue</code>；按照实现原理来分析，<code>ArrayBlockingQueue</code> 完全可以采用<code>分离锁</code>，从而实现生产者和消费者操作的完全并行运行。Doug Lea 之所以没这样去做，也许是因为 <code>ArrayBlockingQueue</code> 的数据<code>写入和获取</code>操作已经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其在性能上完全占不到任何便宜。</s></p>\n<p>​\t2、<strong>LinkedBlockingQueue(常用)</strong>:基于<code>链表</code>的阻塞队列，其内部也维持着一个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue 可以通过构造函数指定该值），才会阻塞生产者队列，<code>直到消费者从队列中消费掉</code>一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。==<strong>是由链表结构组成的<code>有界</code>（但大小默认值为integer.MAX_VALUE）阻塞队列。</strong>==</p>\n<p>而 <code>LinkedBlockingQueue</code> 之所以能够高效的处理并发数据，==还因为其对于生产者端和消费者端分别<code>采用了独立的锁</code>来控制数据同步==，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。</p>\n<blockquote>\n<p><code>ArrayBlockingQueue</code> 和<code>LinkedBlockingQueue</code> 间还有一个明显的不同之处在于，前者在<code>插入或删除</code>元素时<code>不会产生或销毁任何额外的对象实例</code>，而后者则会生成一个额外的<code>Node</code> 对象。这在长时间内需要<code>高效并发</code>地处理大批量数据的系统中，其对于<code>GC</code> 的影响还是存在一定的区别。而在创建 <code>ArrayBlockingQueue</code> 时，我们还可以控制对象的<code>内部锁</code>是否采用公平锁，默认采用<code>非公平锁</code>。</p>\n</blockquote>\n<p>​\t3、<strong>DelayQueue</strong>： DelayQueue 中的元素只有当其指定的<code>延迟时间</code>到了，才能够从队列中获取到该元素。DelayQueue 是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。==<strong>总是使用优先级队列实现的延迟无界阻塞队列。</strong>==</p>\n<p>​\t4、<strong>PriorityBlockingQueue</strong>： 基于<code>优先级的阻塞队列</code>，但需要注意的是 <code>PriorityBlockingQueue</code>不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，<strong>生产者生产数据的速度绝对不能快于消费者消费数据的速度</strong>，否则时间一长，会最终耗尽所有的可用堆内存空间。在实现 PriorityBlockingQueue 时，内部控制线程同步的锁采用的是<strong>公平锁</strong>。 ==<strong>是支持优先级排序的无界阻塞队列。</strong>==</p>\n<p>​\t5、<strong>SynchronousQueue</strong>： 一种<code>无缓冲</code>的等待队列；声明一个 SynchronousQueue 有两种不同的方式；==<strong>不存储元素的阻塞队列，也即单个元素的队列。</strong>==</p>\n<p>​\t\t5.1、公平模式： 会采用<code>公平锁</code>，并配合一个<code> FIFO 队列来阻塞</code>多余的生产者和消费者，从而体现整体的公平策略；</p>\n<p>​\t\t5.2、非公平模式（ 默认）：采用非公平锁，同时配合一个 LIFO（后进先出） 队列来管理多余的生产者和消费者</p>\n<p>​\t\t而后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥饿的情况，可能有某些生产者或者是消费者的数据永远都得不到处理。</p>\n<p>​\t6、<strong>LinkedTransferQueue</strong>： 一个由链表结构组成的无界阻塞 <code>TransferQueue</code> 队列。采用一种<code>预占模式</code>。即消费者线程取元素时，如果队列不为空，则直接取走数据，若队列为空，那就生成一个节点（节点元素为 <code>null</code>）入队，然后消费者线程被等待在这个节点上，后面生产者线程入队时发现有一个元素为 null 的节点，生产者线程就不入队了，直接就将元素填充到该节点，并唤醒该节点等待的线程，被唤醒的消费者线程取走元素，从调用的方法返回。==<strong>是由链表组成的无界阻塞队列。</strong>==</p>\n<p>​\t7、<strong>LinkedBlockingDeque</strong>:一个由链表结构组成的<code>双向阻塞队列</code>，可以从队列的<code>两端插入和移除元素</code>。在插入或者获取队列元素时如果队列状态不允许该操作可能会阻塞住该线程直到队列状态变更为允许操作，==<strong>由链表组成的双向阻塞队列</strong>==这里的阻塞一般有两种情况</p>\n<p>​\t\t\t插入元素时: 如果当前队列已满将会进入阻塞状态，一直等到队列有空的位置时再将该元素插入，该操作可以通过设置超时参数，超时后返回 false 表示操作失败，也可以不设置超时参数一直阻塞，中断后抛出异常</p>\n<p>​\t\t\t读取元素时: 如果当前队列为空会阻塞住直到队列不为空然后返回元素，同样可以通过设置超时参数</p>\n<h3 id=\"8、线程池\">8、线程池</h3>\n<p>1、作用：可以维护着多个线程，等待管理者分配可并发执行的任务。避免了在处理短时间任务时创建与销毁线程的代价。线程池不仅能够保证内核的充分利用，还能防止过分调度。</p>\n<p>2、参数：1、<code>corePoolSize</code> 线程池的核心线程数  + 2、<code>maximumPoolSize</code> 能容纳的最大线程数+3、<code>keepAliveTime</code> 空闲线程存活时间+4、<code>unit</code> 存活的时间单位+ 5、<code>workQueue</code> 存放提交但未执行任务的队列 + 6、<code>threadFactory</code> 创建线程的工厂类 + 7、<code>handler</code> 等待队列满了的拒绝策略</p>\n<p>3、核心过程：当提交任务数<code>大于</code> 核心线程数 的时候，会优先将任务放到 阻塞队列中。当阻塞队列<code>饱和</code>后，会<code>扩充线程池中线程数</code>，直到达到 最大线程数的配置之后，再有多余的任务，则会触发线程池的<code>拒绝策略</code>了。</p>\n<p>4、拒绝策略：</p>\n<p>​\t1、<strong>AbortPolicy（默认）</strong>：默认的拒绝策略，当线程池无法接受新任务时，会抛出异常。</p>\n<p>​\t2、<strong>CallerRunsPolicy</strong>：当线程池无法接受新任务时，会使用调用者线程来执行该任务。任务会在提交任务的线程中执行。</p>\n<p>​\t3、<strong>DiscardPolicy</strong>：当线程池无法接受新任务时，会直接丢弃该任务，不会有任何异常抛出。</p>\n<p>​\t4、<strong>DiscardOldestPolicy</strong>：当线程池无法接受新任务时，会丢弃工作队列中最旧的任务，然后尝试重新提交新任务。</p>\n<p>==5、线程池的种类==</p>\n<p>​\t1、<strong>newFixedThreadPool（固定线程池&lt;默认&gt;）</strong>：固定线程池通过 <code>ThreadPoolExecutor</code> 类实现，它包含固定数量的线程。当有任务提交时，如果线程池中有空闲线程，则立即使用空闲线程执行任务；如果没有空闲线程，则将任务放入工作队列中等待执行。固定线程池<code>适用于需要控制线程数量的场景</code>，例如限制资源的使用。</p>\n<p>​\t2、<strong>newCachedThreadPool（缓存线程池）</strong>：缓存线程池也是通过 <code>ThreadPoolExecutor</code> 类实现，它可以根据需要自动创建新线程，线程池中的线程数会根据任务的数量进行动态调整。当有任务提交时，如果有空闲线程，则立即使用空闲线程执行任务；如果没有空闲线程，则创建新线程执行任务。如果线程空闲时间超过一定阈值，线程会被终止并从线程池中移除。缓存线程池<code>适用于任务数量不确定的场景</code>，可以根据实际需求动态调整线程数量。</p>\n<p>​\t3、<strong>newSingleThreadExecutor（单线程池）</strong>：单线程池通过 <code>ThreadPoolExecutor</code> 类实现，它只包含一个工作线程。所有提交的任务都会按照顺序在该线程中执行。如果该线程因异常而终止，会创建一个新线程来替代它。单线程池适用于<code>需要顺序执行任务的场景</code>，例如任务之间有依赖关系。</p>\n<p>​\t\t两个区别：</p>\n<p>​\t\t\t1、和<code>自己创建单线程执行任务</code>的区别：自己创建一个单线程串行执行任务，如果任务执行失败而终止那么没有任何补救措施；而线程池还会新建一个线程，保证池的正常工作</p>\n<p>​\t\t\t2、和<code>Executors.newFixedThreadPool(1) </code>初始时为<code>1</code>时的区别：<code>Executors.newFixedThreadPool(1) </code>初始时为1，以后还可以修改，对外暴露的是 <code>ThreadPoolExecutor</code> 对象，可以<code>强转</code>后调用 <code>setCorePoolSize </code>等方法进行修改</p>\n<p>​\t4、<strong>newScheduledThreadPool（定时任务线程池）</strong>：定时任务线程池通过 <code>ScheduledThreadPoolExecutor</code> 类实现，它可以在指定的延迟时间后执行任务，或者按固定的时间间隔周期性地执行任务。定时任务线程池适用于需要<code>定时执行任务的场景</code>，例如定时任务调度。一种低级的平替方案： 设定定时任务</p>\n<p>​\t<s>5、newWorkStealingPool： 底层使用的是 <code>ForkJoinPool</code> 实现，创建一个<code>拥有多个任务队列</code>的线程池，可以减少连接数，创建当前可用 <code>cpu</code> 核数的线程来并行执行任务；适用于大耗时，可并行执行的场景</s></p>\n<p>==6、线程池的底层原理==</p>\n<p>​\t1、首先在刚开始创建线程池的时候，线程池中的线程数为零；之后当调用<code> execute()</code>方法添加一个请求任务时，线程池执行下面的逻辑：</p>\n<p>​\t\t如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务；如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列； 如果这个时候队列满了且正在运行的线程数量还小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务；如果队列满了且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会启动饱和拒绝策略来执行。</p>\n<p>​\t2、当一个线程完成任务时，它会从队列中取下一个任务来执行</p>\n<p>​\t3、当一个线程无事可做超过一定的时间（keepAliveTime）时，线程会判断：如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。 所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。</p>\n<p>7、ThreadPoolExecutor</p>\n<p>​\t7.1、Executor 框架结构</p>\n<p>​\t\t7.1.1任务(<code>Runnable</code> /<code>Callable</code>) ： 执行任务需要实现的 <code>Runnable</code> 接口 或 <code>Callable</code>接口。Runnable 接口或 Callable 接口<code>实现类</code>都可以被 <code>ThreadPoolExecutor</code> 或 ScheduledThreadPoolExecutor执行。</p>\n<p>​\t\t7.1.2任务的执行(<code>Executor</code>)：任务执行机制的核心   接口 <code>Executor</code> ，以及继承自 <code>Executor</code> 接口的 <code>ExecutorService</code> 接口。<code>ThreadPoolExecutor</code> 和 ScheduledThreadPoolExecutor这两个关键类实现了 <code>ExecutorService</code> 接口。</p>\n<p>​\t\t7.1.3异步计算的结果(<code>Future</code>)    Future 接口以及 <code>Future</code> 接口的实现类 <code>FutureTask</code> 类都可以代表异步计算的结果。随后会把 Runnable接口 或 Callable 接口 的实现类提交给 ThreadPoolExecutor 或 ScheduledThreadPoolExecutor 执行(调用 <code>submit()</code> 方法时会返回一个 <code>FutureTask </code>对象）</p>\n<p>​\t7.2、 流程</p>\n<p>​\t\t1、主线程首先要创建实现 Runnable 或者 Callable 接口的任务对象。</p>\n<p>​\t\t2、把创建完成的 ，实现了 Runnable/Callable接口的 对象直接交给 ExecutorService 执行: <code>ExecutorService.execute（Runnable command）</code>）或者也可以把 <code>Runnable</code> 对象或<code>Callable</code> 对象提交给 <code>ExecutorService</code> 执行（<code>ExecutorService.submit（Runnable task）</code>或 <code>ExecutorService.submit（Callable &lt;T&gt; task）</code>）。</p>\n<p>​\t\t3、如果执行<code> ExecutorService.submit（…）</code>，ExecutorService 将返回一个实现Future接口的对象（注意：执行 <code>execute()</code>方法和 <code>submit()</code>方法的区别，<code>submit()</code>会返回一个 <code>FutureTask</code> 对象）。</p>\n<p>​\t\t4、最后，主线程可以执行<code> FutureTask.get()</code>方法来等待任务执行完成。主线程也可以执行<code> FutureTask.cancel（boolean mayInterruptIfRunning）</code>来取消此任务的执行</p>\n<blockquote>\n<p>注意事项：</p>\n<p>1、创建多线程时，使用常见的<code>三种</code>线程池创建方式，<code>单一、可变、定长</code>都有一定问题，原因是<code>FixedThreadPool 和 SingleThreadExecutor</code>底层都是用<code>LinkedBlockingQueue</code> 实现的，这个队列最大长度为<code> Integer.MAX_VALUE</code>，容易导致 OOM。所以实际生产一般自己通过 ThreadPoolExecutor 的 7 个参数，自定义线程池;一般的创建线程池方式推荐使用<code>  ThreadPoolExecutor 及其 7 个参数手动创建</code></p>\n<p>2、为什么线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式</p>\n<p>​\t1、这样的处理方式可以更加明确线程池的运行规则，规避资源耗尽的风险。</p>\n<p>​\t2、说明：Executors返回的线程池对象的弊端如下：</p>\n<p>​\t<code>FixedThreadPool</code> <code>SingleThreadPool</code>:允许的<code>请求队列</code>长度为<code>Integer.MAX_VALUE</code>,可能会<code>堆积大量</code>的请求，从而导致O0M。</p>\n<p>​\t<code>CachedThreadPool</code> <code>ScheduledThreadPool</code>:允许的<code>创建线程</code>数量为<code>Integer.MAX_VALUE</code>,可能会<code>创建大量</code>的线程，从而导致OOM</p>\n<p>3、解决 ：使用有界队列，控制线程创建数量。</p>\n</blockquote>\n<h3 id=\"9、ForkJoin\">9、ForkJoin</h3>\n<p>1、将一个大的任务<code>拆分成多个子任务(fork)</code>放到双端队列中给不同的线程并行处理，子任务执行完后，结果会放在另外一个队列里，随后将<code>子任务结果合并成(join)</code>最后的计算结果，并进行输出。</p>\n<p>2、原理：</p>\n<p><strong>Fork 方法的实现原理：</strong> 当我们调用 <code>fork</code> 方法时，程序会把任务放在 <code>ForkJoinWorkerThread</code> 的 <code>pushTask</code>中，异步地执行这个任务，然后立即返回结果</p>\n<p><strong>Join 方法的实现原理：</strong> <code>Join</code> 方法的主要作用是阻塞当前线程并等待获取结果。</p>\n<p>3、结合线程池可以可以把每个任务的<code>分解和合并</code>交给<code>不同的线程</code>来完成，进一步<code>提升了运算效率</code>；所以<code>Fork/Join </code> <code>默认</code>会创建与 cpu 核心数<code>大小相同</code>的线程池</p>\n<h2 id=\"原子性\">原子性</h2>\n<blockquote>\n<p>基调：访问共享变量时，保证临界区代码的原子性</p>\n</blockquote>\n<h3 id=\"10、锁-管程\">10、锁/管程</h3>\n<p>1、主要解决临界区的多个线程执行时，由于代码指令的执行顺序不确定带来的结果无法预测的问题。</p>\n<p>2、解决方案</p>\n<p>​\t2.1、阻塞式解决方案：synchronized ，Lock</p>\n<p>​\t2.2、非阻塞式解决方案：原子变量</p>\n<h4 id=\"Synchronized\">Synchronized</h4>\n<p>​\t1、介绍</p>\n<p>​\t一种同步锁，父子类必须都声明了<code>Synchronized</code>才表示两个都是同步方法（synchronized 关键字<code>不能被继承</code>），但是子类方法中调用父类中<code>Synchronized</code>修饰的方法，即使子类没有显示的用<code>Synchronized</code>修饰，那么子类的方法也是相当于同步的</p>\n<p>​\t被锁住的方法只有在 线程执行完这段代码  或者  线程发生了异常  该线程才会对<code>释放锁</code>，其他线程也才会获得被释放的锁，但是一旦已经获得锁的线程被阻塞住，那么就会导致其他线程无限的等下去。</p>\n<p>​\t使用lock手动的释放锁就可以解决无限等待的问题</p>\n<p>​\t2、==思想/ 原理：==</p>\n<p>​\t它采用<code>互斥</code>的方式让<code>同一时刻</code>至多<code>只有一个线程持有对象锁</code>，其他线程如果想获取这个锁就会<code>阻塞住</code>，这样就能保证拥有锁的线程可以<code>安全的</code>执行临界区内的代码，<code>不用担心线程上下文切换</code>；synchronized实际是 <code>用对象锁保证了临界区中代码的原子性</code> 所谓的原子性就是说 : 临界区内的代对码对外是不可分割的，不会被线程切换所打断。</p>\n<p>​\t注意： 虽然 java 中互斥和同步都可以采用 synchronized 关键字来完成，但它们还是有区别的：</p>\n<p>​\t\t1、互斥是保证临界区的竞态条件发生，同一时刻只能有一个线程执行临界区的代码</p>\n<p>​\t\t2、同步是由于线程执行的先后顺序不同，但是需要一个线程等待其它线程运行到某个点。</p>\n<p>​\t3、==修饰==</p>\n<p>​\t\t同步方法底层也是<code>有锁对象</code>的：</p>\n<p>​\t\t\t同步方法:锁的是当前<code>实例对象</code>，锁的是<strong>this对象</strong></p>\n<p>​\t\t\t静态同步方法:静态<code>同步方法</code>，锁的是当前类的<strong>Class对象</strong></p>\n<p>​\t\t\t同步<code>代码块</code>，锁是 <strong>Synchonized代码块里配置的对象</strong></p>\n<blockquote>\n<p>当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。</p>\n<p>​\t1、如果一个实例对象的<code>非静态同步方法</code>获取锁后，<code>该实例对象的其他</code>非静态同步方法<code>必须等待</code>获取锁的方法释放锁后才能获取锁，</p>\n<p>​\t2、<code>别的实例对象的非静态同步方法</code>因为跟该实例对象的非静态同步方法用的是<code>不同的锁</code>，所以<code>无须等待</code>就可以获取他们自己的锁。</p>\n<p>​\t3、所有的<code>静态同步方法</code>用的也是同一把锁:  <code>类对象本身</code>，这两把锁是两个不同的对象，所以静态同步方法与非静态同步方法之间是不会有竞态条件的。但是一旦<code>一个静态同步方法获取锁后</code>，其他的（不管是同一个或者 不同的实例对象）静态同步方法都<code>必须等待</code>该方法释放锁后才能获取锁！</p>\n</blockquote>\n<p>​\t4、是否是线程安全的：主要关注锁住的对象是不是同一个,只要锁对象<code>不相同</code>就<code>不会出现加锁阻塞</code>的情况；如果锁住<code>类对象</code>，<code>所有类的实例</code>的方法都是安全的，类的所有实例都相当于<code>同一把锁</code>；如果锁住<code> this 对象</code>，只有在<code>当前实例</code>对象的线程内是安全的，如果有多个实例就不安全</p>\n<p>​\t<strong>5、可重入的原理</strong>：</p>\n<p>​\t每个锁对象  都会  拥有一个<code>锁计数器</code>和一个<code>指向持有该锁的线程的指针</code>     <code>_count(初始值为0，表示当前对象是否被锁定，执行加锁+1，执行解锁-1)</code>  <code>_owner（锁定当前对象的线程ID）</code>        <code>_recursions（表示同步代码块的重入次数，每进入一层+1，每出来一层-1）</code></p>\n<ul>\n<li><strong>首次加锁</strong>：当执行<code>monitorenter</code>时，如果目标锁对象的计数器<code>_count</code>为零，那么说明它没有被其他线程所持有，Java虚拟机会将该锁对象的持有线程<code>_owner</code>设置为当前线程，并且将计数器<code>_count</code>加1。</li>\n<li><strong>重入</strong>：在目标锁对象的计数器<code>不为零</code>的情况下，如果锁对象的<code>持有线程是当前线程</code>，那么 Java 虚拟机可以将其计数器<code>_count</code>加1,并且锁的重入次数<code>_recursions</code>加一，否则需要等待，直至持有线程释放该锁。要是持有锁的不是当前线程，那么说明有其他线程在持有这把锁，就进入阻塞队列中进行等待</li>\n<li><strong>释放锁</strong>：当执行<code>monitorexit</code>时，Java虚拟机则需将锁对象的计数器减1。如果<code>_recursions</code>不为0,<code>_recursions</code>和<code>_count</code>都减一,<code>_recursions</code>为零已经从多层<code>sychronized</code>中退出，此时将这个线程的所有者置为空，表示这个线程完全释放了锁；要是不为0 ,表示未退出所有的<code>sychronized</code>,锁的持有者不变</li>\n</ul>\n<h4 id=\"Monitor-管程\">Monitor(管程)</h4>\n<blockquote>\n<p>Synchronized 的对临界代码的互斥作用</p>\n</blockquote>\n<p>1、介绍</p>\n<p>​\t\tMonitor（监视器）是一种同步机制，用于控制并发访问共享资源的线程间的互斥和协作。它是一种抽象的概念，可以通过锁（通常是互斥锁）和条件变量来实现；也可以将其视为一种就是重量级锁，一个对象一个<code>锁</code>，就是说一个对象一个<code>monitor</code>；</p>\n<p>2、原理</p>\n<p>​\t<code>EntryList</code>  称为等待队列,其中的元素是<code>非公平</code>的，不是FIFO的顺序执行，<code>其依赖于JDK的底层实现</code></p>\n<ul>\n<li>刚开始时<code>Monitor</code>中的<code>Owner（所有者）</code>为<code>null</code></li>\n<li>当一个线程 执行<code>synchronized(obj)&#123;&#125;</code>代码时就会将Monitor的所有者设置为 <code>当前线程</code>，上锁成功，Monitor中同一时刻只能有一个<code>所有者</code></li>\n<li>如果此时又来一个线程，也来执行<code>synchronized(obj)&#123;&#125;</code>代码，就会进入<code>EntryList(等待队列)</code>中变成<code>BLOCKED</code>状态</li>\n<li>当上一个线程执行完同步代码块的内容，然后唤醒 等待队列 中等待的线程来<code>竞争锁</code>，<code>竞争时是非公平的</code></li>\n<li>执行完代码的线程即上一个所有者的线程，会调用 wait 方法，进入 等待集合 变为 WAITING 状态</li>\n<li>随后BLOCKED 线程会在 所有者 线程释放锁时唤醒；WAITING 线程会在 所有者 线程释放时调用 notify 或 notifyAll 时唤醒，唤醒后并不意味者立刻获得锁，<strong>需要进入 EntryList 重新竞争</strong></li>\n</ul>\n<blockquote>\n<p><code>BLOCKED</code> 未获得锁的等待过程   <code>WAITING</code>获得锁之后又放弃锁，之后进入<code>WaitSet</code>(<strong>等待集合</strong>) 的 等待过程；</p>\n<p>BLOCKED 和 WAITING 的线程都处于阻塞状态，不占用 CPU 时间片;</p>\n<p>必须要<code>获得锁</code>,成为<code> 所有者</code>才能调用<code>notify() 、notifyAll()</code> 和<code>wait() 、 wait(long timeout) </code>方法</p>\n</blockquote>\n<h4 id=\"Synchronized-锁优化-升级\">Synchronized 锁优化(升级)</h4>\n<blockquote>\n<p>锁升级的过程：无锁–&gt;偏向锁–&gt;轻量级锁–&gt;重量级锁</p>\n<p>锁的<code>严苛程度</code>变强叫做升级，反之叫做降级</p>\n</blockquote>\n<blockquote>\n<p>重量级锁为什么比较消耗性能?   重量级锁涉及到<code>用户态</code>和<code>内核态</code>之间的切换</p>\n<p>多线程访问的4种情况：</p>\n<ol>\n<li>所有线程都可以来访问 ----&gt;无锁</li>\n<li>只有一个线程来访问，有且唯一Only One —&gt;偏向锁</li>\n<li>有2个线程A、B来交替访问 —&gt;轻量锁</li>\n<li>竞争激烈，多个线程来访问 —&gt;重锁</li>\n</ol>\n</blockquote>\n<p><strong>1、偏向锁</strong></p>\n<p>​\t在轻量级的锁中，如果同一个线程对同一个对象进行重入锁时，也需要执行<code>CAS</code>操作，会耗时，此时就引入了偏向锁；<code>偏向锁默认是延迟的</code>；其是<code>synchronized</code>关键字的另一种优化机制。</p>\n<p>​\t当一个线程访问一个同步块并获取锁时，如果该同步块没有发生竞争，JVM会将锁的标记为偏向锁。偏向锁表示该锁偏向于第一个获取它的线程，并假设在接下来的执行中，该线程将继续占有锁。这样，当这个线程再次进入同步块时，无需再次竞争锁，可以直接进入临界区执行。</p>\n<p>​\t偏向锁的引入主要是为了减少无竞争情况下的锁操作开销。在这种情况下，不需要使用轻量级锁或重量级锁的复杂机制，而是通过偏向锁来<code>避免竞争和线程切换</code>的开销，提高程序的性能。需要注意的是，偏向锁的前提是同步块在大部分时间内<code>只被一个线程访问</code>。如果有其他线程尝试获取该锁，偏向锁会<code>自动升级</code>为轻量级锁或重量级锁，进行适当的竞争处理。</p>\n<p>流程：</p>\n<p>​\t如果锁总是被第一个占用他的线程拥有，这个线程就是锁的偏向线程。</p>\n<p>​\t那么只需要在锁第一次被拥有的时候，记录下偏向线程ID。这样偏向线程就一直持有着锁(后续这个线程进入和退出这段加了同步锁的代码块时，不需要再次加锁和释放锁。而是直接比较对象头里面是否存储了指向当前线程的偏向锁)。</p>\n<p>​\t\t如果相等表示偏向锁是偏向于当前线程的，就不需要再尝试获得锁了，**直到竞争发生才释放锁。**以后每次同步，检查锁的偏向线程ID与当前线程ID是否一致，如果一致直接进入同步。无需每次加锁解锁都去<code>CAS</code>更新对象头。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。</p>\n<p>​\t\t如果不一致意味着发生了竞争，锁已经不是总是偏向于同一个线程了，这时候可能需要升级变为轻量级锁，才能保证线程间公平竞争锁。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程是不会主动释放偏向锁的。</p>\n<p>​\t\t\t<strong>竞争成功</strong>，表示之前的线程不存在了，MarkWord里面的线程1D为新线程的ID，锁不会升级，仍然为偏向锁；</p>\n<p>​\t\t\t<strong>竞争失败</strong>，这时候可能需要升级变为轻量级锁，才能保证线程间公平竞争锁。</p>\n<p>总结起来，偏向锁是为了提高无竞争情况下<code>synchronized</code>的性能而引入的一种锁优化机制，它将锁偏向于第一个获取它的线程，避免了竞争和线程切换的开销。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程是不会主动释放偏向锁的</p>\n<p><strong>2、轻量级锁</strong></p>\n<p>​\t是一种乐观锁策略，适用于多线程竞争不激烈的情况。本质就是自旋锁（尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，当线程发现锁被占用时，会不断循环判断锁的状态，直到获取。可以减少线程上下文切换的消耗，但是循环会消耗CPU）</p>\n<p>​\t1、每次指向到synchronized代码块时，都会创建<code>锁记录</code>（Lock Record）对象，每个线程都会包括一个锁记录的结构，锁记录内部 有锁记录的地址和对象引用reference，对象头 中有Mark word 和klass word</p>\n<p>​\t2、让锁记录中的Object reference指向对象，并且尝试用cas(compare and sweep)替换Object对象的Mark Word ，将Mark Word 的值存入锁记录中</p>\n<p>​\t3、如果cas替换<code>成功</code>，那么对象的对象头储存的就是<code>锁记录的地址和状态00 </code>  , 表示由该线程给对象加锁，</p>\n<p>​\t4、如果cas失败，有两种情况</p>\n<p>​\t\t1、如果是其它线程已经持有了该Object的轻量级锁（状态已经是 00 ），那么表示有竞争，将进入<code>锁膨胀阶段</code></p>\n<p>​\t\t\t1.1、如果在尝试加轻量级锁的过程中，cas操作无法成功，有一种情况就是<code>其它线程已经为这个对象加上了轻量级锁，</code>这是就要进行<code>锁膨胀</code>，将<code>轻量级锁升级为重量级锁。</code></p>\n<p>​\t\t\t1.2、当 Thread-1 进行轻量级加锁时，Thread-0 已经对该对象加了轻量级锁（状态已经00 所以会T1加锁失败）；这时 Thread-1 加轻量级锁失败，进入锁膨胀流程 ,T1 即为对象申请锁，让Object指向<strong>重量级锁地址</strong>，然后自己进入Monitor 的EntryList 变成BLOCKED状态</p>\n<p>​\t\t\t1.3、当Thread-0 <code> 退出synchronized</code>同步块时，如果使用<code>cas</code>将Mark Word的值<code>恢复</code>给对象头，<code>T0恢复信息时就会失败</code>，T0 就会进入<code>重量级锁的解锁过程，即按照Monitor的地址找到Monitor对象，将Owner设置为null，唤醒EntryList 中的Thread-1线程</code></p>\n<p>​\t\t2、如果是自己的线程执行了synchronized锁重入，那么再添加一条 Lock Record [锁记录]作为<code>重入的计数</code></p>\n<blockquote>\n<p>解锁</p>\n</blockquote>\n<p>1、当线程退出synchronized代码块的时候，**如果获取的是取值为 null 的锁记录 **，表示有重入，这时重置锁记录，表示重入计数<code>减一</code></p>\n<p>2、当线程退出synchronized代码块的时候，如果获取的锁记录取值不为 null，那么使用cas将Mark Word的值恢复给对象</p>\n<p>​\t2.1、成功则解锁成功</p>\n<p>​\t2.2、失败，则说明轻量级锁进行了<code>锁膨胀</code>或已经<code>升级为重量级锁</code>，执行<code>重量级锁解锁</code>流程</p>\n<p><strong>主要目的：</strong> 在没有多线程竞争的前提下，通过<code>CAS</code>减少重量级锁使用操作系统互斥量产生的性能消耗，说白了<code>先自旋再阻塞</code></p>\n<p><strong>何时升级为轻量级锁：</strong> 当关闭偏向锁功能或多线程竞争偏向锁会导致偏向锁升级为轻量级锁</p>\n<p>**何时加为轻量级锁： **<code>JVM</code>会为<code>每个线程</code>在当前线程的栈帧中创建用于存储锁记录的空间。若一个线程获得锁时发现是轻量级锁，会把锁的<code>MarkWord</code>复制到自己的<code>Displaced Mark Word</code>里面。然后线程尝试用<code>CAS</code>将锁的<code>MarkWord</code>替换为指向锁记录的指针；如果成功，当前线程获得锁，如果失败，表示<code>Mark Word</code>已经被替换成了其他线程的锁记录，说明在与其它线程竞争锁，当前线程就尝试使用自旋来获取锁</p>\n<p><strong>何时解锁:</strong> 在释放锁时，当前线程会使用CAS操作将Displaced Mark Word的内容复制回锁的Mark Word里面。如果没有发生竞争，那么这个复制的操作会成功。如果有其他线程因为自旋多次导致轻量级锁升级成了重量级锁，那么CAS操作会失败，此时会释放锁并唤醒被阻察的线程。</p>\n<p><strong>何时升级为重量级锁：</strong> <code>自旋达到一定次数和程度</code>；<strong>JDK6之前</strong>，默认启用，默认情况下自旋的次数是 10 次；自旋线程数超过cpu核数一半；Java6之后，自适应；意味着自旋的次数不是固定不变的；而是根据：同一个锁上一次自旋的时间 +   拥有锁线程的状态  来决定</p>\n<p><strong>轻量锁与偏向锁的区别和不同</strong></p>\n<ul>\n<li>争夺轻量级锁失败时，自旋尝试抢占锁</li>\n<li>轻量级锁每次退出同步块都需要释放锁，而偏向锁是在竞争发生时才释放锁</li>\n</ul>\n<p><strong>2.2、自旋优化</strong></p>\n<p>​\t自旋优化的思想是：在发现锁被占用时，线程不会立即进入阻塞状态，而是进行一段短暂的自旋操作。在自旋过程中，线程会反复检查锁是否被释放，避免了线程切换和阻塞的开销。如果在自旋期间锁被释放，线程可以立即获取锁并继续执行。如果自旋超过一定次数或时间仍然无法获取锁，线程才会进入阻塞状态。就是说：\t重量级锁<code>竞争</code>时候，可以使用自旋来进行优化，如果当前线程自旋成功（即在自旋的时候<code>持锁的线程释放了锁</code>），那么当前线程就可以<code>不用</code>进行上下文切换<code>就获得了锁</code>；适用于锁竞争时间短、竞争激烈但占用时间短暂的情况，</p>\n<p>1、自旋重试失败是指，自旋了<code>一定次数</code>还是没有等到持锁的线程释放锁</p>\n<p>2、自旋会占用 CPU 时间，单核 CPU 自旋就是浪费，多核 CPU 自旋才能发挥优势。</p>\n<p><strong>3、膨胀锁</strong></p>\n<p>​\t简而言之:膨胀锁就是在多线程环境中，当<code>细粒度锁</code>的竞争激烈时，将其<code>升级为粗粒度锁</code>，以减少锁的数量和管理开销</p>\n<p><strong>4、JIT编译器对锁的优化</strong></p>\n<p>1、<strong>锁粗化</strong></p>\n<p>多个连续的细粒度的<code>synchronized</code>块合并为一个更大的块，从而减少锁的获取和释放次数。这样可以减少锁竞争和线程切换的开销，提高程序的性能。</p>\n<p>2、<strong>锁消除</strong></p>\n<p>锁消除是指在编译器或运行时，通过静态分析发现一些代码中<code>不可能存在共享数据竞争</code>的情况，从而可以消除对应的锁操作。对于没有竞争的代码块，<code>JVM</code>可以安全地将<code>synchronized</code>锁消除，以减少锁的开销。</p>\n<p><strong>锁的对比</strong></p>\n<table>\n<thead>\n<tr>\n<th>锁</th>\n<th>优点</th>\n<th>缺点</th>\n<th>适用场景</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>偏向锁</td>\n<td>加锁和解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒级的差距</td>\n<td>如果线程间存在锁竞争,会带来额外的锁撤销的消耗</td>\n<td>适用于只有一个线程访问同步块的场景</td>\n</tr>\n<tr>\n<td>轻量级锁</td>\n<td>竞争的线程不会阻塞，提高了程序的响应速度</td>\n<td>如果始终得不到锁竞争的线程，使用自旋会消耗CPU</td>\n<td>追求响应时间<br>同步块执行速度非常快</td>\n</tr>\n<tr>\n<td>重量级锁</td>\n<td>线程竞争不使用自旋，不会消耗CPU</td>\n<td>线程阻塞，响应时间缓慢</td>\n<td>追求吞吐量，同步块执行速度较长</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li>偏向锁：适用单线程适用的情况，在不存在锁竞争的时候进入<code>同步方法/代码块</code>则使用偏向锁。</li>\n<li>轻量级锁：适用竞争不激烈的情况（这和乐观锁的使用范围类似），存在竞争时升级为轻量级锁，轻量级锁采用的是自旋锁，如果同步方法代码块执行时间很短的话，采用轻量级锁虽然会占用cpu资源但是相对比使用重量级锁还是更高效。</li>\n<li>重量级锁：适用于竞争激烈的情沉，如果同步方法/代码块执行时间很长，那么使用轻量级锁自旋带来的性能消耗就比使用重量级锁更严重，这时候就需要升级为重量级锁</li>\n</ul>\n<blockquote>\n<p>1、加锁顺序</p>\n<p>​\t1、<code>未禁用</code>偏向锁的时候，刚创建的锁就是<code>偏向锁</code></p>\n<p>​\t2、<code>禁用</code>偏向锁 之后 创建的就是 <code>轻量级锁</code></p>\n<p>​\t3、但是 <code>锁膨胀</code>之后，就创建<code>重量级锁</code></p>\n<p>2、撤销偏向锁的方法</p>\n<p>​\t2.1、<strong>撤销偏向锁-hashcode方法</strong>：当调用对象的hashcode方法的时候就会撤销这个对象的偏向锁，因为使用偏向锁时没有位置存<code>hashcode</code>的值了，锁就变为了<code>轻量级锁</code></p>\n<p>​\t2.2、<strong>撤销偏向锁-让其它线程使用锁</strong>：让偏向锁撤销变成轻量级锁的过程，那么就得满足轻量级锁的使用条件，就是没有线程对同一个对象进行锁竞争，注意使用<code>wait</code> 和 <code>notify</code> 来辅助实现，就是让两个线程一个等待，一个执行，执行完的线程通过<code>notify()</code>通知另一个线程就消去了<code>竞争</code>的关系 ;    此时就会导致只能偏向于一个线程的锁现在又要偏向 另一个线程；锁就变为了<code>轻量级锁</code></p>\n<p>​\t2.3、<strong>撤销偏向锁 - 调用 wait/notify</strong>：会使对象的锁变成重量级锁，因为<code>wait/notify</code>方法<code>重量级锁</code>才支持，锁就变为了<code>重量级锁</code></p>\n<p>3、批量重偏向</p>\n<p>​\t3.1、如果对象被多个线程访问，但是没有竞争，这时候偏向了线程T1的对象又有机会重新偏向线程T2[就是上面的 <code>撤销偏向锁-让其它线程使用对象</code>的情况]；</p>\n<p>​\t3.2、此时为了可以不升级为轻量级锁，又要实现重新偏向是要有<code>条件</code>的：<code>就是超过一定的阈值（20）</code>;</p>\n<p>​\t3.3、之后对象会在<code>第20次及以后</code>撤销对<code>先前线程</code>的偏向，转为偏向线程T2</p>\n<p>4、批量撤销</p>\n<p>​\t4.1、当撤销偏向锁阈值超过 <code>40 </code>次后，</p>\n<p>​\t4.2、jvm 会这样觉得，自己确实偏向错了，根本就不该偏向。于是整个类的所有对象都会变为不可偏向的，新建的对象也是不可偏向的</p>\n<p>5、偏向锁已经逐渐废除的原因</p>\n<p>​\t1、代码侵入： <strong>偏向锁</strong>为整个「同步子系统」引入了大量的复杂度，并且这些复杂度也入侵到了 <code>HotSpot</code> 的其它组件。这导致了系统代码难以理解，难以进行大的设计变更，降低了子系统的演进能力</p>\n<p>​\t2、由于是基于  synchronized 来保证线程安全 ，所以性能低下</p>\n<p>6、锁升级hashCode去哪了？</p>\n<p>锁升级为<strong>轻量级或重量级锁后，Mark Word中保存的分别是线程栈帧里的锁记录指针和重量级锁指针</strong>，已经没有位置再保存哈希码、GC年龄了，那么这些信息被移动到哪里去了呢?</p>\n<ul>\n<li>\n<p>在无锁状态下，<code>Mark Word</code>中可以存储对象的<code>identity hash code</code>值。当对象的<code>hashCode()</code>方法第一次被调用时，JVM会生成对应的<code>identity hash code</code>值并将该值存储到<code>Mark Word</code>中。</p>\n</li>\n<li>\n<p>对于偏向锁，在线程获取偏向锁时，会用<code>Thread ID</code>和<code>epoch</code>值覆盖<code>identity hash code</code>所在的位置。**如果一个对象的<code>hashCode()</code>方法已经被调用过一次之后，这个对象不能被设置偏向锁。**因为如果可以的话，那<code>Mark Word</code>中的<code>identity hash code</code>必然会被偏向线程ld给覆盖，这就会造成同一个对象前后两次调用<code>hashCode()</code>方法得到的结果不一致。</p>\n<ul>\n<li>当一个对象已经计算过<code>identity hashcode</code>，它就无法进入偏向锁状态，跳过偏向锁，直接升级轻量级锁</li>\n<li>偏向锁过程中遇到一致性哈希计算请求，立马撤销偏向模式，膨胀为重量级锁</li>\n</ul>\n</li>\n<li>\n<p>升级为轻量级锁时，JVM会在当前线程的栈帧中创建一个锁记录(Lock Record)空间，用于存储锁对象的Mark Word拷贝，该拷贝中可以包含<code>identity hash code</code>，所以轻量级锁可以和<code>identity hash code</code>共存，哈希码和GC年龄自然保存在此，释放锁后会将这些信息写回到对象头。</p>\n</li>\n<li>\n<p>升级为重量级锁后，<code>Mark Word</code>保存的重量级锁指针，代表重量级锁的<code>Object Monitor</code>类里有字段记录非加锁状态下的<code>Mark Word</code>，锁释放后也会将信息写回到对象头。</p>\n</li>\n</ul>\n</blockquote>\n<h3 id=\"11、-wait-和-notify\">11、 <code>wait()</code> 和 <code>notify()</code></h3>\n<blockquote>\n<p>基于对象的监视器（monitor）机制实现的</p>\n</blockquote>\n<p>基本原理：</p>\n<ol>\n<li><code>wait()</code> 方法被调用时，线程会释放对象上的锁，进入等待状态。</li>\n<li>线程在等待状态中，不会消耗CPU资源，直到被其他线程唤醒。</li>\n<li>当其他线程调用相同对象上的 <code>notify()</code> 或 <code>notifyAll()</code> 方法时，等待线程中的一个或多个线程会被唤醒。</li>\n<li>被唤醒的线程会进入就绪状态，等待获取对象上的锁。</li>\n<li>等待线程获取到锁后，会从 <code>wait()</code> 方法返回，并继续执行后续代码。</li>\n</ol>\n<h3 id=\"12、park-和-unpack\">12、<code>park 和 unpack</code></h3>\n<blockquote>\n<p>是Java中用于线程阻塞和唤醒的方法，与锁无关</p>\n</blockquote>\n<p>1、介绍：是 LockSupport 类中的方法 ；park()暂停当前线程；unpark()恢复当前线程;</p>\n<p>2、对比：</p>\n<blockquote>\n<p>Thread 的<code>park unpark </code>与 Object 的<code>wait &amp; notify</code>相比</p>\n<ul>\n<li><code>wait</code>，<code>notify</code> 和 <code>notifyAll</code> 必须配合 Object Monitor 一起使用，而 <code>park</code>，<code>unpark</code> 不用</li>\n<li><code>park</code> &amp; <code>unpark</code> 是以<code>线程</code>为单位来【阻塞】和【唤醒】线程，而 <code>notify</code> 只能随机唤醒一个等待线程，<code>notifyAll</code> 是唤醒所有等待线程，就不那么【精确】</li>\n<li><code>park</code> &amp; <code>unpark</code> 可以先 <code>unpark</code>，而 <code>wait</code> &amp; <code>notify</code> 不能先 <code>notify</code></li>\n</ul>\n</blockquote>\n<p>3、原理：</p>\n<p>1、先调用park再调用upark的过程</p>\n<p>​\t先调用<code>park</code>：当前线程调用 Unsafe.park() 方法；检查 _counter ，此时为 0，获得 _mutex 互斥锁(mutex对象有个等待队列 _cond)；线程进入 _cond 条件变量阻塞；设置 _counter = 0</p>\n<p>​\t再调用<code>unpark</code>：调用 Unsafe.unpark(Thread_0) 方法，设置 _counter 为 1；唤醒 _cond 条件变量中的 Thread_0；Thread_0 恢复运行；设置 _counter 为 0</p>\n<p>2、先调用upark再调用park的过程</p>\n<p>​\t调用 Unsafe.unpark(Thread_0) 方法，设置 _counter 为 1；当前线程调用 Unsafe.park() 方法；检查 _counter ，此时为 1，这时线程无需阻塞，继续运行；设置 _counter 为 0</p>\n<h3 id=\"13、await-singal-siangalall\">13、<code>await() singal() siangalall()</code></h3>\n<blockquote>\n<p>它们是基于条件变量（Condition Variable）的机制实现的，常用于与 <code>Lock</code> 对象一起使用</p>\n</blockquote>\n<ol>\n<li><code>await()</code>: 当一个线程调用某个条件变量的 <code>await()</code> 方法时，它会释放相关的锁，并进入等待状态，直到其他线程调用相同条件变量的 <code>signal()</code> 或 <code>signalAll()</code> 方法来唤醒等待线程。</li>\n<li><code>signal()</code>: 当一个线程调用某个条件变量的 <code>signal()</code> 方法时，它会唤醒等待该条件变量的一个线程。被唤醒的线程从等待状态进入就绪状态，并尝试重新获取相关的锁。</li>\n<li><code>signalAll()</code>: 当一个线程调用某个条件变量的 <code>signalAll()</code> 方法时，它会唤醒等待该条件变量的所有线程。被唤醒的线程从等待状态进入就绪状态，并尝试重新获取相关的锁。</li>\n</ol>\n<h3 id=\"14、锁的活跃性\">14、锁的活跃性</h3>\n<p>1、死锁</p>\n<p>现象：一个线程需要同时获取多把锁，这时就容易发生死锁；t1 线程<code>获得A</code>对象锁，接下来<code>想获取B</code>对象的锁；此时 t2 线程<code>获得B</code>对象锁，接下来<code>想获取A</code>对象的锁例</p>\n<p>2、活锁</p>\n<p>现象： 一直执行，无法停止</p>\n<p><span style=\"color:purple\">解决：执行时间有一定的<code>交错</code> 或者设置随机的<code>睡眠时间</code></span></p>\n<p>3、饥饿：一个线程由于优先级太低，始终得不到 CPU 调度执行，也不能够结束，讲读写锁时会涉及饥饿问题</p>\n<p>4、上述现象的解决：<strong>ReentrantLock</strong></p>\n<h3 id=\"15、ReentrantLock\">15、ReentrantLock</h3>\n<p>1、相对于 synchronized 它具备如下特点</p>\n<p>​\t1、<code>可中断</code>（比如：a有锁    b可以将这个锁取消掉）</p>\n<p>​\t2、可以设置<code>超时时间</code>，超过时间就放弃<code>争抢锁</code>，执行其他逻辑</p>\n<p>​\t3、可以设置为<code>公平锁</code>，防止饥饿（先到先得，不争抢）</p>\n<p>​\t4、支持<code>多个条件变量</code>（类似<code>waitset</code>，但是ReentrantLock有多个，可以将 等烟、等外卖等分开等，有多个休息室），即对与不满足条件的线程可以放到不同的集合中等待</p>\n<p>​\t5、与 synchronized 一样（只有一个<code>waitset</code>可以将 等烟、等外卖等分开等，只有个休息室，<code>notify()</code>通知所有对象），都支持<code>可重入</code>（同一个线程可以对同一个对象反复加锁）</p>\n<p><strong>2、可重入</strong></p>\n<p>可重入是指==同一个线程如果首次获得了这把锁，那么因为它是这把锁的拥有者，因此有权利再次获取这把锁== ；如果是不可重入锁，那么第二次获得锁时，自己也会被上一把锁挡住；</p>\n<p><strong>3、可打断</strong></p>\n<p>当设置为 <code>可打断模式</code>,即调用 : 打断锁方法：<code>  lock.lockInterruptibly()</code>  ;如果没有竞争，那么此方法就会获取Lock对象锁；如果有竞争 ，就进入阻塞队列，可以被其它线程用  <code>interruput</code> 方法打断</p>\n<p><strong>4、锁超时</strong></p>\n<p>等待一段时间，要是还是没有获得锁，就放弃等待，表示<code>获取失败</code>，因此不会死锁</p>\n<p><strong>5、公平锁</strong></p>\n<p>1、synchronized锁中，在<code>entrylist</code>等待的锁在竞争时不<code>是按照先到先得</code>来获取锁的，所以说synchronized锁时<code>不公平</code>的；</p>\n<p>2、ReentranLock锁默认是不公平的，但是可以通过<code>设置实现公平锁</code>。<code>本意是为了解决之前提到的饥饿问题</code>，但是公平锁一般没有必要，会降低并发度</p>\n<p><strong>6、条件变量</strong></p>\n<p>synchronized 中也有条件变量，ReentrantLock 的条件变量比 synchronized 强大之处在于，它是支持<code>多个条件变量</code>的，这就好比synchronized 是那些不满足条件的线程都在一间休息室等消息；而 ReentrantLock 支持多间休息室，有专门等烟的休息室、专门等早餐的休息室、唤醒时也是按休息室来唤醒</p>\n<p><strong>7、原理</strong></p>\n<ol>\n<li><code>ReentrantLock</code> 内部维护了一个锁状态（lock state），用于标识当前锁的拥有者和获取次数。</li>\n<li>当一个线程请求获取锁时，如果锁没有被其他线程占用，则该线程会立即获取到锁，并将锁状态设置为自己。</li>\n<li>如果锁已经被当前线程占用，则它可以再次获取该锁，即可重入特性。每次重入都会增加锁状态的获取次数。</li>\n<li>当一个线程持有锁时，其他线程请求获取锁会被阻塞，直到锁被释放。</li>\n<li>当一个线程释放锁时，它会将锁状态的获取次数减少。只有当锁状态的获取次数为零时，锁才会完全释放，其他线程才能获取到锁。</li>\n<li><code>ReentrantLock</code> 还提供了公平性和非公平性两种获取锁的策略。在公平模式下，锁会按照请求的顺序分配给等待线程。在非公平模式下，锁可能会优先分配给新请求的线程，以提高并发性能。</li>\n</ol>\n<blockquote>\n<p>注意： <code>ReentrantLock</code>必须<code>lock() unlock()</code>同时使用，不像<code>synchronized</code> 在<code>字节码层面</code>的退出时会<code>自动释放锁</code></p>\n<p><code>ReentrantLock</code> 的使用细节：<code>可打断</code>&lt;不会死锁&gt;、<code>锁超时</code>&lt;规定时间内得不到锁返回false不会死锁&gt;、<code>公平锁</code>（<code>ReentrantLock</code>  <code>synchronized</code> 默认都是非公平锁）、<code>条件变量</code></p>\n</blockquote>\n<h2 id=\"可见性\">可见性</h2>\n<h3 id=\"16、JMM-Java内存模型\">16、JMM (Java内存模型)</h3>\n<p>概念：是JVM提供的一张规范或者说是约束；用来实现线程和主内存之间的抽象关系，并屏蔽掉各种<code>硬件和操作系统的内存</code>访问差异，以实现让<code>Java</code>程序在各种平台下都能达到<code>一致的内存访问效果</code></p>\n<p>三大特性：</p>\n<p>​\t<code>原子性</code> - 保证指令执行时是原子的，不会受到线程上下文切换的影响 ;一个操作是不可中断的，即多线程环境下，操作不能被其他线程干扰</p>\n<p>​\t <code>可见性</code> - 保证指令不会受 <code>cpu 缓存</code>的影响,一个线程<code>修改</code>了某一个共享变量的值，其他线程是否能够<code>立即</code>知道该变更 ，JMM规定了<code>所有的变量</code>都存储在<code>主内存</code>中；要是没有可见性就会产生<code>线程脏读</code>的问题;</p>\n<p>​\t  <code>有序性</code> - 保证指令不会受 <code>cpu 指令并行优化</code>的影响</p>\n<p>​\t\t\t<code>有序性</code>的三个层面：\t1、编译器优化的重排\t\t2、指令并行的重排\t\t3、内存系统的重排</p>\n<p>背景：</p>\n<p>​\t在线程执行过程中，会将共享变量存到自己的高速缓冲区中，减少对主存的访问，提高效率，但是主线程中对该变量一旦进行了修改，那么子线程就不能读到这个变量，就会导致该值在子线程的高速缓冲区中并未得到修改</p>\n<p>解决：volatile</p>\n<h3 id=\"17、-volatile\">17、 volatile</h3>\n<p>volatile的内存语义</p>\n<p>​\t1、当写一个<code>volatile</code>变量时，JMM会把该线程对应的本地内存中的<code>共享变量值</code> <code>立即刷新回主内存中</code></p>\n<p>​\t2、当读一个<code>volatile</code>变量时，JMM会把该线程对应的<code>本地内存设置为无效</code>，直接从<code>主内存中读取</code>共享变量</p>\n<p>​\t3、所以volatile的<code>写内存语义</code>是<code>直接刷新到主内存中</code>，<code>读的内存语义</code>是直接从<code>主内存中读取</code>。</p>\n<p>作用：可以<code>避免</code>线程从<code>自己的工作缓存</code>中查找变量的值，必须到<code>主存中获取它的值</code>，线程操作<code> volatile</code> 变量都是直接操作<code>主存</code></p>\n<p>注意：</p>\n<p>​\t1、使用<code>synchronized</code>关键字也有相同的效果！  因为：线程在加锁时会 先<code>清空</code>工作内存→在主内存中<code>拷贝</code>最新变量的副本到<code>工作内存</code> →执行完代码→将更改后的<code>共享变量</code>的值刷新到<code>主内存</code>中→释放<code>互斥锁</code>；但是<code>volatile</code> 更加轻量   可见性角度 推荐使用 <code>volatile</code> 而不是  <code>synchronized</code></p>\n<p>​\t2、<code>synchronized</code> 内部的代码块可以由 <code>synchronized</code>保证 变量的可见性；非<code>synchronized</code> 内部的代码块需要由 <code>volatile</code>保证 变量的可见性</p>\n<h2 id=\"有序性\">有序性</h2>\n<h3 id=\"17、volatile续\">17、volatile续</h3>\n<p>使用synchronized并不一定能解决有序性问题，但是如果是该变量整个都在synchronized代码块的保护范围内，那么变量就不会被多个线程同时操作，也不用考虑有序性问题！</p>\n<h4 id=\"指令重排序优化\">指令重排序优化</h4>\n<p>指令的重排序：JVM线程内部维持<code>顺序化语义</code>，即<code>只要程序</code>的最终结果与它顺序化执行的结果相等，那么指令的执行顺序可以与代码顺序不一致；指令重排可以保证<code>串行语义一致</code>，但不能保证在<code>多线程</code>情况下的语义也是一致的，可能产生&quot;脏读&quot;简单说:两行以上不相干的代码在执行的时候有可能先执行的不是第一条，也就是不一定是从上到下顺序执行，执行顺序会被优化。</p>\n<blockquote>\n<p>对指令做更小力度的划分：<code>取指令 - 指令译码 - 执行指令 - 内存访问 - 数据写回</code> 这 5 个阶段称为 <code>五级指令流水线</code></p>\n<p>流水线指令的虽然<code>不能缩短指令的</code>执行时间<code>，但是变相的</code>提高了<code>指令的</code>吞吐量</p>\n</blockquote>\n<p>1、指令重排的前提是，重排指令<code>不能影响结果</code></p>\n<p>2、重排序遵守的规则：</p>\n<p>​\t1、重排序操作不会对<code>存在数据依赖关系</code>的操作进行重排序。</p>\n<p>​\t\t比如：<code>a=1;b=a; </code>这个指令序列，由于第二个操作依赖于第一个操作，所以在编译时和处理器运行时这两个操作不会被重排序。</p>\n<p>​\t2、重排序是为了优化性能，但是不管怎么重排序，单线程下程序的执行结果不能被改变。</p>\n<p>​\t\t比如：<code>a=1;b=2;c=a+b</code>这三个操作，第一步（a=1)和第二步(b=2)由于不存在数据依赖关系，所以可能会发生重排序，但是<code>c=a+b</code>这个操作是不会被重排序的，因为需要保证最终的结果一定是c=a+b=3。</p>\n<p>3、使用使用 <code>volatile</code> 修饰 就可以 <code>禁止指令重排</code></p>\n<p>问题：重排序在<code>单线程</code>模式下是一定会保证最终结果的正确性（单线程环境里面确保<code>程序 </code>  <code> 最终执行结果</code> 和 <code>代码</code> <code>顺序执行的结果</code>一致。），但是在<code>多线程</code>环境下，问题就出来了（多线程环境中线程<code>交替执行</code>,由于编译器<code>优化重排的存在</code>，两个线程中使用的变量能否保证一致性是无法确定的,结果无法预测）</p>\n<p>解决方法：volatile 修饰的变量，可以禁用指令重排，从而保证程序的有序性</p>\n<p>4、多线程对变量的读取过程：</p>\n<p>​\t1、各个线程先要将变量从主内存拷贝到的线程自己的工作内存空间，然后对变量进行操作，操作完成后再将变量<code>写回</code>主内存，<code>不能直接操作</code>主内存中的变量</p>\n<p>​\t2、各个线程中的工作内存中存储着主内存中的变量副本拷贝，因此不同的线程间无法访问对方的工作内存，线程间的通信(传值)必须通过<code>主内存</code>来完成</p>\n<blockquote>\n<p>由于JVM运行程序的实体是<code>线程</code></p>\n<p>每个线程<code>创建时</code>JVM都会为其<code>创建一个工作内存</code>(有些地方称为<code>栈空间</code>)，<code>工作内存</code>是每个线程的<code>私有的本地内存</code>(本地<strong>工作内存</strong>中存储了该线程用来<code>读/写共享变量的副本</code>),而Java内存模型中规定所有变量都<code>存储在主内存</code></p>\n<p>主内存是<code>共享内存区域</code>，所有线程都可以访问，但线程对变量的<code>操作</code>必须在<code>工作内存</code>中进行</p>\n<p>小结：</p>\n<ul>\n<li>我们定义的所有共享变量都储存在<code>物理主内存</code></li>\n<li>每个线程都有自己独立的工作内存，里面保存该线程使用到的变量的副本(主内存中该变量的一份拷贝)</li>\n<li>线程对共享变量所有的操作都必须先在线程自己的工作内存中进行后写回主内存，不能直接从主内存中读写(不能越级)</li>\n<li>不同线程之间也无法直接访问其他线程的工作内存中的变量，线程间变量值的传递需要通过主内存来进行(同级不能相互访问)</li>\n</ul>\n</blockquote>\n<h4 id=\"内存屏障：\">内存屏障：</h4>\n<p>又名： 内存栅栏，内存栅障，屏障指令</p>\n<p>是什么：一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作，避免代码重排序。</p>\n<p>作用：阻止<strong>屏障两边的</strong>指令重排序；写数据时加入屏障，强制将线程私有工作内存的数据刷回主物理内存；读数据时加入屏障，线程私有工作内存的数据失效，重新到主物理内存中获取最新数据</p>\n<p>什么是读写屏障：</p>\n<p>​\t1、写屏障(Store Memory Barrier) ：告诉处理器在写屏障之前将所有存储在缓存(store buffer es) 中的数据同步到主内存。也就是说当看到<code>Store</code>屏障指令， 就必须把该指令之前所有写入指令执行完毕才能继续往下执行。</p>\n<p>​\t2、读屏障(Load Memory Barrier) ：处理器在读屏障之后的读操作， 都在读屏障之后执行。也就是说在<code>Load</code>屏障指令之后就能够保证后面的读取数据指令一定能够读取到最新的数据。</p>\n<p>​\t3、<strong>对一个 <code>volatile</code> 变量的  写  先行发生于任意后续对这个 <code>volatile</code> 变量的   读  ，也叫写后读。</strong></p>\n<blockquote>\n<p>总结：</p>\n<p>保证有序—&gt;  do: 禁止指令重排序—&gt; do: 内存屏障禁止重排</p>\n<p>禁止指令重排序的方案：</p>\n<p>1、对于<code>编译器</code>的重排序， JMM会根据<code>重排序的规则</code>， 禁止特定类型的编译器重排序。</p>\n<p>2、对于<code>处理器</code>的重排序， Java编译器在生成指令序列的适当位置， 插入<code>内存屏障指令</code>， 来禁止特定类型的处理器排序。</p>\n</blockquote>\n<h4 id=\"原理\">原理</h4>\n<p>1、volatile 的底层实现原理是<code>内存屏障</code></p>\n<p>​\t1.1、对 volatile 变量的<code>写指令后</code>会加入<code>写屏障</code></p>\n<p>​\t1.2、对 volatile 变量的<code>读指令前</code>会加入<code>读屏障</code></p>\n<p>2、如何保证可见性</p>\n<p>​\t2.1、写屏障（sfence）保证在该屏障之<code>前</code>的，对共享变量的改动，<code>都同步到主存当中</code></p>\n<p>​\t2.2、读屏障（lfence）保证在该屏障之<code>后</code>，对共享变量的读取，<code>加载的是主存中最新数据</code></p>\n<p>3、如何保证有序性</p>\n<p>​\t3.1、写屏障会确保指令重排序时，不会将<code>写屏障之前</code>的代码排在<code>写屏障之后</code></p>\n<p>​\t3.2、读屏障会确保指令重排序时，不会将<code>读屏障之后</code>的代码排在<code>读屏障之前</code></p>\n<p>4、<code>volatile</code> 只能保证<code>有序性和可见性</code>不能解决指令交错：</p>\n<p>​\t4.1、<code>写屏障</code>仅仅是保证之后的读能够读到<code>最新</code>的结果，但不能保证其它线程的读跑到它前面去</p>\n<p>​\t4.2、<code>有序性</code>的保证也只是保证了<code>本线程内</code>相关代码<code>不被</code>重排序  ,线程间的需要由 <code>cpu分配的时间片决定</code></p>\n<p>5、 JMM 就将内存屏障插⼊策略分为 4 种</p>\n<p>​\t写屏障</p>\n<p>​\t<code>StoreStore</code> 屏障(写写屏障)     在每个 volatile <code>写操作的前</code>⾯插⼊⼀个 <code>StoreStore</code> 屏障；禁止上面的普通写与下面的volatile写重排序</p>\n<p>​\t<code>StoreLoad</code> 屏障(写读屏障)       在每个 <code>volatile 写操作的后</code>⾯插⼊⼀个 <code>StoreLoad</code> 屏障；防止上面volatile写与下面可能有的volatile读/写重排序</p>\n<p>​\t读屏障</p>\n<p>​\t<code>LoadLoad</code> 屏障(读读屏障)          在每个 <code>volatile</code> 读操作的<code>后</code>⾯插⼊⼀个 <code>LoadLoad</code> 屏障；禁止下面所有的普通读volatile读操作和上面的volatile读重排序</p>\n<p>​\t<code>LoadStore</code>屏障(读写屏障)         在每个 <code>volatile</code> 读操作的<code>后</code>⾯插⼊⼀个 <code>LoadStore</code> 屏障；禁止下面所有的<code>普通写/volatile写</code>操作和上面的<code>volatile读</code>重排序</p>\n<p><strong>volatile的底层实现是通过内存屏障</strong></p>\n<table>\n<thead>\n<tr>\n<th>第一个操作</th>\n<th>第二个操作：普通读写</th>\n<th>第二个操作：volatile读</th>\n<th>第二个操作：volatile写</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>普通读写</td>\n<td>普通读写</td>\n<td>可以重排</td>\n<td>不可以重排</td>\n</tr>\n<tr>\n<td>volatile读</td>\n<td>不可以重排</td>\n<td>不可以重排</td>\n<td>不可以重排</td>\n</tr>\n<tr>\n<td>volatile写</td>\n<td>可以重排</td>\n<td>不可以重排</td>\n<td>不可以重排</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p>当第一个操作为<code>volatilei读</code>时，不论第二个操作是什么，都<code>不能重排序</code>。这个操作保证了volatile<code>读之后</code>的操作<code>不会</code>被<code>重排</code>到volatile<code>读之前</code>。<br>\n当第二个操作为volatile写时，不论第一个操作是什么，都<code>不能重排序</code>。这个操作保证了volatile<code>写之前</code>的操作不会被<code>重排</code>到volatile<code>写之后</code>。<br>\n当第一个操作为volatile写时，第二个操作为volatile读时，不能重排。</p>\n</blockquote>\n<p><strong>volatile主要使用场景</strong></p>\n<ul>\n<li>用在一个线程写 其他多个线程读时的来保证可见性</li>\n<li>和<code>double-checked locking</code>模式中保证<code>synchronized</code>代码块外的共享变量的<code>指令重排序</code>问题</li>\n<li>单一赋值可以，但是含复合运算赋值不可以(i++之类)          最好是int或者boolean类型</li>\n<li>状态标志的时候，判断业务是否结束/开始</li>\n<li>开销较低的读，写锁策略；当读远多于写，结合使用内部锁和 volatile 变量来减少同步的开销（利用volatile保证读取操作的可见性；利用synchronized保证复合操作的原子性）</li>\n</ul>\n<blockquote>\n<p>其他情况还是要使用<code>synchronized</code></p>\n<p>==反复记忆==        volatile <code>仅仅</code>保证了共享变量的可见性，让其它线程能够看到最新值，但<code>不能解决指令交错</code>问题（不能保证原子性）</p>\n<p>不能保证原子性的原因：修改就是可见，为什么还不能保证原子性？</p>\n<p>1、要<code>use(使用)</code>一个变量的时候必需<code>load(载入）</code>，要载入的时候必需从主内存<code>read(读取）</code>这样就解决了读的可见性。<code> (load和user关联)</code></p>\n<p>2、写操作是把<code>assign</code>和<code>store</code>做了关联(在<code>assign</code>(赋值)后必需<code>store</code>(存储))。<code>store</code>(存储)后<code>write</code>(写入)。也就是做到了给一个变量赋值的时候一串关联指令直接把变量值写到主内存。<code>(assign和store关联)</code></p>\n<p>3、<code>用的</code>时候直接从主内存取，在<code>赋值</code>到直接写回主内存就可以保证做到内存可见。注意蓝色框框的间隙(但是<code>use</code>和<code>assign</code>直接仍然有有间隙)</p>\n<p>所以：</p>\n<p><code>read-load-use</code> 和 <code>assign-store-write</code> 成为了两个不可分割的原子操作，但是在<code>use</code>和<code>assign</code>之间依然有极小的一段<code>真空期</code>，有可能变量会被其他线程读取，导致写丢失一次</p>\n</blockquote>\n<h3 id=\"18、双检加锁\">18、双检加锁</h3>\n<p>&lt;单例模式懒汉式的一种&gt;</p>\n<p><strong>1、问题</strong> <code>double-checked locking </code>问题产生原因：</p>\n<p>​\t1、因为<code>synchronized</code>不能完全阻止重排序 ，【synchronized 并不能保证同步块外部的指令按照预期顺序执行，因此有可能会导致一些意外情况的发生，特别是在多线程的情况下】；</p>\n<p>​\t2、但是<code>volatile</code> 是可以阻止重排序的；就是说如果 <code>共享变量</code>完全被<code>synchronized</code>保护，那么<code>共享变量</code>是没有<code>原子  可见   有序 的问题的</code></p>\n<p>​\t3、所以出现问题就是因为<code>if(INSTANCE == null)</code>判断代码<code>没有</code>在同步代码块<code>synchronized</code>中,没有被完全保护的，发生了指令重排的现象，假设此时有两个线程在执行，<code>t1</code>还未完全将构造方法执行完毕，如果在构造方法中要执行很多<code>初始化</code>操作，那么 t2 拿到的是将是一个<code>未初始化完毕</code>的单例</p>\n<p><strong>2、解决</strong></p>\n<p><code>INSTANCE  加  volatile 修饰 就行了</code>,这个时候就会再读写的时候对指令加 <code>内存屏障</code>,不会有上述现象的产生</p>\n<p>具体而言就是：在读写 <code>volatile</code> 变量操作时会加入内存屏障，禁止了指令重排序&lt;<code>主要是写屏障</code>&gt;，解决了上述问题。</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">final</span> <span class=\"keyword\">class</span> <span class=\"title class_\">Singleton</span> &#123;</span><br><span class=\"line\">       <span class=\"keyword\">private</span> <span class=\"title function_\">Singleton</span><span class=\"params\">()</span> &#123; &#125;</span><br><span class=\"line\">       <span class=\"keyword\">private</span> <span class=\"keyword\">static</span> <span class=\"keyword\">volatile</span> <span class=\"type\">Singleton</span> <span class=\"variable\">INSTANCE</span> <span class=\"operator\">=</span> <span class=\"literal\">null</span>;</span><br><span class=\"line\">       <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> Singleton <span class=\"title function_\">getInstance</span><span class=\"params\">()</span> &#123;</span><br><span class=\"line\">           <span class=\"comment\">// 实例没创建，才会进入内部的 synchronized代码块</span></span><br><span class=\"line\">           <span class=\"keyword\">if</span> (INSTANCE == <span class=\"literal\">null</span>) &#123;</span><br><span class=\"line\">               <span class=\"keyword\">synchronized</span> (Singleton.class) &#123; <span class=\"comment\">// t2</span></span><br><span class=\"line\">                   <span class=\"comment\">// 也许有其它线程已经创建实例，所以再判断一次</span></span><br><span class=\"line\">                   <span class=\"keyword\">if</span> (INSTANCE == <span class=\"literal\">null</span>) &#123; <span class=\"comment\">// t1</span></span><br><span class=\"line\">                       INSTANCE = <span class=\"keyword\">new</span> <span class=\"title class_\">Singleton</span>();</span><br><span class=\"line\">                   &#125;</span><br><span class=\"line\">               &#125;</span><br><span class=\"line\">           &#125;</span><br><span class=\"line\">           <span class=\"keyword\">return</span> INSTANCE;</span><br><span class=\"line\">       &#125;</span><br><span class=\"line\">   &#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"19、Happens-before-先行发生原则\">19、Happens-before(先行发生原则)</h3>\n<blockquote>\n<p>内存屏障和先行发生原则之间的关系是：内存屏障可以被用于实现先行发生原则。通过在适当的位置插入内存屏障，可以限制指令重排序和内存访问的可见性，从而确保操作之间的 happens-before 关系</p>\n</blockquote>\n<p>就是规定了<code>对共享变量的写操作</code>对其它线程的<code>读操作可见</code>，它是可见性与有序性的一套<code>规则的总结</code>，抛开 happens-before 规则，<code>JMM 并不能保证一个线程对共享变量的写</code>，对于其它线程对<code>共享变量</code>的<code>读可见</code></p>\n<p>作用</p>\n<ul>\n<li>可以进行判断数据<code>是否存在竞争</code>，<code>线程是否安全</code>的非常有用的手段。</li>\n<li>依赖这个原则，我们可以通过几条简单规则简单直接的<code>判断</code>并发环境下两个操作之间<code>是否可能存在冲突的所有问题</code></li>\n</ul>\n<p>总原则</p>\n<ul>\n<li>如果一个操作<code>happens-before</code>另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</li>\n<li>两个操作之间存在<code>happens-before</code>关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照<code>happens-before</code>关系来执行的结果一致，那么这种重排序也是合法的。</li>\n</ul>\n<p>细分的8条原则</p>\n<ul>\n<li>\n<p>次序规则<br>\n一个线程内，按照代码顺序，写在前面的操作先行发生于写在后面的操作；(前一个操作的<code>结果</code>可以被后续的操作<code>获取</code>)</p>\n</li>\n<li>\n<p>锁定规则: 锁的获取的先后顺序<br>\n一个<code>unLock</code>操作先行发生于后面对同一个锁的<code>lock</code>操作；(对于同一把锁<code>objectLock</code>，<code>threadA</code>一定先<code>unlock</code>同一把锁后,<code>threadB</code>才能获得该锁， A 先行发生于B)              (这里的“后面”是指时间上的先后)</p>\n</li>\n<li>\n<p><code>volatile</code>变量规则<br>\n对一个<code>volatile</code>变量的写操作先行发生于后面对这个变量的读操作，前面的写对后面的读是可见的，这里的“后面”同样是指时间上的先后。</p>\n</li>\n<li>\n<p>传递规则<br>\n如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；</p>\n</li>\n<li>\n<p>线程启动规则(Thread Start Rule)<br>\nThread对象的<code>start()</code>方法先行发生于此线程的每一个动作</p>\n</li>\n<li>\n<p>线程中断规则(Thread Interruption Rule)</p>\n<p>对线程<code>interrupt()</code>方法的调用先行发生于被中断线程的代码<code>检测到中断事件的发生</code>；</p>\n<p>可以通过<code>Thread.interrupted()</code>检测到是否发生中断</p>\n</li>\n<li>\n<p>线程终止规则(Thread Termination Rule)<br>\n线程中的<code>所有操作</code>都<code>先行</code>发生于对此线程的<code>终止检测</code>，</p>\n<p>我们可以通过<code>Thread::join()</code>方法是否结束、<code>Thread::isAlive()</code>的<code>返回值</code>等手段检测线程是否已经终止执行。</p>\n</li>\n<li>\n<p>对象终结规则(Finalizer Rule)<br>\n一个对象的<code>初始化完成</code>（构造函数执行结束）先行发生于它的<code>finalize()</code>方法的开始(对象没有完成初始化之前，是不能调用<code>finalized()</code>方法的)</p>\n</li>\n</ul>\n<blockquote>\n<p>规则：</p>\n<ul>\n<li>\n<p>线程解锁 <code>m 之前</code>对变量<code>的写</code>，对于接下来对 <code>m 加锁</code>的其它线程对该变量的<code>读可见</code></p>\n</li>\n<li>\n<p>线程对 <code>volatile</code> 变量的写，对接下来其它线程对该变量的<code>读可见</code></p>\n</li>\n<li>\n<p>线程 <code>start</code> 前对变量的写，对该线程开始后对该变量的读可见</p>\n</li>\n<li>\n<p>线程结束前对变量的写，对其它线程得知它结束后的读可见（比如其它线程调用 t1.isAlive() 或 t1.join()等待它结束）</p>\n</li>\n<li>\n<p>线程 t1 打断<code> t2（interrupt）</code>前对变量的写，对于其他线程得知 <code>t2 被打断后</code>对变量的读可见（通过<code>t2.interrupted </code>或<code> t2.isInterrupted</code>）</p>\n</li>\n<li>\n<p>对变量默认值（0，false，null）的写，对其它线程对该变量的读可见</p>\n</li>\n<li>\n<p>具有传递性，如果 x -&gt; y 并且 y -&gt; z 那么有 x -&gt; z ，可以配合 volatile 的防指令重排</p>\n</li>\n<li>\n<p>如果一个操作执行的结果需要对另一个操作<code>可见性或者代码重排序</code>那么这两个操作<code>之间</code>必须存在<code>happens-before</code>关系</p>\n</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>happens-before总结</strong></p>\n<ul>\n<li>在Java 语言里面，<code>Happens-Before</code> 的语义<code>本质上</code>是一种<code>可见性</code></li>\n<li>A Happens-Before B意味着A发生过的事情对B来说是可见的，无论A事件和B事件是否发生在同一个线程里.</li>\n<li>JMM的设计分为两部分:\n<ul>\n<li>一部分是面向我们程序员提供的，也就是<code>happens-before</code>规则，它通俗易懂的向我们程序员阐述了一个<code>强内存模型</code>，我们只要理解<code>happens-before</code>规则，就可以编写并发安全的程序了。</li>\n<li>另一部分是针对JVM实现的，为了尽可能少的对编译器和处理器做约束从而提高性能，JMM在不影响程序执行结果的前提下对其不做要求，即<code>允许优化重排序</code>。</li>\n<li>我们只需要关注前者就好了,也就是理解happens-before规则即可，其它繁杂的内容有JMM规范结合操作系统给我们搞定，我们只写好代码即可。</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h2 id=\"无锁\">无锁</h2>\n<blockquote>\n<p>管程即<code>monitor</code>是阻塞式的<code>悲观锁</code>实现并发控制</p>\n<p>无锁 ： 基于<code>非阻塞式的乐观锁</code>的来<code>实现并发控制</code></p>\n</blockquote>\n<p><strong>无锁的效率为什么高</strong></p>\n<p>1、无锁情况下，<code>即使重试失败</code>，线程<code>始终在高速运行</code>，没有停歇</p>\n<p>2、相比于无锁，悲观锁 的机制  会 让线程在没有获得锁的时候，<code>就先发生上下文切换，进入阻塞状态</code></p>\n<h4 id=\"乐观锁和悲观锁\">乐观锁和悲观锁</h4>\n<p>1、<code>悲观锁</code>: 认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。</p>\n<p>​\t1.1、适合<code>写操作多</code>的场景,先加锁可以保证写操作时数据正确</p>\n<p>2、<code>乐观锁</code>:乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作</p>\n<p>​\t2.1、乐观锁一般有两种实现方式：</p>\n<ul>\n<li>采用<code>版本号机制</code></li>\n<li><code>CAS</code>（Compare-and-Swap，即比较并替换）算法实现</li>\n</ul>\n<p>​\t2.2、适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升</p>\n<h4 id=\"公平锁和非公平锁\">公平锁和非公平锁</h4>\n<p>1、公平锁：指多个线程<strong>按照申请锁的顺序来获取锁</strong>；优点是保证了资源的公平分配，避免了饥饿现象，确保每个线程都能获取锁</p>\n<p>2、非公平锁： 指多个<strong>线程获取锁的顺序并不是按照申请锁的顺序</strong>，有可能后申请的线程比先申请的线程优先获取锁，在高并发环境下，有可能造成优先级翻转或者饥饿的状态（某个线程一直得不到锁)；就是说  允许已经持有锁的线程再次获取锁，这样可以减少线程切换的开销，提高并发性能；非公平锁可能导致某些线程一直无法获取到锁，造成饥饿现象</p>\n<p>3、为什么默认为非公平锁</p>\n<p>​\t1、非公平锁的吞吐量要高于公平锁。这是因为非公平锁允许已经持有锁的线程再次获取锁，避免了线程切换的开销，提高了并发性能。</p>\n<p>​\t2、非公平锁可以利用CPU缓存的局部性原理，减少缓存竞争，提高缓存命中率，从而进一步提高性能。</p>\n<p>4、公平锁的问题</p>\n<p>​\t虽然保证了排队的公正性，不会造成饥饿的现象，但是一定程度上会增加线程的开销</p>\n<p>5、使用场景：</p>\n<p>​\t1、非公平锁：更高的吞吐量  +       资源竞争较少的场景（比如读多写少）</p>\n<p>​\t2、公平锁：资源的公平分配   +    需要严格控制线程的执行顺序</p>\n<h3 id=\"20、CAS\">20、CAS</h3>\n<p><strong>1、原子性保证的底层原理：</strong></p>\n<p>​\t1、CAS 的底层是<code> lock cmpxchg</code> 指令（X86 架构），在单核 CPU 和多核 CPU 下都能够<code>保证</code>【比较-交换】的<code>原子性</code>。</p>\n<p>​\t2、在多核状态下，<code>某个核</code>执行到带 <code>lock 的指令</code>时，<code>CPU 会让总线锁住</code>，当<code>这个核</code>把此指令执行完毕，再开启总线。这个过程中<code>不会被线程的调度机制所打断</code>，保证了多个线程对内存操作的准确性，<code>是原子的</code>。</p>\n<p><strong>2、特点</strong></p>\n<p>​\tCAS 必须借助 <code>volatile</code> 才能读取到<code>共享变量的最新值</code>来<code>实现</code>【<code>比较并交换</code>】的效果</p>\n<p><strong>3、介绍</strong></p>\n<p>​\t1、基于基于乐观“锁”的思想：最乐观的估计，不怕别的线程来修改共享变量，就算改了也没关系,重试就好。</p>\n<p>​\t2、CAS 操作包含三个操作数：内存位置（或称为变量）、预期值和新值。它的执行过程如下：</p>\n<p>​\t\t\t首先比较内存位置的当前值与预期值是否相等。如果相等，则将新值设置到内存位置中，并返回 true 表示更新成功。如果不相等，则表示其他线程已经修改了内存位置的值，CAS 操作失败，返回 false。</p>\n<h4 id=\"Unsafe类\">Unsafe类</h4>\n<p>强大又危险：</p>\n<p>强大：</p>\n<p>1、Unsafe是CAS核心类，由于Java方法无法直接访问底层系统，需要通过本地（native）方法来访问，Unsafe相当于一个后门,基于该类可以<code>直接操作</code>特定内存的数据。</p>\n<p>2、Unsafe类存在于<code>sun.misc</code>包中，其内部方法操作可以像C的指针一样<code>直接操作内存</code>，因为Java中CAS操作的执行依赖于Unsafe类的方法。</p>\n<p>3、直接内存操作：<code>Unsafe</code> 提供了一些方法来直接操作内存，如读写基本类型、分配和释放内存等。这使得开发者能够绕过 Java 的对象模型，直接对内存进行操作，以实现更高效的数据处理。</p>\n<p>4、对象实例化：<code>Unsafe</code> 可以通过绕过构造器来创建对象实例，即使构造器为私有或者受限制。这种能力可以用于实现单例模式、对象池等特殊的对象创建方式。</p>\n<p>5、数组操作：<code>Unsafe</code> 提供了对数组的操作方法，如获取数组元素的偏移地址、获取数组元素的大小等。这些方法可以用于在底层进行高效的数组操作。</p>\n<p>6、并发操作：<code>Unsafe</code> 提供了一些原子操作方法，如 CAS（Compare and Swap）等，用于实现线程安全的操作。这些方法可以用于实现自定义的并发数据结构和锁机制。</p>\n<p>危险：</p>\n<p>1、不受 Java 语言约束：<code>Unsafe</code> 的方法可以绕过 Java 语言的一些限制，如访问私有字段、绕过访问控制等。这可能导致代码的不可读性、不可维护性和安全性问题。</p>\n<p>2、内存管理风险：直接操作内存可能导致内存泄漏、越界访问等问题。使用 <code>Unsafe</code> 时需要特别小心，确保正确管理内存，以避免潜在的安全问题。</p>\n<p>3、平台依赖性：<code>Unsafe</code> 的功能在不同的 Java 虚拟机实现中可能有所不同。使用 <code>Unsafe</code> 时需要注意平台的兼容性和可移植性。</p>\n<blockquote>\n<p>注意<code>Unsafe</code>类中的所有方法都是<code>native</code>修饰的，也就是说<code>Unsafe</code>类中的方法都<code>直接调用</code>操作系统底层资源执行相应任务</p>\n</blockquote>\n<h3 id=\"21、原子类\">21、原子类</h3>\n<p>1、原子类的底层原理：  实现还是通过<code>cas</code>原理来进行实现的</p>\n<p>2、基本类型的原子类</p>\n<p>​\t对基本数据类型原子操作。包含三个：<code>AtomicInteger</code>：整型原子类（4字节）  +   <code>AtomicLong</code>：长整型原子类 （8字节）  +  <code>AtomicBoolean</code> ：布尔型原子类</p>\n<p>3、非基本类型的原子类</p>\n<p>​\t 1、<code>原子引用类</code>是一种原子类，用于对引用类型的原子操作 ；</p>\n<p>​\t\t\t作用：保证<code>引用类型</code>的<code>共享变量是线程安全</code>的。<code>基本类型原子类</code>只能更新一个变量，如果需要原子更新<code>多个变量</code>，需要使用<code>引用类型原子类</code>。</p>\n<p>​\t\t\t分类：</p>\n<p>​\t\t\t\t1、<code>AtomicReference</code>：引用类型原子类</p>\n<p>​\t\t\t\t2、<code>AtomicStampedReference</code>：原子<code>更新带有版本号</code>的引用类型。该类将<code>整数值与引用关联</code>起来，可用于解决原子的更新数据和数据的版本号，可以【加一个版本号】解决使用<code> CAS 进行原子更新</code>时<code>可能出现的 ABA 问题</code>。</p>\n<p>​\t\t\t\t3、<code>AtomicMarkableReference </code>：原子更新<code>带有标记</code>的引用类型。该类将<code> boolean 标记与引用关联</code>起来，也可以【引入一个额外的标志位】<code>一定程度上</code>解决使用 CAS 进行原子更新时可能出现的 ABA 问题。</p>\n<p>​\t 2、  <code> 原子数组类</code>是一种原子类，用于对数组类型的原子操作</p>\n<p>​\t\t\t作用：修改引用本身   或者     修改引用对象里面的内容： 比如数组: 想要 修改<code>数组对象</code>里面的值</p>\n<p>​\t\t\t分类:</p>\n<p>​\t\t\t\t1、<code>AtomicIntegerArray</code>：整形数组原子类</p>\n<p>​\t\t\t\t2、<code>AtomicLongArray</code>：长整形数组原子类</p>\n<p>​\t\t\t\t3、<code>AtomicReferenceArray</code>  ：引用类型数组原子类</p>\n<p>4、<code>字段更新器</code></p>\n<p>介绍：是一种原子类，用于对指定类的字段进行原子性的<code>更新操作</code>。它们通过反射来实现对字段的原子更新。</p>\n<p>作用：保护的是类里面的属性，成员变量，保证<code>多线程访问成员变量</code>时的线程安全性</p>\n<p>注意：利用字段更新器，可以针对<code>对象的某个域（Field）</code>进行原子操作，只能配合<code> volatile</code> 修饰的字段使用，否则会出现异常</p>\n<p>分类：<code>AtomicReferenceFieldUpdater</code>   域 字段 引用类型 [String  或者 Date() 等]  +   <code>AtomicIntegerFieldUpdater</code>  整型+   <code>AtomicLongFieldUpdater</code>  long型</p>\n<p>5、<code>原子累加器</code></p>\n<p>1、是原子类的一种特殊形式，专门用于对数值进行原子性的<code>累加操作</code>。例如，AtomicInteger 和 AtomicLong 类都是基本原子类，提供了对整数和长整数的原子操作。</p>\n<p>2、<code>longadder</code>的性能比较高的原因：</p>\n<ol>\n<li>分散的累加器：<code>LongAdder</code> 内部维护了一个数组，将累加操作分散到多个单元（cell）中，每个单元独立累加。这样可以减少线程之间的竞争，特别适用于高并发环境。而 <code>AtomicLong</code> 则是单个变量进行累加，容易出现线程之间的竞争。</li>\n<li>CAS 自旋：<code>LongAdder</code> 使用 CAS（比较并交换）操作来更新累加器的值。在竞争不激烈的情况下，CAS 操作通常能够成功，避免了线程的阻塞和切换。而 <code>AtomicLong</code> 在高并发情况下，由于竞争激烈，可能会导致较多的 CAS 失败，从而增加线程的阻塞和切换开销。</li>\n<li>缓存友好性：<code>LongAdder</code> 的数组单元在多核 CPU 中可以分布在不同的缓存行中，减少了缓存行的伪共享问题，提高了缓存的命中率。而 <code>AtomicLong</code> 由于是单个变量，容易引起缓存行的伪共享问题，从而影响性能。</li>\n</ol>\n<p><strong>3、Longadder</strong></p>\n<p>​\t1、原理：</p>\n<p>​\t1.1、<code>LongAdder</code> 内部维护了一个 <code>Cell</code> 数组，用于分段累加。</p>\n<p>​\t1.2、每个线程在进行累加操作时，通过哈希算法选择一个 <code>Cell</code> 进行累加。</p>\n<p>​\t1.3、使用 CAS 操作来更新 <code>Cell</code> 中的累加值，保证原子性。</p>\n<p>​\t1.4、如果更新失败，会进行重试或扩容。</p>\n<p>​\t1.5、如果 <code>Cell</code> 数组为空，会先尝试进行初始化，否则会更新 <code>base</code> 字段的值。</p>\n<blockquote>\n<ol>\n<li>分段累加：<code>LongAdder</code> 内部维护了一个数组，其中的每个元素称为一个单元（cell）。当需要进行累加操作时，线程会根据哈希算法选择一个单元，将累加操作分散到多个单元中进行。这样可以减少线程之间的竞争，提高并发性能。</li>\n<li>Cell 数组：<code>LongAdder</code> 的数组单元称为 Cell，每个 Cell 内部维护了一个累加值。初始情况下，<code>LongAdder</code> 会创建一个初始大小的 Cell 数组，每个 Cell 的初始值为 0。当需要进行累加操作时，线程会选择一个 Cell 进行累加。</li>\n<li>CAS 自旋：每个 Cell 内部使用 CAS（比较并交换）操作来更新累加值。在竞争不激烈的情况下，CAS 操作通常能够成功，线程不会被阻塞。如果 CAS 操作失败，说明有其他线程正在更新该 Cell 的累加值，此时会进行重试，直到成功为止。</li>\n<li>总和计算：当需要获取累加结果时，<code>LongAdder</code> 会将所有 Cell 的累加值进行求和，得到最终的累加结果。这个操作可能会涉及到对多个 Cell 的遍历，但由于 Cell 数组的分散累加，避免了大规模的竞争和线程阻塞。</li>\n</ol>\n</blockquote>\n<p>​\t2、longadder为什么快：</p>\n<p>​\t\t2.1、分段累加：<code>LongAdder</code> 内部使用了一种分段的累加策略。它将一个长整型的值拆分为多个小段，每个小段都由一个独立的变量来维护。不同线程在累加时，可以独立地操作不同的小段，避免了多线程竞争的问题，从而提高了并发性能。</p>\n<p>​\t\t2.2、竞争减少：由于分段累加的策略，<code>LongAdder</code> 在高并发情况下减少了线程之间的竞争。每个线程在累加时只需要操作自己负责的小段，而不需要与其他线程进行竞争。这样可以减少锁冲突和线程调度的开销，提高了整体的性能。</p>\n<p>​\t\t2.3、自适应调整：<code>LongAdder</code> 还具有自适应调整的特性。当某个小段的竞争较激烈时，<code>LongAdder</code> 会自动增加小段的数量，以减少竞争，提高性能。这种动态调整的机制可以根据实际的并发情况来优化性能。</p>\n<p>6、CAS的问题</p>\n<p>​\t1、ABA问题</p>\n<p>​\t2、循环时间长开销很大：如果CAS失败，会一直进行尝试。如果CAS长时间一直不成功，可能会给CPU带来很大的开销。</p>\n<blockquote>\n<p>ABA问题：</p>\n<p>1、指的是在某个线程执行过程中，某个变量的值从 A 变成 B，又从 B 变成 A，而其他线程在此期间对这个变量进行了修改，导致这些修改没有被检测到。这种情况下，使用 CAS 操作时可能会出现误判，因为 CAS 操作只能比较对象引用是否相等，而无法判断其中的值是否发生过变化。</p>\n<p>2、使用<code>AtomicStampedReference</code>来解决： 只需要再<code>加一个版本号</code>。但是有时候，并不关心引用变量改变了几次，只是单纯的关心是否更改过，所以就有了<code>AtomicMarkableReference   </code></p>\n</blockquote>\n<p>我们知道i++线程不安全的，那<code>atomicInteger.getAndIncrement()</code>为什么能够通过CAS保证原子性呢?</p>\n<p>1、AtomicInteger 类主要利用<code> CAS  + volatile 和 native 方法</code>来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。</p>\n<p>2、CAS并发原语<code>体现在</code>JAVA语言中就是<code>sun.misc.Unsafe</code>类中的各个方法。</p>\n<p>3、调用UnSafe类中的CAS方法，JVM会帮我们实现出<code>CAS汇编指令</code>。这是一种<code>完全依赖于硬件的功能</code>，通过它实现了原子操作。</p>\n<p>4、由于CAS是一种系统原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，所以不会造成所谓的数据不一致问题。</p>\n<p>5、<code>getAndIncrement()</code>方法中实现了通过调用<code>unsefe</code>类的<code>compareAndSwapInt</code>本地方法和<code>自旋</code>的方式来实现<code>CAS</code></p>\n<h2 id=\"线程安全类\">线程安全类</h2>\n<h3 id=\"22、JUC下的线程安全类\">22、JUC下的线程安全类</h3>\n<p><strong>1、分类：</strong></p>\n<p>​\t1、遗留的<code>线程安全</code>集合如<code> Hashtable ， Vector</code></p>\n<p>​\t2、使用 <code>Collections 装饰</code>的线程安全集合，</p>\n<p>​\t3、<code>java.util.concurrent.* </code> 下的线程安全集合类，可以发现它们有规律，里面包含三类关键词：<code>Blocking、CopyOnWrite、Concurrent</code></p>\n<p>​\t\t3.1、<code>Blocking</code> 大部分实现<code>基于锁</code>，并提供用来<code>阻塞的方法</code></p>\n<p>​\t\t3.2、<code>CopyOnWrite</code> 之类容器修改开销相对较重,用于<code>读多写少</code>的时候</p>\n<p>​\t\t3.3、<code>Concurrent </code>类型的容器</p>\n<p><strong>2、concurrentHashmap</strong></p>\n<p>Java 8 数组（Node） +（ 链表 Node | 红黑树 TreeNode ）</p>\n<p>以下数组简称（table），链表简称（bin）</p>\n<ul>\n<li>初始化，使用 cas 来保证并发安全，懒惰初始化 table</li>\n<li>树化，当 table.length &lt; 64 时，先尝试扩容，超过 64 时，并且 bin.length &gt; 8 时，会将链表树化，树化过程会用 synchronized 锁住链表头</li>\n<li>put，如果该 bin 尚未创建，只需要使用 cas 创建 bin；如果已经有了，锁住链表头进行后续 put 操作，元素添加至 bin 的尾部</li>\n<li>get，无锁操作仅需要保证可见性，扩容过程中 get 操作拿到的是 ForwardingNode 它会让 get 操作在新table 进行搜索</li>\n<li>扩容，扩容时以 bin 为单位进行，需要对 bin 进行 synchronized，但这时妙的是其它竞争线程也不是无事可做，它们会帮助把其它 bin 进行扩容，扩容时平均只有 1/6 的节点会把复制到新 table 中</li>\n<li>size，元素个数保存在 baseCount 中，并发时的个数变动保存在 CounterCell[] 当中。最后统计数量时累加即可</li>\n</ul>\n<p><strong>3、 <code>ConcurrentLinkedQueue</code>并发队列</strong></p>\n<p><code>ConcurrentLinkedQueue</code> 的设计与 <code>LinkedBlockingQueue</code> 非常像</p>\n<ul>\n<li>\n<p>也是两把【锁】，同一时刻，可以允许两个线程同时（一个生产者与一个消费者）执行</p>\n</li>\n<li>\n<p><code>dummy</code> 节点的引入让两把【锁】将来锁住的是不同对象，避免竞争</p>\n</li>\n<li>\n<p>只是这【锁】使用了<code>cas</code>来实现</p>\n</li>\n</ul>\n<p>事实上，<code>ConcurrentLinkedQueue</code> 应用还是非常广泛的</p>\n<p><strong>4、CopyOnWriteArrayList</strong></p>\n<p><strong>1、<strong>它相当于线程安全版的 <code>ArrayList</code>。但是又有一些</strong>特性</strong></p>\n<ol>\n<li>线程安全：<code>CopyOnWriteArrayList</code> 是线程安全的，读操作无需加锁，写操作通过复制机制保证线程安全。</li>\n<li>读写分离：读操作不受写操作的影响，可以并发执行，提高了读操作的性能。</li>\n<li>弱一致性：由于写操作会创建新的数组，读操作可能会读到旧的数据，因此在写操作完成后，读操作可能会看到一个过期的数据快照。</li>\n</ol>\n<p><strong>2、使用场景</strong></p>\n<ol>\n<li>读多写少：<code>CopyOnWriteArrayList</code> 适用于读操作频繁、写操作较少的场景，可以提高读操作的性能。</li>\n<li>高并发读取：由于读操作无需加锁，可以支持高并发读取，适用于需要快速读取数据的场景。</li>\n<li>不需要实时更新的数据：<code>CopyOnWriteArrayList</code> 的写操作需要复制整个数组，适用于不需要实时更新数据的场景，例如读取配置信息、缓存数据等。’</li>\n</ol>\n<p><strong>3、如何 解决独占锁效率低</strong></p>\n<p>​\t1、读写分离：就是将读操作和写操作分离，让读操作可以并发执行，而不需要加锁。这样可以提高读操作的性能，因为多个线程可以同时读取数据而不会相互影响。而写操作仍然需要获取独占锁，确保写操作的原子性和线程安全性。</p>\n<p>​\t2、使用复制的思想： 就是在写操作时，不直接在原容器上进行修改，而是创建一个新的容器，将原容器的数据复制到新容器中，然后在新容器上进行修改。最后，再将原容器的引用指向新容器。这样做的好处是，读操作可以继续访问原容器的数据，不会受到写操作的影响，实现了读写分离。同时，通过复制操作，不会影响正在进行的读操作，并且在写操作完成后，可以快速切换到新容器，提高写操作的效率</p>\n<p>​\t3、CopyOnWriteArrayList 在使用复制的思想的时候</p>\n<p>​\t\t1、遇到的问题</p>\n<p>​\t\t数据不一致的问题。由于复制操作是在新容器上进行的，而读操作可能会访问到旧容器的数据，因此在写操作完成之前，其他线程可能会读取到脏数据或过期数据。如果写线程还没来得及写回内存，其他的线程就会读到了脏数据。</p>\n<p>​\t\t2、解决</p>\n<p>​\t\t 1、<code>写操作完成后再进行切换</code>：在写操作完成后再将原容器的引用指向新容器，确保读操作访问到的是最新的数据。可以保证数据的一致性，但会引入写操作的延迟</p>\n<p>​\t\t2、<code>使用读写锁</code>：通过使用读写锁，在写操作期间阻塞其他的读操作，直到写操作完成。这样可以避免其他线程读取到脏数据，但会降低读操作的并发性能</p>\n<p>​\t\t3、<code>使用版本号或标记</code>：在新容器中引入一个版本号或标记，读操作在访问数据时检查版本号或标记，如果不一致则重新读取。可以避免读取脏数据，但会增加一些额外的开销</p>\n<p><strong>4、CopyOnWriteArrayList 的核心思想</strong></p>\n<p>​\t是在写操作时创建一个新的数组来修改数据，从而实现读写分离，保证读操作的线程安全性，而不需要使用显式的锁机制；就是说底层实现采用了<code>写入时拷贝</code>的思想，<code>(写入)增删改操作</code>会将底层数组拷贝一份，更改操作在<code>新数组</code>上执行，这时不影响其它线程的<code>并发读，读写分离</code>。 所有的<code>读操作</code>并未加锁</p>\n<p><strong>5、原理</strong></p>\n<p><strong>5.1、基于动态数组的机制而言</strong></p>\n<ul>\n<li><code>CopyOnWriteArrayList</code> 内部使用一个数组（<code>volatile</code> 数组）来存储元素，每当有写操作（如添加、修改、删除）时，会创建一个新的数组，将原数组的数据复制到新数组中，并在新数组上进行修改操作。<code>CopyOnWriteArrayList</code> 效率很低；但是单单只是进行遍历查找的话，效率比较高。</li>\n<li>在写操作期间，读操作仍然可以访问原来的旧数组，即读操作不受写操作的影响，实现了读写分离。</li>\n<li>当写操作完成后，<code>CopyOnWriteArrayList</code> 将使用新数组替换旧数组，使得后续的读操作可以访问到最新的数据。</li>\n<li>由于读操作不需要加锁，所以读操作可以并发执行，提高了读操作的性能。</li>\n<li>写操作虽然需要创建新的数组，但是写操作是在新数组上进行的，不会影响正在进行的读操作，所以写操作的性能相对较低，适用于写操作较少的场景。</li>\n</ul>\n<p><strong>5.2、基于线程安全机制而言</strong></p>\n<p>通过 <code>volatile</code> 和<code>互斥锁</code>来实现的。</p>\n<p>​\t1、 通过<code>volatile</code> 数组来保存数据的。一个线程读取 volatile 数组时，总能看到其它线程对该 <code>volatile</code> 变量最后的写入；这样，通过 <code>volatile</code> 提供了<code>读取到的数据</code>总是<code>最新的</code>这个机制的保证。</p>\n<p>​\t2、通过<code>互斥锁</code>来保护数据。在<code>添加/修改/删除</code>数据时，会先<code>获取互斥锁</code>, 修改完毕之后，先将数据更新到<code>volatile 数组</code>中，然后再<code>释放互斥锁</code>，就达到了保护数据的目的。</p>\n<h3 id=\"23、安全性分析\">23、安全性分析</h3>\n<p><strong>5、变量安全性分析</strong></p>\n<blockquote>\n<p>类里面定义的是<code>成员</code>变量\t\t；\tstatic 修饰的是 <code>静态</code>变量     ；\t\t方法内部或代码块内部的是<code>局部</code>变量</p>\n</blockquote>\n<p>​\t成员变量和静态变量的线程安全分析： 如果没有变量在线程间共享，那么变量是安全的；如果变量在线程间共享，如果<code>只有读</code>操作，则<code>线程安全</code>；如果<code>有读写</code>操作，则这段代码是<code>临界区</code>，需要<code>考虑线程安全</code></p>\n<p>​\t局部变量线程安全分析；局部变量【局部变量被初始化为基本数据类型】是安全的；局部变量<code>引用的对象</code>未必是安全的；如果局部变量引用的对象<code>没有引用线程</code>共享的对象，那么是线程<code>安全的</code>；如果局部变量引用的对象<code>引用了线程共享的对象</code>，那么线程安全要看情况而定</p>\n<h3 id=\"24、Java安全类\">24、Java安全类</h3>\n<p>​\t<strong>6、线程安全的类</strong></p>\n<blockquote>\n<p>这里说它们是线程安全的是指，<span style=\"color:red\">多个线程调用它们同一个实例的某个方法时，是线程安全的</span>。</p>\n<p>==注意==： 可以理解为它们的每个方法<code>单独</code>使用都是原子的；但<strong>注意</strong>它们多个方法的<code>组合</code>不是原子的</p>\n</blockquote>\n<p>1、<code>String</code>   不可变的类,因为其类内部状态（属性）是<code>不可改变</code>的，因此它们的方法都是线程安全的</p>\n<p>2、<code>Integer等包装类</code>   不可变的类，因为其类内部状态（属性）是<code>不可改变</code>的，因此它们的方法都是线程安全的</p>\n<p>3、<code>StringBuffer</code>     4、<code>Random</code>    5、<code>Vector</code>    6、<code>Hashtable</code>   7、<code>java.util.concurrent (JUC)包下的类</code>    8、<code>String 串池机制</code></p>\n<p>9、<code>BigDecimal      BigInteger</code>    10、<code>没有任何成员变量的</code>类是线程安全的,又称为  <code>无状态（指的就是没有成员变量）的类是安全的</code></p>\n<p>11、<code>DateTimeFormatter</code> 日期类</p>\n<blockquote>\n<p>解决线程安全问题</p>\n</blockquote>\n<blockquote>\n<p>之前： 未使用  <code>ThreadLocal</code>之前解决线程安全的问题—<code>synchronized</code>加锁的方式来解决并发问题</p>\n<p>现在： 使用  <code>ThreadLocal</code>之前解决线程安全的问题—不加锁同样也可以解决线程安全问题</p>\n</blockquote>\n<h3 id=\"25、ThreadLocal\">25、ThreadLocal</h3>\n<p>1、介绍：</p>\n<p>​\t<code>ThreadLocal</code>为线程提供局部变量。这些变量与正常的变量不同，因为每一个线程在访问ThreadLocal实例的时候（通过其get或set方法）都有自己的、独立初始化的变量副本。ThreadLocal实例通常是类中的私有静态字段，使用它的目的是希望将状态（例如，用户ID或事务ID）与线程关联起来。</p>\n<p>2、作用：</p>\n<p>​\t使得每一个线程都有自己专属的本地变量副本，主要<strong>解决了让每个线程绑定自己的值，通过使用get()和set()方法，获取默认值或将其值更改为当前线程所存的副本的值从而避免了线程安全问题。</strong></p>\n<p>​</p>\n<p>3、和synchrnized 的对比：<br>\n1、相同点<code>ThreadLocal</code>和<code>Synchonized</code>都用于解决多线程并发访问</p>\n<p>​\t2、不同点:\t<code>synchronized</code>是利用锁的机制，使变量或代码块在某一时该只能被一个线程访问,用于在多个线程间通信时能够获得数据共享。</p>\n<p>​\t\t\t\tThreadLocal为每一个线程都提供了变量的副本，使得每个线程在某一时间访问到的并不是同一个对象，隔离了多个线程对数据的数据共享。</p>\n<p>4、总结：</p>\n<p>​\t1、每个 Thread 内有自己的<code>实例副本</code>且该副本<code>只由</code>当前线程自己使用</p>\n<p>​\t2、其它 线程 不可访问本线程的变量，就<code>不存在多线程间</code>共享的问题</p>\n<p>​\t3、可以统一设置初始值，但是每个线程对这个值的修改都是各自线程互相独立的</p>\n<p>​\t4、必须回收自定义的<code>ThreadLocal</code>变量，尤其在<strong>线程池场景</strong>下，线程经常会被<strong>复用</strong>，如果不清理自定义的<code>ThreadLocal</code>变量，可能会影响后序业务逻辑和造成<strong>内存泄露</strong>等问题。尽量在代理中使用<code>try-finally</code>块进行回收。</p>\n<p>​\t5、需要使用remove方法：因为<strong>如果<code>ThreadLocal</code>在线程复用的情况下执行完成后<code>不</code>进行<code>remove</code>,那么当该线程再次拿到任务时,上一次的<code>ThreadLocal</code>还在该线程中,出现如下效果,<code>数字越来越大</code>,最后<code>极端情况线程会爆</code></strong></p>\n<p>5、内存泄露问题</p>\n<p>​\t1、 什么是内存泄漏?\t\t\t不再会被使用的对象或者变量<code>占用的内存不能被回收</code>，就是内存泄露</p>\n<p>​\t2、为什么会导致内存泄漏?    <code>ThreadLocalMap</code> 中有一个静态内部类<code>Entry</code> ,而这个类继承了<code>弱引用</code>,那么这个类的实例对象就是<code>弱引用</code>的</p>\n<p>​</p>\n<p>6、<code> ThreadLocalMap</code>源码中为什么要使用弱引用?</p>\n<p>当方法执行完毕后，栈帧销毁<code>强引用</code> t1 也就没有了。但此时线程的<code>ThreadLocalMap</code>里某个<code>entry</code>的<code>key</code>引用还指向这个对象</p>\n<ul>\n<li>若这个<code>key</code>引用是<code>强</code>引用，就会导致<code>key</code>指向的<code>ThreadLocal</code>对象及指向的对象不能<code>被gc回收</code>，造成内存泄漏；</li>\n<li>若这个<code>key</code>引用是<code>弱</code>引用就大概率会减少内存泄漏的问题(但还有一个key为null的类)。使用弱引用，就可以使ThreadLocal对象在方法执行完毕后顺利被回收且Entry的key引用指向为null。</li>\n</ul>\n<p>7、ThreadMap</p>\n<p>​\t<code>ThreadLocal</code>能实现了线程的<code>数据隔离</code>，<code>不在于</code>它自己本身，<code>而在于</code>Thread的<code>ThreadLocalMap</code>所以，ThreadLocal可以只初始化一次，只分配一块存储空间就足以了，没必要作为成员变量多次被初始化。</p>\n<p>​\t1、<code>ThreadLocalMap</code>从字面上就可以看出这是一个保存<code>ThreadLocal</code>对象的<code>map</code>(其实是以<code>ThreadLocal</code>为<code>Key</code>),不过是经过了两层包装的<code>ThreadLocal</code>对象</p>\n<p>​\t\t1.1、第一层包装是使用 <code>WeakReference&lt;ThreadLocal&lt;?&gt;&gt; </code>将<code>ThreadLocal</code>对象变成一个弱引用的对象；</p>\n<p>​\t\t1.2、第二层包装是定义了一个专门的类 <code>Entry</code> 来扩展<code> WeakReference&lt;ThreadLocal&lt;?&gt;&gt;</code>：</p>\n<p>​\t2、<code>threadLocalMap</code>实际上就是一个以<code>threadLocal</code>实例为<code>key</code>，任意对象为<code>value</code>的<code>Entry</code>对象。</p>\n<p>​\t3、当我们为<code>threadLocal</code>变量赋值，实际上就是以当前<code>threadLocal</code>实例为<code>key</code>，值为<code>value</code>的<code>Entry</code>往这个<code>threadLocalMap</code>中存放</p>\n<p>​\t4、JVM内部维护了一个线程版的<code>Map&lt;Thread,T&gt;</code>(通过ThreadLocal对象的set方法，结果把ThreadLocal对象自己当做key，放进了ThreadLoalMap中),每个线程要用到这个T的时候，用当前的线程去Map里面获取，通过这样让每个线程都拥有了自己独立的变量，竞争条件被彻底消除，在并发模式下是绝对安全的变量</p>\n<p>8、ThreadLocal Thread   ThreadMap 三者的关系</p>\n<p>​\t1、每个<code>Thread</code>对象维护着一个<code>ThreadLocalMap</code>的引用</p>\n<p>​\t2、<code>ThreadLocalMap</code>是<code>ThreadLocal</code>的内部类，用<code>Entry</code>来进行存储</p>\n<p>​\t3、调用<code>ThreadLocal</code>的<code>set()</code>方法时，实际上就是往<code>ThreadLocalMap</code>设置值，<code>key</code>是<code>ThreadLocal</code>对象，值<code>Value</code>是传递进来的对象</p>\n<p>​\t4、调用<code>ThreadLocal</code>的<code>get()</code>方法时，实际上就是往<code>ThreadLocalMap</code>获取值，<code>key</code>是<code>ThreadLocal</code>对象</p>\n<p>​\t5、<code>ThreadLocal</code>本身并不存储值，它只是自己作为一个<code>key</code>来让线程从<code>ThreadLocalMap</code>获取<code>value</code>，正因为这个原理，所以<code>ThreadLocal</code>能够实现<code>数据隔离</code>，获取当前线程的局部变量值，不受其他线程影响</p>\n<h2 id=\"模式\">模式</h2>\n<ul>\n<li>循环交替打印</li>\n<li>固定运行顺序打印</li>\n</ul>\n<p>……</p>\n<h2 id=\"面试\">面试</h2>\n<p><strong>JVM 对 Java 的原生锁（synchronized 关键字）进行了多项优化，以提高锁的性能和效率</strong></p>\n<p>1、偏向锁（Biased Locking）：JVM 会在对象头中记录锁的偏向线程 ID，以偏向锁的形式来实现同步。当只有一个线程访问同步块时，JVM 会假设该锁只会被该线程访问，将锁标记为偏向锁。这样，在后续的同步操作中，该线程可以无需竞争锁，减少了锁的开销。</p>\n<p>2、轻量级锁（Lightweight Locking）：当有多个线程竞争同一个锁时，JVM 会将偏向锁升级为轻量级锁。轻量级锁使用 CAS（Compare and Swap）操作来实现线程之间的互斥访问，避免了用户态和内核态之间的切换，减少了锁的开销。</p>\n<p>3、自旋锁（Spin Locking）：如果轻量级锁的竞争仍然存在，JVM 会使用自旋锁来避免线程的阻塞和切换。自旋锁会让线程进行一定次数的忙等待，尝试获取锁，而不是立即进入阻塞状态。这种优化适用于锁竞争短暂的情况，能够减少线程切换的开销。</p>\n<p>4、锁消除（Lock Elimination）：JVM 在编译时会进行锁消除的优化。当编译器分析到某个锁对象不可能被其他线程访问到时，会将相关的同步代码块或方法中的锁消除，从而避免不必要的锁操作，提高性能。</p>\n<p>5、锁粗化（Lock Coarsening）：JVM 在编译时也会进行锁粗化的优化。当编译器检测到多个连续的同步操作都对同一个对象加锁解锁时，会将这些同步操作合并为一个更大的同步块，减少锁操作的次数，提高性能。</p>\n<p><strong>可重入性</strong></p>\n<p>可重入性是指同一个线程在持有锁的情况下，可以再次获取该锁而不会被阻塞。当一个线程已经持有某个锁时，再次请求该锁时会立即成功，而不会被自己所持有的锁所阻塞。</p>\n<p><strong>为什么说Synchronized是可重入锁</strong></p>\n<p>Synchronized 是可重入锁的一种实现。当一个线程获取了某个对象的 Synchronized 锁之后，它可以再次请求该对象的 Synchronized 锁，而不会被阻塞。这是因为 Synchronized 内部使用了一个计数器来记录锁的持有次数，当计数器为0时，表示锁被释放，其他线程可以获取该锁。</p>\n<p><strong>Reentrant Lock是如何实现可重入性的?</strong></p>\n<p>使用一个计数器来记录锁的持有次数。当一个线程第一次获取锁时，计数器加1；当同一个线程再次获取锁时，只需将计数器再加1。只有当计数器归零时，锁才会完全释放。这样，同一个线程在持有锁的情况下，可以再次获取该锁而不会被阻塞，从而实现了可重入性。这种机制使得代码可以方便地进行递归调用或者在多个层次上进行加锁，提供了更大的灵活性和便利性。</p>\n<p><strong>Synchronized原理是什么</strong></p>\n<p>Synchronized 的原理是基于对象的监视器（monitor）实现的。每个对象都有一个与之关联的监视器，当一个线程进入 Synchronized 代码块时，它会尝试获取该对象的监视器，如果监视器的计数器为0，表示没有其他线程持有该锁，那么该线程就会成功获取锁并将计数器加1；如果计数器不为0，表示已有其他线程持有该锁，那么该线程就会被阻塞，直到计数器为0时才能获取锁。</p>\n<p><strong>乐观锁一定就是好的吗</strong></p>\n<p>乐观锁并不一定就是好的。乐观锁是一种乐观的并发控制机制，它假设并发冲突的概率较低，因此不会阻塞线程，而是通过版本号、时间戳等机制来检测数据是否被修改。如果检测到数据被修改，则需要回滚操作并重新尝试。</p>\n<p>乐观锁适用于读多写少的场景，能够提高并发性能。然而，在高并发、写操作频繁的情况下，乐观锁可能会导致大量的冲突和重试，降低性能。此时，悲观锁（如悲观读锁和悲观写锁）可能更适合，它通过阻塞和排他性的方式来保证数据的一致性。因此，选择合适的并发控制机制需要根据具体的场景和需求进行评估和选择。</p>\n<p><strong>跟Synchronized相比，可重入锁Reentrant Lock其实现原理有什么不同?</strong></p>\n<ul>\n<li>ReentrantLock 是显式锁，需要手动获取和释放锁，而 Synchronized 是隐式锁，由 JVM 自动管理。</li>\n<li>ReentrantLock 提供了更多的功能和灵活性，如可中断锁、可设置超时时间、公平性等，而 Synchronized 不具备这些特性。</li>\n<li>ReentrantLock 使用了 AQS（AbstractQueuedSynchronizer）框架来实现锁的底层机制，而 Synchronized 则直接依赖于 JVM 的内部实现。</li>\n</ul>\n<p><strong>那么请谈谈AQS框架是怎么回事儿?</strong></p>\n<p>一个用于构建锁和同步器的框架。它提供了一组基础的同步操作，如获取锁、释放锁、阻塞线程等，以及一些底层的状态管理机制。AQS 使用了一个等待队列（由节点组成）来管理等待获取锁的线程，通过 CAS 操作来保证线程的互斥和有序性。ReentrantLock 就是基于 AQS 实现的，它通过继承 AQS 并重写其中的方法来实现锁的具体逻辑。</p>\n<p>流程：</p>\n<ol>\n<li>定义同步器的状态（state）和等待队列（queue）。</li>\n<li>线程通过 acquire 方法尝试获取锁。如果锁已被占用，则线程会被加入到等待队列中，进入等待状态。</li>\n<li>释放锁时，线程通过 release 方法释放锁并唤醒等待队列中的下一个线程。</li>\n</ol>\n<p><strong>请尽可能详尽地对比下Synchronized和Reentrant Lock的异同</strong></p>\n<p>相同点：</p>\n<ul>\n<li>都是用于实现线程之间的同步和互斥。</li>\n<li>都是可重入锁，同一个线程可以多次获取同一个锁。</li>\n<li>都提供了可见性和原子性的保证。</li>\n</ul>\n<p>不同点：</p>\n<ul>\n<li>Synchronized 是隐式锁，由 JVM 自动管理，而 ReentrantLock 是显式锁，需要手动获取和释放。</li>\n<li>ReentrantLock 提供了更多的高级功能，如可中断锁、可设置超时时间、公平性等。</li>\n<li>ReentrantLock 可以替代 Synchronized，但 Synchronized 无法替代 ReentrantLock 的所有功能。</li>\n<li>ReentrantLock 的性能相对较好，在高并发和竞争激烈的场景下比 Synchronized 更灵活和高效。</li>\n</ul>\n<p><strong>hashmap的hash冲突怎么解决?为什么使用红黑树?</strong></p>\n<p>冲突解决：由于哈希函数的映射空间有限，不同的键可能映射到相同的索引位置，这就是哈希冲突。HashMap 使用链表和红黑树来解决哈希冲突。</p>\n<ul>\n<li>链表：当发生哈希冲突时，新的键值对会添加到冲突位置的链表末尾。当链表长度超过一定阈值（默认为8）时，链表会转换为红黑树，提高查找效率。</li>\n<li>红黑树：当链表长度超过阈值时，链表会转换为红黑树。红黑树是一种自平衡的二叉搜索树，它的插入、删除和查找操作的时间复杂度都是 O(log n)。这样可以在具有大量冲突的桶中，提高查找效率。</li>\n</ul>\n<p>使用红黑树的原因是</p>\n<p>​\t当发生哈希冲突时，链表的查找效率较低，因为需要遍历整个链表才能找到目标节点。而红黑树作为一种高效的自平衡二叉搜索树，可以提供更快的查找、插入和删除操作。因此，当链表长度超过阈值时，HashMap 会将链表转换为红黑树，以提高查找效率，从而保持 HashMap 的高性能。</p>\n<p><strong>spring循环依赖怎么解决?</strong></p>\n<p>在 Spring Boot 中，循环依赖通常指的是两个或多个 Bean 之间相互依赖，形成了循环引用的情况。Spring Boot 提供了两种解决循环依赖的方式：</p>\n<ol>\n<li>构造器注入（Constructor Injection）：通过构造器注入可以解决循环依赖的问题。在构造器注入中，Bean 的依赖通过构造函数的参数传递，而不是通过属性注入。这样，即使出现循环依赖，因为构造函数在创建对象时就会立即调用，所以能够避免循环依赖的问题。</li>\n<li>@Lazy 注解：通过在循环依赖的其中一个 Bean 上添加 <code>@Lazy</code> 注解，可以延迟加载该 Bean，从而解决循环依赖。<code>@Lazy</code> 注解告诉 Spring 延迟加载 Bean，直到第一次使用时才进行初始化。这样，在循环依赖的情况下，当一个 Bean 被延迟加载时，另一个 Bean 已经初始化完成，从而避免了循环依赖的问题。</li>\n</ol>\n<p><strong>ThreadLocal中ThreadLocalMap的数据结构和关系？</strong></p>\n<p>在 ThreadLocal 中，每个线程都有一个对应的 ThreadLocalMap，ThreadLocalMap 是 ThreadLocal 的内部类。ThreadLocalMap 使用<code>数组</code>实现，每个数组元素是一个 Entry 对象，Entry 对象包含了一个弱引用的 ThreadLocal 对象和对应的值。</p>\n<p><strong>ThreadLocal的key是弱引用，这是为什么？</strong></p>\n<p>这是为了防止内存泄漏。如果 ThreadLocal 的 key 是强引用，当 ThreadLocal 对象被回收时，如果没有手动调用 remove 方法将对应的 Entry 从 ThreadLocalMap 中移除，那么 Entry 对象将无法被垃圾回收，从而导致内存泄漏。使用弱引用的 key 可以解决这个问题，当 ThreadLocal 对象被垃圾回收时，对应的 Entry 对象也会被自动清理。</p>\n<p><strong>ThreadLocal<a href=\"https://so.csdn.net/so/search?q=%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F&amp;spm=1001.2101.3001.7020\">内存泄漏</a>问题你知道吗？</strong></p>\n<p>ThreadLocal 内存泄漏问题指的是在使用 ThreadLocal 时，如果没有手动调用 remove 方法，可能会导致 ThreadLocalMap 中的 Entry 对象一直存在，从而造成内存泄漏。这种情况发生在 ThreadLocal 被声明为静态变量或长时间持有的情况下。为了避免内存泄漏，使用 ThreadLocal 后应当在不再需要时手动调用 remove 方法，将 Entry 对象从 ThreadLocalMap 中移除。</p>\n<p><strong>ThreadLocal中最后为什么要加remove方法？</strong></p>\n<p>ThreadLocal 中加入 remove 方法是为了避免内存泄漏。通过调用 remove 方法，可以立即清理 ThreadLocalMap 中对应的 Entry 对象，释放相关的资源。在线程池等长时间运行的环境下，如果不手动调用 remove 方法，可能会导致 ThreadLocalMap 中的 Entry 对象一直存在，从而造成内存泄漏。因此，建议在使用 ThreadLocal 后及时调用 remove 方法，以确保资源的释放和避免内存泄漏问题的发生。</p>\n<p><strong>Java对象内存布局和对象头</strong></p>\n<p>Java对象内存布局包括对象头、实例数据和对齐填充。</p>\n<p>对象头存储了对象的元数据信息，包括锁状态、GC标记、哈希码等。实例数据存储了对象的成员变量值。对齐填充用于保证对象在内存中的对齐。对象头的长度在32位系统上一般为32位，64位系统上一般为64位。</p>\n<p><strong>cas自旋锁，是获取不到锁就一直自旋吗？</strong></p>\n<p>是的，CAS自旋锁是指线程在获取锁时，如果发现锁已被其他线程占用，就会一直自旋（即反复尝试获取锁），直到成功获取到锁才会退出自旋，继续执行后续代码。自旋的目的是为了避免线程阻塞和唤醒带来的开销，提高并发性能。</p>\n<p>在自旋过程中，线程会通过CAS操作不断尝试将锁的状态从未锁定转换为锁定状态。如果CAS操作成功，表示线程成功获取到了锁，可以继续执行后续代码。如果CAS操作失败，表示锁仍被其他线程占用，线程会继续自旋尝试获取锁，直到成功为止。</p>\n<p><strong>cas和synchronized区别在哪里</strong></p>\n<p>CAS（Compare and Swap）和 synchronized 是两种不同的线程同步机制，它们的区别主要体现在以下几个方面：</p>\n<ol>\n<li>锁的实现方式：synchronized 是悲观锁，即线程在获取锁时会阻塞等待；而CAS是乐观锁，线程不会阻塞，而是通过不断重试来获取锁。</li>\n<li>对内存的影响：synchronized 在获取和释放锁时会涉及到线程的切换，涉及到内核态和用户态之间的切换，开销较大；而CAS操作是在用户态完成的，避免了线程切换的开销。</li>\n<li>安全性：synchronized 是悲观锁，可以保证线程安全，但可能导致线程的阻塞和唤醒开销；CAS是乐观锁，如果多个线程同时进行CAS操作，可能会导致竞争失败，需要进行重试。</li>\n<li>使用范围：synchronized 可以用于修饰方法、代码块，也可以用于修饰静态方法和类；而CAS通常用于对单个变量进行原子操作，如 AtomicInteger 类中的 compareAndSet 方法。</li>\n</ol>\n<p><strong>为什么cas好，具体优势在哪里</strong></p>\n<p>自旋的线程不一定会一直占用 CPU，具体取决于操作系统和 CPU 调度策略。当自旋的线程没有获取到锁时，操作系统可以将其设置为阻塞状态，将 CPU 资源分配给其他线程。当锁的状态发生变化时，操作系统会将线程重新唤醒，使其继续执行。</p>\n<p><strong>cas中在自旋的这个线程能保证一直占用cpu吗？</strong></p>\n<p>在 CAS 中自旋的线程<code>不能保证一直</code>占用 CPU。自旋是一种忙等待的机制，线程会反复检查共享变量的状态，直到满足条件为止。在自旋期间，线程会一直占用 CPU 资源，但这并不能保证一直占用 CPU。操作系统的调度器会根据一定的策略和优先级来分配 CPU 时间给不同的线程。如果有其他线程具有更高的优先级或更紧急的任务，调度器可能会剥夺自旋线程的 CPU 时间，将其切换到等待状态，以便执行其他任务。这种情况下，自旋线程将会失去 CPU 的占用权。</p>\n<p>当自旋线程再次获得 CPU 时间时，它将继续自旋，继续尝试满足条件。因此，自旋线程并不能保证一直占用 CPU，而是根据调度器的决策来分配 CPU 时间。为了避免自旋线程长时间占用 CPU 资源，可以考虑使用适当的自旋次数限制、线程礼让、线程睡眠等技术手段，以平衡 CPU 的使用和线程等待的效率。</p>\n<p><strong>假如cpu放弃了这个线程，不是还要带来线程再次抢占cpu的开销？</strong></p>\n<p>是的，如果 CPU 放弃了自旋的线程，即将其调度出去执行其他任务，那么当线程再次获得 CPU 时间时，会产生线程抢占 CPU 的开销。当一个线程被调度器从 CPU 中移除，然后再次调度回来时，会发生上下文切换的开销。上下文切换是指将当前线程的执行状态（包括寄存器值、程序计数器、堆栈等）保存起来，然后加载另一个线程的执行状态，使其能够继续执行。上下文切换本身就会带来一定的开销，包括保存和恢复寄存器状态、切换堆栈等操作。因此，如果线程频繁地被调度进出 CPU，会增加系统的开销，降低整体的执行效率。</p>\n<p>可以通过减少线程抢占 CPU 带来的开销来进行解决;具体就是：</p>\n<ol>\n<li>使用适当的自旋次数限制：在自旋等待期间，可以设置一个合理的自旋次数限制，超过限制后放弃自旋，避免过度占用 CPU 资源。</li>\n<li>使用线程礼让：在自旋等待期间，可以通过调用线程礼让的方法，如<code>Thread.yield()</code>，让出 CPU 时间给其他优先级更高的线程，降低自旋线程占用 CPU 的时间。</li>\n<li>使用线程睡眠：在自旋等待期间，可以通过调用线程睡眠的方法，如<code>Thread.sleep()</code>，暂时释放 CPU，避免持续自旋占用 CPU 资源，然后再根据条件唤醒线程继续执行。</li>\n<li>使用合适的同步机制：考虑使用更适合的同步机制，如 Lock、Condition 等，它们能够更灵活地控制线程的等待和唤醒，避免不必要的自旋。</li>\n<li>调整线程数量和优先级：合理设置线程的数量和优先级，避免过多线程竞争 CPU，导致频繁的上下文切换。</li>\n</ol>\n<p><strong>synchronized 底层如何实现的，实现同步的时候用到cas了吗？</strong></p>\n<p>synchronized 通过对象监视器（Monitor）实现同步。在 Java 中，每个对象都有一个与之相关联的 Monitor 对象。当线程进入 synchronized 代码块时，它会尝试获取 Monitor 对象的锁。</p>\n<p>具体实现上，synchronized 在编译时会在同步块的前后插入 monitorenter 和 monitorexit 指令。当线程进入同步块时，会执行 monitorenter 指令来尝试获取 Monitor 对象的锁。如果锁已经被其他线程占用，线程就会进入阻塞状态，等待锁的释放。当线程执行完同步块中的代码后，会执行 monitorexit 指令来释放 Monitor 对象的锁。</p>\n<p>在实现同步的过程中，并没有直接使用 CAS（Compare and Swap）操作。synchronized 使用的是一种基于锁的方式来实现线程的同步，而不是基于CAS的乐观锁。当线程获取锁时，会直接进入阻塞状态，等待锁的释放，而不会进行自旋重试。</p>\n","_path":"post/aa55683f.html","_link":"http://rycan.top/post/aa55683f.html","_id":"clmhxgjfu0009p70p42jpfqwu"}}