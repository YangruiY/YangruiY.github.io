{"type":"getPostById","data":{"title":"Kafka","date":"2023-07-03T12:50:21.000Z","description":"Kafka","categories":[{"name":"中间件","_id":"cln1a3w9a0004gg0p0e2vf2yq"}],"tags":[{"name":"Kafka","_id":"cln1a3w9g000ugg0p3cwdbyeb"}],"content":"<meta name=\"referrer\" content=\"no-referrer\">\n<h1>kafka</h1>\n<h2 id=\"基础\">基础</h2>\n<h3 id=\"简单介绍\">简单介绍</h3>\n<ul>\n<li>\n<p>定义：</p>\n<ul>\n<li>Kafka是一个分布式的基于<code>发布/订阅模式</code>的消息队列 (Message Queue) ，主要应用于大数据实时处理领域</li>\n<li>Kafka 是 一 个 开 源 的 <code>分 布 式 事 件 流 平 台</code> ( Event  Streaming Platform) ，用于高性能数据管道、流分析、数据集成和关键任务应用。</li>\n</ul>\n</li>\n<li>\n<p>发布/订阅：消息的发布者不会将消息直接发送给特定的订阅者，而是将发布的消息 分为不同的类别，订阅者只接收感兴趣的消息。</p>\n</li>\n<li>\n<p>消息队列：</p>\n<blockquote>\n<p>应用场景：</p>\n<ul>\n<li><strong>缓存消峰</strong>：有助于控制和优化数据流经过系统的速度， 解决<code>生产消息和消费消息</code>的<code>处理速度</code>不一致的情况</li>\n<li><strong>解耦</strong>：允许独立的<code>扩展或修改两边的处理过程</code>，只要确保它们<code>遵守同样的接口约束</code></li>\n<li><strong>异步通信</strong>：允许用户把一个消息<code>放入队列</code>，但<code>并不立即处理它</code>，然后<code>在需要的时候</code>再去处理它们</li>\n</ul>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306182252562.png\" alt=\"image-20230618225244545\" style=\"zoom:33%;\">\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306182253362.png\" alt=\"image-20230618225325343\" style=\"zoom:33%;\">\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306182253870.png\" alt=\"image-20230618225345851\" style=\"zoom:33%;\">\n<blockquote>\n<p>消息队列的两种模式</p>\n</blockquote>\n<ul>\n<li>\n<p><code>点对点模式</code></p>\n<ul>\n<li>\n<p>消费者主动拉取数据，消息收到后清除消息</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306182304155.png\" alt=\"image-20230618230413135\" style=\"zoom:33%;\">\n</li>\n</ul>\n</li>\n<li>\n<p><code>发布订阅模式</code></p>\n<ul>\n<li>\n<p>可以有多个<code>topic</code>主题(浏览、点赞、收藏、评论等)</p>\n</li>\n<li>\n<p>消费者<code>消费数据</code>之后，<code>不删除数据</code></p>\n</li>\n<li>\n<p>每个消费者相互独立，都可以消费到数据</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306182314264.png\" alt=\"image-20230618231435235\" style=\"zoom:33%;\">\n</li>\n</ul>\n</li>\n<li>\n<p>两种模式的对比：</p>\n<ul>\n<li>点对点消费 ：消息只能发布到一个主题， 消费完成就删除消息，且只有一个消费者</li>\n<li>发布订阅模式：消息可以发布到多个主题， 消息一般保留七天，且有多个消费者</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306182321214.png\" alt=\"image-20230618232149155\" style=\"zoom:33%;\">\n</li>\n<li>\n<p>说明：</p>\n<ul>\n<li><code>Partition?</code>表示的就是对 <code>Kafka</code>进行分区，注意：一个分区中的一份数据就只能有一个消费者进行消费;一个非常大的 <code>topic</code> 可以分布到多个 <code>broker</code>（即服务器）上，一个 <code>topic</code> 可以分为多个 <code>partition</code>，每个 <code>partition</code> 是一个有序的队列</li>\n<li><code>broker?</code>表示的就是一个服务器,一个集群由多个 <code>broker</code> 组成。一个<code>broker</code> 可以容纳多个 <code>topic</code></li>\n<li><code>Topic</code>：可以理解为一个队列，生产者和消费者面向的都是一个 topic</li>\n<li><code>leader</code> 表示原来的数据，无论生产还是消费处理的都是<code>leader</code>; <code>follower</code>表示副本数据，只进行备份，除非<code>leader</code>挂了，<code>follower</code>才可能会成为<code>leader</code>\n<ul>\n<li><code>Leader</code>：每个分区多个副本的“主”，<strong>生产者发送数据的对象，以及消费者消费数据的对象都是 <code>Leader</code></strong></li>\n<li><code>Follower</code>：每个分区多个副本中的“从”，实时从 <code>Leader</code> 中同步数据，保持和<code>Leader</code> 数据的同步。<code>Leader</code> 发生故障时，某个 <code>Follower</code> 会成为新的 <code>Leader</code></li>\n</ul>\n</li>\n<li>在Kafka2.8版本前，Zookeeper会记录有哪些<code>Broker上线了</code>，还会记录<code>leader</code>副本的相关信息，同时，Zookeeper的Consumer文件中存放消息被消费的记录（offset）；在Kafka2.8版本后，消息被消费的记录（offset）存放在Kafka中zk就是可选的了</li>\n<li><code>Consumer Group（CG）</code>：消费者组，由多个 <code>consumer</code> 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>启动集群的脚本<code>kf.sh</code>    位置在   <code>root/bin下</code></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">#! /bin/bash</span><br><span class=\"line\"><span class=\"keyword\">case</span> $<span class=\"number\">1</span> in</span><br><span class=\"line\"><span class=\"string\">&quot;start&quot;</span>)&#123;</span><br><span class=\"line\"> <span class=\"keyword\">for</span> i in centos7 centos7c1 centos7c2</span><br><span class=\"line\"> <span class=\"keyword\">do</span></span><br><span class=\"line\"> echo <span class=\"string\">&quot; --------启动 $i Kafka-------&quot;</span></span><br><span class=\"line\"> ssh $i <span class=\"string\">&quot;/ryang/MyApplication/kafka/kafka_2.13-3.4.1/bin/kafka-server-start.sh -daemon /ryang/MyApplication/kafka/kafka_2.13-3.4.1/config/server.properties&quot;</span></span><br><span class=\"line\"> done</span><br><span class=\"line\">&#125;;;</span><br><span class=\"line\"><span class=\"string\">&quot;stop&quot;</span>)&#123;</span><br><span class=\"line\"> <span class=\"keyword\">for</span> i in centos7 centos7c1 centos7c2</span><br><span class=\"line\"> <span class=\"keyword\">do</span></span><br><span class=\"line\"> echo <span class=\"string\">&quot; --------停止 $i Kafka-------&quot;</span></span><br><span class=\"line\"> ssh $i <span class=\"string\">&quot;/ryang/MyApplication/kafka/kafka_2.13-3.4.1/bin/kafka-server-stop.sh &quot;</span></span><br><span class=\"line\"> done</span><br><span class=\"line\">&#125;;;</span><br><span class=\"line\">esac</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>停止 Kafka 集群时，一定要等 Kafka 所有节点进程全部停止后再停止 Zookeeper集群。</p>\n<p>因为 Zookeeper 集群当中记录着 Kafka 集群相关信息，Zookeeper 集群一旦先停止，Kafka 集群就没有办法再获取停止进程的信息，只能<code>手动</code>杀死 Kafka 进程了。</p>\n</blockquote>\n<h3 id=\"Kafka生产者\">Kafka生产者</h3>\n<h4 id=\"生产者消息的发送流程\">生产者消息的发送流程</h4>\n<blockquote>\n<p><font color=\"red\">发送原理</font></p>\n</blockquote>\n<ul>\n<li>在消息发送的过程中，涉及到了<strong>两个线程——<code>main</code></strong> <strong>线程和</strong> <strong><code>Sender</code></strong> <strong>线程</strong>。</li>\n<li>在 <code>main</code> 线程中创建了<strong>一个<code>双端队列</code></strong> <strong><code>RecordAccumulator</code></strong>,<code>main</code>线程是消息的<code>生产线程</code>并将消息发送给 <code>RecordAccumulator</code></li>\n<li><code>sender</code>线程是<code>jvm</code>单例的线程，专门用于消息的发送，即：不断从 <code>RecordAccumulator</code> 中拉取消息发送到<code> Kafka Broker</code></li>\n<li>在<code>jvm</code>的内存中开辟了一块缓存空间叫<strong>RecordAccumulator（消息累加器）</strong>，用于将多条消息合并成一个批次，然后由sender线程发送给kafka集群。</li>\n</ul>\n<blockquote>\n<p><font color=\"red\">流程</font></p>\n</blockquote>\n<ul>\n<li>消息在生产过程会调用<code>send</code>方法</li>\n<li>随后经过<code>拦截器</code>经过序列化器</li>\n<li>再经过分区器确定消息发送在具体<code>topic</code>下的哪个分区</li>\n<li>然后发送到对应的<code>消息累加器</code>中，消息累加器是多个双端队列。每个队列和主题分区都具有一一映射关系</li>\n<li>消息在累加器中，进行合并，达到了对应的<code>size（batch.size</code>）或者等待<code>超过对应的等待时间(linger.ms)</code>，都会触发<code>sender</code>线程的发送</li>\n<li><code>sender</code>线程有一个请求池，<code>默认缓存最多接受五个请求</code>（ ==max.in.flight.requests.per.connection== ），发送消息后，会等待服务端的<code>ack</code>，如果没收到<code>ack</code>就会重试；默认重试<code>int</code>最大值（ <code>retries</code> ）。如果<code>ack</code>成功就会删除累加器中的消息批次，并相应到<code>生产端</code></li>\n</ul>\n<blockquote>\n<p><font color=\"red\">流程图</font></p>\n</blockquote>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191630066.png\" alt></p>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>bootstrap.servers</td>\n<td>生产者连接集群所需的 broker 地 址 清 单<br>例 如centos7:9092,centos7c1:9092,centos7c2:9092，可以设置 1 个或者多个，中间用逗号隔开<br>注意这里并非需要所有的 broker 地址，因为生产者是从给定的 <code>broker</code>里查找到其他 <code>broker</code> 信息</td>\n</tr>\n<tr>\n<td><code>key.serializer</code> 和<code> value.serializer</code></td>\n<td>指定发送消息的 key 和 value 的序列化类型。一定要写全类名</td>\n</tr>\n<tr>\n<td>buffer.memory</td>\n<td>RecordAccumulator 缓冲区总大小，默认 32m</td>\n</tr>\n<tr>\n<td>batch.size</td>\n<td>缓冲区一批数据最大值，默认 16k<br>适当增加该值，可以提高吞吐量，但是如果该值设置太大，会导致数据传输延迟增加</td>\n</tr>\n<tr>\n<td><a href=\"http://linger.ms\">linger.ms</a></td>\n<td>如果数据迟迟未达到 batch.size，sender 等待 linger.time之后就会发送数据。<br>单位 ms，默认值是 0ms，表示没有延迟。生产环境建议该值大小为 5-100ms 之间。</td>\n</tr>\n<tr>\n<td>acks</td>\n<td>0：生产者发送过来的数据，不需要等数据落盘应答，可以直接发送<br>1：生产者发送过来的数据，Leader 收到数据后应答之后才能进行发送<br>-1（all）：生产者发送过来的数据，Leader+和 isr 队列里面的所有节点收齐数据后应答<br>默认值是-1，-1 和all 是等价的</td>\n</tr>\n<tr>\n<td>max.in.flight.requests.per.connection</td>\n<td>允许最多没有返回 <code>ack</code> 的次数，默认为 5，开启幂等性要保证该值是 1-5 的数字。</td>\n</tr>\n<tr>\n<td>retries</td>\n<td>当消息发送出现错误的时候，系统会重发消息。<br><code>retries</code>表示重试次数。默认是 int 最大值，2147483647。<br>如果设置了重试，还想保证消息的有序性，需要设置<code>MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION=1</code><br>否则在重试此失败消息的时候，其他的消息可能发送</td>\n</tr>\n<tr>\n<td><a href=\"http://retry.backoff.ms\">retry.backoff.ms</a></td>\n<td>两次重试之间的<code>时间间隔</code>，默认是 <code>100ms</code>。</td>\n</tr>\n<tr>\n<td>enable.idempotence</td>\n<td>是否开启幂等性，默认 <code>true</code>，开启<code>幂等性</code></td>\n</tr>\n<tr>\n<td>compression.type</td>\n<td>生产者发送的所有数据的压缩方式。默认是 <code>none</code>，也就是不压缩<br>支持压缩类型：<code>none、gzip、snappy、lz4 和 zstd</code></td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"异步发送API\">异步发送API</h4>\n<blockquote>\n<p><font color=\"red\"><strong>普通异步发送</strong></font></p>\n<p><code>kafkaProducer.send(new ProducerRecord(&quot;first&quot;, &quot;name&quot; + i));</code></p>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191319230.png\" alt=\"image-20230619131951173\" style=\"zoom:33%;\">\n<blockquote>\n<p><font color=\"red\">带回调函数的异步发送</font></p>\n<ul>\n<li>回调函数会在 <code>producer</code> 收到 <code>ack</code> 时调用，为异步调用，该方法有两个参数，分别是<code>元数据信息</code>（RecordMetadata）和<code>异常信息</code>（Exception）\n<ul>\n<li>如果 <code>Exception</code> 为 null，说明消息<code>发送成功</code></li>\n<li>如果 <code>Exception</code> 不为 null，说明消息<code>发送失败</code></li>\n</ul>\n</li>\n<li>注意：消息发送失败会自动重试，不需要我们在回调函数中手动重试。</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kafkaProducer.send(<span class=\"keyword\">new</span> <span class=\"title class_\">ProducerRecord</span>(<span class=\"string\">&quot;first&quot;</span>, <span class=\"string\">&quot;name&quot;</span> + i), <span class=\"keyword\">new</span> <span class=\"title class_\">Callback</span>() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">onCompletion</span><span class=\"params\">(RecordMetadata recordMetadata, Exception e)</span> &#123;</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (e == <span class=\"literal\">null</span>) &#123;</span><br><span class=\"line\">            System.out.println( <span class=\"string\">&quot;分区 ： &quot;</span> + recordMetadata.partition() + <span class=\"string\">&quot; 主题： &quot;</span> + recordMetadata.topic() );</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;);</span><br></pre></td></tr></table></figure>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191320570.png\" alt=\"image-20230619132053541\" style=\"zoom:33%;\">\n<blockquote>\n<p><font color=\"red\">同步发送API</font></p>\n<p>流程</p>\n<ul>\n<li>\n<p>先处理已经堆积在 <code>DQueue</code> 中的数据</p>\n</li>\n<li>\n<p>随后 <code>RecordAccumulator</code> 再处理外部数据放入<code>DQueue</code></p>\n</li>\n</ul>\n<p>做法：</p>\n<ul>\n<li>只需在<code>异步发送</code>的基础上，再调用一下 <code>get()</code>方法即可</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kafkaProducer.send(<span class=\"keyword\">new</span> <span class=\"title class_\">ProducerRecord</span>(<span class=\"string\">&quot;first&quot;</span>, <span class=\"string\">&quot;name&quot;</span> + i), <span class=\"keyword\">new</span> <span class=\"title class_\">Callback</span>() &#123;</span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">onCompletion</span><span class=\"params\">(RecordMetadata recordMetadata, Exception e)</span> &#123;</span><br><span class=\"line\">\t\t...</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;).get();  <span class=\"comment\">//get 应该就是阻塞的意思</span></span><br></pre></td></tr></table></figure>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191332714.png\" alt=\"image-20230619133220677\" style=\"zoom:33%;\">\n<blockquote>\n<p><font color=\"red\">生产者拦截器</font></p>\n</blockquote>\n<p>拦截器接口一共有三个方法。三个方法内的实现<code>如果抛出异常</code>，会被<code>ProducerInterceptors</code>内部捕获，并不会抛到上层</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">interface</span> <span class=\"title class_\">ProducerInterceptor</span>&lt;K, V&gt; <span class=\"keyword\">extends</span> <span class=\"title class_\">Configurable</span> &#123;</span><br><span class=\"line\">    ProducerRecord&lt;K, V&gt;  <span class=\"title function_\">onSend</span><span class=\"params\">(ProducerRecord&lt;K, V&gt; record)</span>;</span><br><span class=\"line\">    <span class=\"keyword\">void</span>  <span class=\"title function_\">onAcknowledgement</span><span class=\"params\">(RecordMetadata metadata, Exception exception)</span>;</span><br><span class=\"line\">    <span class=\"keyword\">void</span>  <span class=\"title function_\">close</span><span class=\"params\">()</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ul>\n<li>\n<p><code>onSend </code>方法在消息<code>分区之前</code>，可以对<code>消息进行一定的修改</code>，比如给key添加前缀，<code>甚至可以修改我们的topic</code>，如果需要使用kafka实现<code>延时队列高级应用</code>，我们就可以通过<code>拦截器对消息进行判断</code>，并修改，暂时放入我们的<code>延时主题</code>中，等时间达到再放回<code>普通主题队列</code>。</p>\n</li>\n<li>\n<p><code>onAcknowledgement</code>该方法是在我们服务端对<code>sender</code>线程进行<code>消息确认</code>，或消息发送失败后的一个回调。<code>优先于</code>我们send方法的<code>callback回调</code>。我们可以对发送情况做一个统计。但是该方法在我们的<code>sender</code>线程,也就是唯一的IO线程执行，逻辑越少越好。</p>\n</li>\n<li>\n<p><code>close</code>该方法可以在<code>关闭拦截器时，进行一些资源的释放</code></p>\n</li>\n</ul>\n<blockquote>\n<p><font color=\"red\">自定义拦截器</font></p>\n</blockquote>\n<ol>\n<li>自定义拦截器</li>\n</ol>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> MyInterceptor <span class=\"keyword\">implements</span> <span class=\"title class_\">ProducerInterceptor</span> &#123;</span><br><span class=\"line\">\t<span class=\"comment\">//实现上面的方法</span></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<ol start=\"2\">\n<li>将自定义拦截器加入到设置中</li>\n</ol>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,MyInterceptor.getClass.getName());</span><br></pre></td></tr></table></figure>\n<h4 id=\"生产者分区\">生产者分区</h4>\n<ul>\n<li>分区的好处\n<ul>\n<li><strong>便于合理使用存储资源</strong>，每个<code>Partition</code>在一个<code>Broker</code>上存储，可以把海量的数据按照分区<code>切割成一块一块数据</code>存储在多台<code>Broker</code>上。</li>\n<li>合理控制分区的任务，可以<strong>实现<code>负载均衡</code>的效果</strong>。</li>\n<li><strong>提高并行度</strong>，生产者可以 以分区为单位<code>发送</code>数据；消费者可以以分区为单位进行<code>消费</code>数据。</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p><font color=\"red\"><strong>生产者发送消息的分区策略</strong></font></p>\n</blockquote>\n<ul>\n<li><strong>默认的分区器</strong> <strong>DefaultPartitioner</strong></li>\n<li>三种支持分区的策略\n<ul>\n<li>指定分区</li>\n<li>指定<code>key</code> , 计算 <code>hash</code> 得到分区</li>\n<li>制定随机粘性分区</li>\n</ul>\n</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191401432.png\" alt=\"image-20230619140157399\" style=\"zoom:47%;\">\n<ul>\n<li>自定义分区策略\n<ul>\n<li>自定义类实现接口<code>Partitioner</code></li>\n<li>重写 <code>partition()</code>方法</li>\n<li>使用<code>自定义的分区器</code>的方法，在生产者的配置中添加分区器参数。</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">package</span> com.ry.kafka.producer;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.kafka.clients.producer.Partitioner;</span><br><span class=\"line\"><span class=\"keyword\">import</span> org.apache.kafka.common.Cluster;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> java.util.Map;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">MyPartitioner</span> <span class=\"keyword\">implements</span> <span class=\"title class_\">Partitioner</span> &#123;</span><br><span class=\"line\">    <span class=\"comment\">/**</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> topic 主题</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> key 消息的 key</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> keyBytes 消息的 key 序列化后的字节数组</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> value 消息的 value</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> valueBytes 消息的 value 序列化后的字节数组</span></span><br><span class=\"line\"><span class=\"comment\">     * <span class=\"doctag\">@param</span> cluster 集群元数据可以查看分区信息</span></span><br><span class=\"line\"><span class=\"comment\">     */</span></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"type\">int</span> <span class=\"title function_\">partition</span><span class=\"params\">(String topic, Object key, <span class=\"type\">byte</span>[] keyBytes, Object value, <span class=\"type\">byte</span>[] valueBytes, Cluster cluster)</span> &#123;</span><br><span class=\"line\">        <span class=\"type\">String</span> <span class=\"variable\">string</span> <span class=\"operator\">=</span> value.toString();</span><br><span class=\"line\">        <span class=\"keyword\">if</span> (string.contains(<span class=\"string\">&quot;hi&quot;</span>))&#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">2</span>;</span><br><span class=\"line\">        &#125;<span class=\"keyword\">else</span>&#123;</span><br><span class=\"line\">            <span class=\"keyword\">return</span> <span class=\"number\">1</span>;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">close</span><span class=\"params\">()</span> &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"meta\">@Override</span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">configure</span><span class=\"params\">(Map&lt;String, ?&gt; configs)</span> &#123;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//自定义分区规则 </span></span><br><span class=\"line\">properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,MyPartitioner.class.getName());</span><br></pre></td></tr></table></figure>\n<h4 id=\"如何提高生产者的吞吐量\">如何提高生产者的吞吐量</h4>\n<ul>\n<li>\n<p>目的： 通过<code>提高吞吐量</code>达到<code>降低延迟的效果</code></p>\n</li>\n<li>\n<p>使用:</p>\n<ul>\n<li><strong>Batch.size<code>默认 16k</code> 与 linger.ms<code>等待时间</code> 配合使用，根据生成数据的大小指定。</strong></li>\n<li><strong>RecordAccumlator<code>缓冲区大小</code>：在异步发送并且分区很多的情况下，<code>32M</code>的数据量容易被满足，进程交互加大，可以适当提高到64M。</strong></li>\n<li><strong>compression.type<code>压缩类型</code>：压缩snappy</strong></li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p><font color=\"red\">消息累加器</font></p>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191453604.png\" alt=\"image-20230619145337572\" style=\"zoom:33%;\">\n<ul>\n<li>\n<p>为了提高生产者的吞吐量，我们通过累加器将多条消息<code>合并</code>成一批统一发送。在broker中将消息<code>批量存入</code>。<code>减少多次的网络IO</code>。</p>\n</li>\n<li>\n<p>消息累加器默认<code>32m</code>，如果生产者的<code>发送速率</code>大于<code>sender发送的速率</code>，消息就会<code>堆满</code>累加器。生产者就会<code>阻塞</code>，或者<code>报错</code>，报错取决于阻塞时间的配置。</p>\n</li>\n<li>\n<p>累加器的存储形式为<code>ConcurrentMap&lt;TopicPartition, Deque&lt;ProducerBatch&gt;&gt;</code>，可以看出来就是一个分区对应一个双端队列，队列中存储的是<code>ProducerBatch</code>一般大小是<code>16k根</code>据<code>batch.size</code>配置，新的消息会<code>append</code>到<code>ProducerBatch</code>中，满<code>16k</code>就会创建新的<code>ProducerBatch</code>，并且触发<code>sender</code>线程进行发送。</p>\n</li>\n<li>\n<p>如果消息量非常大，生成了大量的<code>ProducerBatch</code>，在发送后，又需要<code>JVM</code>通过<code>GC</code>回收这些<code>ProducerBatch</code>就变得非常影响性能，所以kafka通过 <code>BufferPool</code>作为<code>内存池</code>来管理<code>ProducerBatch</code>的创建和回收，需要申请一个新的<code>ProducerBatch</code>空间时，调用<code> free.allocate(size, maxTimeToBlock)</code>找<code>内存池申请空间</code>。</p>\n</li>\n<li>\n<p>如果单条消息大于16k，那么就不会复用内存池了，会生成一个更大的<code>ProducerBatch</code>专门存放大消息，发送完后<code>GC回收</code>该内存空间。</p>\n</li>\n</ul>\n<blockquote>\n<p>为了进一步减小网络中消息传输的带宽。我们也可以通过<strong>消息压缩</strong>的方式，在生产端将消息追加进<code>ProducerBatch</code> <code>就</code>对每一条消息进行压缩了。常用的有Gzip、Snappy、Lz4 和 Zstd，这是时间换空间的手段。压缩的消息会在<code>消费端进行解压</code>。</p>\n</blockquote>\n<blockquote>\n<p><font color=\"red\">消息发送线程(Sender) </font></p>\n</blockquote>\n<ul>\n<li>消息保存在内存后，Sender线程就会把符合条件的消息<code>按照批次进行发送</code>。除了发送消息，<code>元数据的加载</code>也是通过<code>Sender</code>线程来处理的。</li>\n<li><code>Sender</code>线程发送消息以及接收消息，都是基于<code>java NIO的Selector</code>。通过<code>Selector</code>把消息发出去，并通过<code>Selector</code>接收消息。</li>\n<li><code>Sender</code>线程默认容纳5个未确认的消息，消息发送失败后会进行重试。</li>\n</ul>\n<h4 id=\"数据的可靠性\">数据的可靠性</h4>\n<blockquote>\n<p>主要针对<code>ACKs</code>应答环节</p>\n<p>做法</p>\n<ul>\n<li><code>properties.put(ProducerConfig.ACKS_CONFIG, &quot;all&quot;);     // 设置 acks</code></li>\n<li><code>properties.put(ProducerConfig.RETRIES_CONFIG, 3); // 重试次数 retries，默认是 int 最大值</code></li>\n</ul>\n</blockquote>\n<ul>\n<li>\n<p><code>acks</code>为<code>0</code>时， 表示生产者将数据发送出去就不管了，不等待任何返回。这种情况下数据<code>传输效率最高</code>，但是数据<code>可靠性最低</code>，当 server挂掉的时候就会丢数据；</p>\n</li>\n<li>\n<p><code>acks</code>为<code>1</code>时（默认），表示数据发送到<code>Kafka</code>后，经过leader成功接收消息的的确认，才算发送成功，如果leader宕机了，就会丢失数据。</p>\n</li>\n<li>\n<p><code>acks</code>为<code>-1/all</code>时，表示生产者需要等待<code>ISR</code>中的所有<code>follower</code>都确认接收到数据后才算发送完成，这样数据不会丢失，因此<code>可靠性最高，性能最低</code>。</p>\n</li>\n</ul>\n<blockquote>\n<p><code>ISR</code></p>\n<ul>\n<li>\n<p>指的是与 <code>leader</code> 副本保持同步的副本集合，ISR 中的副本和 leader 副本之间的数据<code>保持一致</code>。</p>\n</li>\n<li>\n<p>当 <code>Kafka</code> 集群中的 <code>broker</code> 出现故障或网络问题时，<code>ISR</code> 可以作为新的 <code>leader</code> 副本的候选者来保证集群的<code>高可用性</code></p>\n</li>\n</ul>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191451759.png\" alt=\"image-20230619145156686\" style=\"zoom:50%;\">\n<blockquote>\n<p><font color=\"red\">数据完全可靠条件</font></p>\n<ul>\n<li><code>ACK级别设置为   -1 + 分区副本大于等于  2 + ISR里应答的最小副本数量大于等于  2</code></li>\n</ul>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191503059.png\" alt=\"image-20230619150328005\" style=\"zoom:50%;\">\n<blockquote>\n<p><font color=\"red\">总结：</font></p>\n</blockquote>\n<ul>\n<li><code>acks=0</code>，生产者发送过来数据就不管了，可靠性差，效率高；</li>\n<li><code>acks=1</code>，生产者发送过来数据Leader应答，可靠性中等，效率中等；</li>\n<li><code>acks=-1</code>，生产者发送过来数据Leader和ISR队列里面所有Follwer应答，可靠性高，效率低；</li>\n<li>在生产环境中，<code>acks=0</code>很少使用；<code>acks=1</code>，一般用于传输普通日志，允许丢个别数据；<code>acks=-1</code>，一般用于传输和钱相关的数据，对可靠性要求比较高的场景。</li>\n</ul>\n<blockquote>\n<p><code>AR = ISR + ORS</code></p>\n</blockquote>\n<ul>\n<li>\n<p><code>AR</code>（Assigned Replicas）表示一个主题分区的<code>全部副本集合</code>，它包括了 ISR（in-sync replica set）和 ORS（out-of-sync replica set）两部分</p>\n</li>\n<li>\n<p>正常情况下，如果所有的<code>follower</code>副本都应该与<code>leader</code>副本保持一定程度的同步，即：<code>AR = ISR，OSR = null</code></p>\n<ul>\n<li><code>ISR</code> 表示在指定时间内和leader保存数据同步的集合，即 表示与 leader 副本保持同步的副本集合,如果 <code>Follower</code> 长时间未向 <code>Leader</code> 发送通信请求或同步数据，则该 <code>Follower</code> 将被踢出 <code>ISR</code>;该时间阈值由**<code>replica.lag.time.max.ms</code>**参数设定，默认 <code>30s</code>。<code>Leader</code> 发生故障之后，就会从 <code>ISR</code> 中选举新的 <code>Leader</code>。</li>\n</ul>\n</li>\n<li>\n<p><code>ORS</code>表示不能在指定的时间内和<code>leader</code>保持数据同步集合，即 表示跟 <code>leader</code> 副本数据有差异的副本集合,就是说其表示的是：<code>Follower</code> 与 <code>Leader</code> 副本同步时<code>延迟过多</code>的副本。</p>\n</li>\n<li>\n<p>当 <code>ISR </code>中的副本出现故障或不可用时，Kafka 将会从 <code>AR</code> 的 <code>ORS</code> 中选择一个副本作为新的 <code>leader</code> 副本，此时已经处于 ISR <code>中的</code>副本就不再可用，诸如此类的改变可能会影响到整个集群的性能表现。</p>\n</li>\n</ul>\n<h4 id=\"数据重复性\">数据重复性</h4>\n<blockquote>\n<p><font color=\"red\">数据重复分析：</font><br>\n<code>acks = -1(all) </code>：生产者发送过来的数据，<code>Leader</code>和<code>ISR队列</code>里面的所有节点收齐数据后应答。</p>\n</blockquote>\n<blockquote>\n<p><font color=\"red\"> 数据的传递语义</font></p>\n</blockquote>\n<ul>\n<li>至少一次（At Least Once）： <code>ACK级别设置为-1 + 分区副本&gt;=2 + ISR里应答的最小副本数量&gt;=2</code>。可以保证数据不丢失，但是不能保证数据不重复。</li>\n<li>最多一次（At Most Once）：ACK级别设置为<code>0</code> 。可以保证数据不重复，但是不能保证数据不丢失。</li>\n<li>精确一次（Exactly Once）：至少一次 + 幂等性 。( Kafka 0.11版本引入一项重大特性：幂等性和事务。)</li>\n</ul>\n<blockquote>\n<p><font color=\"red\"> 幂等性原理</font></p>\n</blockquote>\n<ul>\n<li>\n<p>幂等性的理解</p>\n<ul>\n<li>简单地说就是对接口的多次调用所产生的结果和调用一次是一致的。生产者在进行重试的时候有可能会<code>重复写入消息</code>，而使用Kafka 的<code>幂等性</code>功能之后就可以<code>避免这种情况</code>。<code>（不产生重复数据）</code></li>\n</ul>\n</li>\n<li>\n<p>重复数据的判断标准：具有<code>&lt;PID, Partition, SeqNumber&gt;</code>相同主键的消息提交时，<code>Broker</code>只会持久化一条。</p>\n<ul>\n<li><code>ProducerId（pid）</code>是Kafka每次重启都会分配一个新的</li>\n<li><code>Partition</code> 表示分区号</li>\n<li><code>Sequence Number </code>序列化号，是单调自增的</li>\n</ul>\n</li>\n<li>\n<p><code>broker</code>中会在内存维护一个<code>pid+分区对应的序列号</code>。</p>\n<ul>\n<li>如果收到的序列号正好<code> 等于  内存序列号+1</code>，才存储消息，如果小于内存序列号，意味着消息重复，那么会丢弃消息，并应答。如果远大于内存序列号，意味着消息丢失，会抛出异常。</li>\n</ul>\n</li>\n<li>\n<p>幂等解决的是<code>sender到broker间</code>，由于网络波动可能造成的<code>重发问题</code>。用<code>幂等来标识唯一消息</code>。并且幂等性只能保证的是在<code>单分区单会话内不重复</code>。</p>\n</li>\n<li>\n<p>如何使用幂等性</p>\n<ul>\n<li>开启幂等性功能的方式很简单，只需要显式地将生产者客户端参数<code>enable.idempotence</code>设置为<code>true</code>即可(这个参数的默认值为<code>true</code>)</li>\n<li>并且需要确保生产者客户端的<code>retries、acks、max.in.filght.request.per.connection</code>参数不被配置，默认值就是对的</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p><font color=\"red\"> 消息事务</font></p>\n</blockquote>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191550362.png\" alt></p>\n<ul>\n<li>\n<p>开启事务必须开启幂等性，事务的底层是依赖<code>幂等性</code>的</p>\n</li>\n<li>\n<p>由于幂等性不能跨分区运作，为了保证同时发的多条消息，要么全成功，要么全失败,所以kafka 引入了事务的概念</p>\n</li>\n<li>\n<p>通过事务协调器，来实现事务，工作<code>API</code> 与 <code>流程</code>如下</p>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 1 初始化事务</span></span><br><span class=\"line\"><span class=\"keyword\">void</span> <span class=\"title function_\">initTransactions</span><span class=\"params\">()</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 2 开启事务</span></span><br><span class=\"line\"><span class=\"keyword\">void</span> <span class=\"title function_\">beginTransaction</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> ProducerFencedException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 3 在事务内提交已经消费的偏移量（主要用于消费者）</span></span><br><span class=\"line\"><span class=\"keyword\">void</span> <span class=\"title function_\">sendOffsetsToTransaction</span><span class=\"params\">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, String consumerGroupId)</span> <span class=\"keyword\">throws</span>   ProducerFencedException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 4 提交事务</span></span><br><span class=\"line\"><span class=\"keyword\">void</span> <span class=\"title function_\">commitTransaction</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> ProducerFencedException;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 5 放弃事务（类似于回滚事务的操作）</span></span><br><span class=\"line\"><span class=\"keyword\">void</span> <span class=\"title function_\">abortTransaction</span><span class=\"params\">()</span> <span class=\"keyword\">throws</span> ProducerFencedException;</span><br></pre></td></tr></table></figure>\n<h4 id=\"数据-消息的顺序\">数据/消息的顺序</h4>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191620810.png\" alt=\"image-20230619162055751\" style=\"zoom:53%;\">\n<blockquote>\n<p><font color=\"red\">数据有序</font></p>\n</blockquote>\n<ul>\n<li>kafka 的消息在单分区内有序（在<code>特定的条件</code>下），多分区内无序（如果对多分区进行排序，造成分区无法工作需要等待排序，浪费性能）</li>\n</ul>\n<blockquote>\n<p><font color=\"red\">数据乱序</font></p>\n</blockquote>\n<ul>\n<li>kafka只能保证单分区下的消息顺序性，为了保证消息的顺序性,需要进行设置的条件是：\n<ul>\n<li>如果<code>未开启幂等性</code>，需要 <code>max.in.flight.requests.per.connection</code> 设置<code>为1</code>（缓冲队列最多放置1个请求）</li>\n<li>如果<code>开启幂等性</code>，需要<code>max.in.flight.requests.per.connection</code>设置为<code>小于5</code>\n<ul>\n<li>原因： 启用幂等后，<code>kafka</code>服务端会缓存<code>producer</code>发来的最近5个<code>request</code>的元数据，所以无论如何，都可以保证<code>最近5个request</code>的数据都是<code>有序的</code></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Kafka-Broker\">Kafka Broker</h3>\n<h4 id=\"Broker的引入\">Broker的引入</h4>\n<ul>\n<li>\n<p>集群不仅可以让消息负载均衡，还能提高消息存取的吞吐量</p>\n</li>\n<li>\n<p>kafka集群中，会有多台<code>broker</code>，每台<code>broker</code>分别在不同的机器上</p>\n</li>\n<li>\n<p>为了提高吞吐量，每个<code>topic</code>也会都多个分区，同时为了保持可靠性，每个分区还会有多个副本</p>\n</li>\n<li>\n<p>这些分区副本被<code>均匀的散落</code>在每个<code>broker</code>上，其中每个分区副本中有一个副本为<code>leader</code>，其他的为<code>follower</code></p>\n</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191904105.png\" alt=\"image-20230619190423071\" style=\"zoom:33%;\">\n<blockquote>\n<p><font color=\"red\"><strong>Zookeeper存储的Kafka信息</strong></font></p>\n</blockquote>\n<ul>\n<li>\n<p>记录有哪些服务器 <code>/kafka/brokers/ids [0,1,2] </code></p>\n</li>\n<li>\n<p>记录谁是<code>Leader</code>，有哪些服务器可用   <code> /kafka/brokers/topics/first/partitions/0/state</code></p>\n</li>\n<li>\n<p>辅助选举<code>Leader</code></p>\n</li>\n</ul>\n<blockquote>\n<p><code>Kafka</code>的选举<code>Leader</code>的方式有三种</p>\n<ul>\n<li><code>broker（控制器）选leader</code></li>\n<li>分区多副本选leader</li>\n<li>消费者选Leader</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><font color=\"red\">broker（控制器）选leader</font></p>\n</blockquote>\n<p>在kafka集群中有很多的<code>broker</code>（也叫做控制器），但是他们之间<code>需要</code>选举出一个<code>leader</code>，其他的都是<code>follower</code>。</p>\n<ul>\n<li>选举机制：\n<ul>\n<li>每个broker都有<code>唯一</code>的<code>brokerId</code>，他们在启动后会去竞争注册<code>zookeeper</code>上的<code>Controller</code>结点，谁先抢到，谁就是<code>broker leader</code>。而其他<code>broker会监听</code>该结点事件，以便后续<code>leader下线后触发重新选举</code></li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p><font color=\"red\"><code>Zookeeper</code>在<code>kafka</code>中的作用</font></p>\n</blockquote>\n<ul>\n<li>kafka使用zookeeper进行元数据管理</li>\n<li>保存broker注册信息，包括主题（Topic）、分区（Partition）信息等</li>\n<li>选择分区leader</li>\n</ul>\n<blockquote>\n<p><font color=\"red\">Kafka Broker总体工作流程</font></p>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191913101.png\" alt=\"image-20230619191308041\" style=\"zoom:53%;\">\n<h4 id=\"Broker的重要参数\">Broker的重要参数</h4>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"http://replica.lag.time.max.ms\">replica.lag.time.max.ms</a></td>\n<td>ISR 中，如果 Follower 长时间未向 Leader 发送通信请求或同步数据，则该 Follower 将被踢出 ISR。该时间阈值，默认 30s。</td>\n</tr>\n<tr>\n<td>auto.leader.rebalance.enable</td>\n<td>默认是 true。 自动 Leader Partition 平衡</td>\n</tr>\n<tr>\n<td>leader.imbalance.per.broker.percentage</td>\n<td>默认是 10%。每个 broker 允许的不平衡的 leader的比率。<br>如果每个 broker 超过了这个值，控制器会触发 leader 的平衡。</td>\n</tr>\n<tr>\n<td>leader.imbalance.check.interval.seconds</td>\n<td>默认值 300 秒。检查 leader 负载是否平衡的间隔时间</td>\n</tr>\n<tr>\n<td>log.segment.bytes</td>\n<td>Kafka 中 log 日志是分成一块块存储的，此配置是指 log 日志划分成块的大小，默认值 <code>1G</code>。</td>\n</tr>\n<tr>\n<td>log.index.interval.bytes</td>\n<td>默认 <code>4kb</code>，kafka 里面每当写入了 4kb 大小的日志(.log)，然后就往 index 文件里面记录一个索引。</td>\n</tr>\n<tr>\n<td>log.retention.hours</td>\n<td>Kafka 中数据保存的时间，<code>默认 7 天</code></td>\n</tr>\n<tr>\n<td>log.retention.minutes</td>\n<td>Kafka 中数据保存的时间，分钟级别，默认关闭。</td>\n</tr>\n<tr>\n<td><a href=\"http://log.retention.ms\">log.retention.ms</a></td>\n<td>Kafka 中数据保存的时间，毫秒级别，默认关闭。</td>\n</tr>\n<tr>\n<td><a href=\"http://log.retention.check.interval.ms\">log.retention.check.interval.ms</a></td>\n<td>检查数据是否保存超时的间隔，默认是 5 分钟。</td>\n</tr>\n<tr>\n<td>log.retention.bytes</td>\n<td>默认等于<code>-1</code>，表示无穷大。超过设置的所有日志总大小，删除最早的 <code>segment</code>。</td>\n</tr>\n<tr>\n<td>log.cleanup.policy</td>\n<td>默认是 <code>delete</code>，表示所有数据启用删除策略如果设置值为 <code>compact</code>，表示所有数据启用压缩策略。</td>\n</tr>\n<tr>\n<td>num.io.threads</td>\n<td>默认是 <code>8</code>。负责写磁盘的线程数。整个参数值要占总核数的 50%。</td>\n</tr>\n<tr>\n<td>num.replica.fetchers</td>\n<td>副本拉取线程数，这个参数占总核数的 50%的 1/3</td>\n</tr>\n<tr>\n<td>num.network.threads</td>\n<td>默认是 <code>3</code>。数据传输线程数，这个参数占总核数的50%的 2/3 。</td>\n</tr>\n<tr>\n<td>log.flush.interval.messages</td>\n<td>强制页缓存刷写到磁盘的条数<br>默认是 long 的最大值，<code>9223372036854775807</code>。<br>一般不建议修改，交给系统自己管理。</td>\n</tr>\n<tr>\n<td><a href=\"http://log.flush.interval.ms\">log.flush.interval.ms</a></td>\n<td>每隔多久，刷数据到磁盘，默认是 null。<br>一般不建议修改，交给系统自己管理。</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"节点的服役退役\">节点的服役退役</h4>\n<blockquote>\n<p>用到了 <code>负载均衡</code></p>\n</blockquote>\n<ul>\n<li>指定需要均衡的主题</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim topics-to-move.json</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span></span><br><span class=\"line\"> <span class=\"attr\">&quot;topics&quot;</span><span class=\"punctuation\">:</span> <span class=\"punctuation\">[</span></span><br><span class=\"line\"> <span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;topic&quot;</span><span class=\"punctuation\">:</span> <span class=\"string\">&quot;first&quot;</span><span class=\"punctuation\">&#125;</span></span><br><span class=\"line\"> <span class=\"punctuation\">]</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"> <span class=\"attr\">&quot;version&quot;</span><span class=\"punctuation\">:</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>生成负载均衡计划</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-reassign-partitions.sh --bootstrap-server centos7:9092 --topics-to-move-json-file  topics-to-move.json --broker-list &quot;0,1,2&quot; --generate</span><br></pre></td></tr></table></figure>\n<ul>\n<li>创建副本存储计划</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim increase-replication-factor.json</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;version&quot;</span><span class=\"punctuation\">:</span><span class=\"number\">1</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;partitions&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;topic&quot;</span><span class=\"punctuation\">:</span><span class=\"string\">&quot;first&quot;</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;partition&quot;</span><span class=\"punctuation\">:</span><span class=\"number\">0</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;replicas&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"number\">0</span><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;log_dirs&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"string\">&quot;any&quot;</span><span class=\"punctuation\">]</span><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span><span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;topic&quot;</span><span class=\"punctuation\">:</span><span class=\"string\">&quot;first&quot;</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;partition&quot;</span><span class=\"punctuation\">:</span><span class=\"number\">1</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;replicas&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"number\">0</span><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;log_dirs&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"string\">&quot;any&quot;</span><span class=\"punctuation\">]</span><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span><span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;topic&quot;</span><span class=\"punctuation\">:</span><span class=\"string\">&quot;first&quot;</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;partition&quot;</span><span class=\"punctuation\">:</span><span class=\"number\">2</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;replicas&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"number\">0</span><span class=\"punctuation\">]</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;log_dirs&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"string\">&quot;any&quot;</span><span class=\"punctuation\">]</span><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">]</span><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>执行与验证副本计划</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-reassign-partitions.sh --bootstrap-server centos7:<span class=\"number\">9092</span> --reassignment-json-file  increase-replication-factor.json --execute</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">bin/kafka-reassign-partitions.sh --bootstrap-server  centos7:<span class=\"number\">9092</span> --reassignment-json-file increase-replication-factor.json --verify</span><br></pre></td></tr></table></figure>\n<h3 id=\"kafka副本机制\">kafka副本机制</h3>\n<h4 id=\"基本信息\">基本信息</h4>\n<ul>\n<li>\n<p><code>Kafka 副本</code>作用：提高数据可靠性；但是一旦副本太多就会导致：增加磁盘存储空间，增加网络上数据传输，降低效率</p>\n</li>\n<li>\n<p><code>Replica </code>：副本，<code>同一分区的不同副本</code>保存的是<code>相同的消息</code>，为保证集群中的某个节点发生故障时，该节点上的 <code>partition</code> 数据不丢失 ，提高副本可靠性，且 <code>kafka</code> 仍然能够继续工作，<code>kafka</code> 提供了副本机制，一个 <code>topic</code> 的每个分区都有若干个副本，一个 <code>leader</code> 和若干个 <code>follower</code></p>\n</li>\n<li>\n<p><code>Leader</code> ：每个分区的多个副本中的&quot;主副本&quot;，<code>生产者以及消费者</code>只与 <code>Leader</code> 交互</p>\n</li>\n<li>\n<p><code>Follower</code> ：每个分区的多个副本中的&quot;<code>从副本</code>&quot;，负责实时从 <code>Leader</code> 中同步数据，保持和 <code>Leader</code> 数据的同步;<code>Leader</code> 发生故障时，从 <code>Follower</code> 副本中重新选举新的 <code>Leader</code> 副本对外提供服务</p>\n</li>\n<li>\n<p>Kafka 分区中的<code>所有副本统称为 AR</code>（Assigned Repllicas）</p>\n</li>\n<li>\n<p><strong>LEO</strong>:每个副本都有内部的LEO，代表当前队列消息的最后一条偏移量,其值为<code>最后一个offset + 1</code></p>\n</li>\n<li>\n<p><strong>HW</strong>:高水位，代表所有ISR中的LEO<code>值最低</code>的那个offset，也是消费者可见的最大消息offset</p>\n</li>\n</ul>\n<h4 id=\"Leader选举流程\"><strong>Leader选举流程</strong></h4>\n<ul>\n<li>Kafka 集群中有一个 <code>broker</code> 的 <code>Controller</code> 会被选举为 <code>Controller Leader</code>，负责管理集群<code>broker</code> 的上下线，所有 <code>topic</code> 的分区副本分配和 Leader 选举等工作。<code>Controller</code> 的信息同步工作是依赖于 <code>Zookeeper</code> 的</li>\n</ul>\n<blockquote>\n<p>注意: <strong>如果leader副本下线<code>选举的原则</code>就是： 在<code>ISR</code>队列中存活为前提，按照<code>AR</code>中排在前面的优先。</strong></p>\n</blockquote>\n<ul>\n<li>\n<p>图解</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306192032525.png\" alt=\"image-20230619203219463\" style=\"zoom:33%;\">\n</li>\n</ul>\n<h4 id=\"副本故障处理\">副本故障处理</h4>\n<ul>\n<li>\n<p><strong><code>Follower</code>的故障处理</strong></p>\n<ul>\n<li>处理大致流程\n<ul>\n<li>如果<code>follower</code>落后<code>leader</code>过<code>多</code>，体现在落后时间 <code>repca.lag.time.max.ms </code>或者落后偏移量<code>repca.lag.max.messages</code>,<code>follower</code>就会被<code>移除ISR队列</code>，等待该<code>队列LEO追上HW</code>，才会<code>重新加入ISR</code>中</li>\n</ul>\n</li>\n<li>过程细节\n<ul>\n<li>Follower发生故障后会被临时踢出ISR</li>\n<li>这个期间Leader和Follower继续接收数据</li>\n<li>待该Follower恢复后， Follower会读取本地磁盘记录的上次的HW，并将<code>log</code>文件高于<code>HW</code>的部分截取掉，从HW开始 向Leader进行同步</li>\n<li>等该Follower的LEO大于等于该Partition的HW，即Follower追上Leader之后，就可以重新加入ISR了</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong><code>leader</code>的故障处理</strong></p>\n<ul>\n<li>\n<p>过程细节</p>\n<ul>\n<li>\n<p>Leader发生故障之后，会从<code>ISR</code>中选出一个新的<code>Leader</code></p>\n</li>\n<li>\n<p>为保证多个副本之间的数据一致性，其余的<code>Follower</code>会先将各自的<code>log</code>文件高于<code>HW</code>的部分截掉，然后从新的<code>Leader</code>同步数据</p>\n<blockquote>\n<p>==Ps:==这只能保证<code>副本之间</code>的数据一致性，并不能保证数据<code>不丢失或者不重复</code></p>\n</blockquote>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"手动调整分区副本存储\">手动调整分区副本存储</h4>\n<blockquote>\n<p><font color=\"red\">为什么需要手动调整</font></p>\n</blockquote>\n<p>每台服务器的配置和性能不一致，但是Kafka只会根据自己的代码规则创建对应的分区副本，就会导致个别服务器存储压力较大,所有需要手动调整分区副本的存储</p>\n<ul>\n<li>创建副本存储计划（所有副本都指定存储在 broker0、broker1 中)</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim increase-replication-factor.json</span><br></pre></td></tr></table></figure>\n<ul>\n<li>输入</li>\n</ul>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;version&quot;</span><span class=\"punctuation\">:</span><span class=\"number\">1</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"attr\">&quot;partitions&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;topic&quot;</span><span class=\"punctuation\">:</span><span class=\"string\">&quot;three&quot;</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;partition&quot;</span><span class=\"punctuation\">:</span><span class=\"number\">0</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;replicas&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"number\">0</span><span class=\"punctuation\">,</span><span class=\"number\">1</span><span class=\"punctuation\">]</span><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;topic&quot;</span><span class=\"punctuation\">:</span><span class=\"string\">&quot;three&quot;</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;partition&quot;</span><span class=\"punctuation\">:</span><span class=\"number\">1</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;replicas&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"number\">0</span><span class=\"punctuation\">,</span><span class=\"number\">1</span><span class=\"punctuation\">]</span><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;topic&quot;</span><span class=\"punctuation\">:</span><span class=\"string\">&quot;three&quot;</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;partition&quot;</span><span class=\"punctuation\">:</span><span class=\"number\">2</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;replicas&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"number\">1</span><span class=\"punctuation\">,</span><span class=\"number\">0</span><span class=\"punctuation\">]</span><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">,</span></span><br><span class=\"line\"><span class=\"punctuation\">&#123;</span><span class=\"attr\">&quot;topic&quot;</span><span class=\"punctuation\">:</span><span class=\"string\">&quot;three&quot;</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;partition&quot;</span><span class=\"punctuation\">:</span><span class=\"number\">3</span><span class=\"punctuation\">,</span><span class=\"attr\">&quot;replicas&quot;</span><span class=\"punctuation\">:</span><span class=\"punctuation\">[</span><span class=\"number\">1</span><span class=\"punctuation\">,</span><span class=\"number\">0</span><span class=\"punctuation\">]</span><span class=\"punctuation\">&#125;</span><span class=\"punctuation\">]</span> </span><br><span class=\"line\"><span class=\"punctuation\">&#125;</span></span><br></pre></td></tr></table></figure>\n<ul>\n<li>执行 和 验证 副本存储计划</li>\n</ul>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-reassign-partitions.sh --bootstrap-server centos7:9092  --reassignment-json-file increase-replication-factor.json --execute</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">bin/kafka-reassign-partitions.sh --bootstrap-server centos7:9092  --reassignment-json-file increase-replication-factor.json --verify</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><font color=\"red\"><strong>Leader Partition负载平衡</strong></font></p>\n</blockquote>\n<p>问题出现的原因</p>\n<ul>\n<li>正常情况下，<code>Kafka</code>本身会自动把<code>Leader Partition</code> <code>均匀分散</code>在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些<code>broker</code>宕机，会导致<code>Leader Partition</code>过于集中在其他少部分几台<code>broker</code>上，这会导致少数几台<code>broker</code>的读写请求压力过高，其他宕机的<code>broker</code>重启之后都是<code>follower partition</code>，读写请求很低，造成集群负载不均衡。</li>\n</ul>\n<p>解决</p>\n<ul>\n<li>kafka出现了自动平衡的机制。kafka提供了下面几个参数进行控制：\n<ul>\n<li><code>auto.leader.rebalance.enable</code>：自动<code>leader parition</code>平衡，默认是true</li>\n<li><code>leader.imbalance.per.broker.percentage</code>：每个<code>broker</code>允许的不平衡的<code>leader</code>的比率，<code>默认是10%</code>，如果超过这个值，控制器将会触发<code>leader</code>的平衡</li>\n<li><code>leader.imbalance.check.interval.seconds</code>：检查<code>leader</code>负载是否平衡的时间间隔，<code>默认是300秒</code></li>\n<li>但是在生产环境中是不开启这个自动平衡，因为触发<code>leader partition</code>的自动平衡会损耗性能，一般会将其触发自动平和的参数<code>leader.imbalance.per.broker.percentage</code>的值调大点</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p><font color=\"red\"><strong>增加副本因子</strong></font></p>\n</blockquote>\n<p>由于<code>某个主题的重要等级需要提升</code>，我们考虑增加副本。副本数的增加需要先制定计划，然后根据计划执行</p>\n<ul>\n<li>\n<p>手动增加副本存储</p>\n<ul>\n<li>\n<p>创建副本存储计划（所有副本都指定存储在 broker0、broker1、broker2 中）</p>\n<figure class=\"highlight sh\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">vim increase-replication-factor.json</span><br><span class=\"line\"></span><br><span class=\"line\">&#123;<span class=\"string\">&quot;version&quot;</span>:1,<span class=\"string\">&quot;partitions&quot;</span>:[</span><br><span class=\"line\">&#123;<span class=\"string\">&quot;topic&quot;</span>:<span class=\"string\">&quot;four&quot;</span>,<span class=\"string\">&quot;partition&quot;</span>:0,<span class=\"string\">&quot;replicas&quot;</span>:[0,1,2]&#125;,</span><br><span class=\"line\">&#123;<span class=\"string\">&quot;topic&quot;</span>:<span class=\"string\">&quot;four&quot;</span>,<span class=\"string\">&quot;partition&quot;</span>:1,<span class=\"string\">&quot;replicas&quot;</span>:[0,1,2]&#125;,</span><br><span class=\"line\">&#123;<span class=\"string\">&quot;topic&quot;</span>:<span class=\"string\">&quot;four&quot;</span>,<span class=\"string\">&quot;partition&quot;</span>:2,<span class=\"string\">&quot;replicas&quot;</span>:[0,1,2]&#125;]&#125;</span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>执行副本存储计划</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bin/kafka-reassign-partitions.sh --bootstrap-server centos7:9092 --reassignment-json-file increase-replication-factor.json --execute</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"文件存储\">文件存储</h3>\n<h4 id=\"Kafka文件存储机制\">Kafka文件存储机制</h4>\n<blockquote>\n<p><font color=\"red\"><code>Topic</code> <strong>数据的存储机制</strong></font></p>\n</blockquote>\n<ul>\n<li>在Kafka中<code>主题（Topic）</code>是一个<code>逻辑</code>上的概念，<code>分区（partition）</code>是<code>物理</code>上的存在的。</li>\n<li>每个<code>partition</code>对应一个<code>log</code>文件，该<code>log</code>文件中存储的就是<code>Producer</code>生产的数据。<code>Producer</code>生产的数据会被不断追加到该<code>log文件末端</code>。</li>\n<li>为防止<code>log</code>文件过大导致数据定位效率低下，<code>Kafka</code>采用了分片和索引机制，将每个<code>partition</code>分为多个<code>segment</code>，每个<code>segment</code>默认<code>1G</code>（ <code>log.segment.bytes </code>）， 每个<code>segment</code>包括: <code>.index文件、.log文件和.timeindex等文件</code></li>\n<li>这些文件位于文件夹下，该文件命名规则为：<code>topic名称+分区号</code></li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306192127925.png\" alt=\"image-20230619212732859\" style=\"zoom:33%;\">\n<blockquote>\n<p><code>INDEX</code>文件</p>\n</blockquote>\n<ul>\n<li>\n<p><code>index</code>为稀疏索引，==大约每往log文件写入4kb数据，会往index文件写入一条索引==。参数<code>log.index.interval.bytes</code>默认4kb。这样的index索引文件就是一个<strong>稀疏索引</strong>，它并不会每条日志都建立索引信息。</p>\n</li>\n<li>\n<p><code>Index</code>文件中保存的offset为相对offset，这样能确保offset的值所占空间不会过大，因此能将offset的值控制在固定大小</p>\n</li>\n</ul>\n<blockquote>\n<p><code>时间戳索引(timeindex)文件</code></p>\n</blockquote>\n<ul>\n<li>作用\n<ul>\n<li>可以查询某一个时间段内的消息，它的数据结构是：<code>时间戳（8byte）+ 相对offset（4byte）</code>，如果要使用这个索引文件</li>\n<li>先要通过<code>时间范围</code>找到对应的<code>offset</code></li>\n<li>然后再去找对应的<code>index</code>文件找到<code>position</code>信息</li>\n<li>最后在<code>遍历log文件</code>，这个过程也是<code>需要用到index索引文件的</code></li>\n</ul>\n</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306192138841.png\" alt=\"image-20230619213824781\" style=\"zoom:33%;\">\n<blockquote>\n<p><code>log日志存储参数配置</code></p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>log.segment.bytes</td>\n<td>Kafka 中 log 日志是分成一块块存储的，此配置是指 log 日志划分成块的大小，默认值 1G。</td>\n</tr>\n<tr>\n<td>log.index.interval.bytes</td>\n<td>默认 4kb，kafka 里面每当写入了 4kb 大小的日志（.log），然后就往 index 文件里面记录一个索引；<code>index</code>是一种<code>稀疏索引</code></td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"文件清理策略\">文件清理策略</h4>\n<p>Kafka将消息存储在磁盘中，为了控制磁盘占用空间，避免不断增加就需要对消息做一定的<code>清理操作</code>。<code>Kafka</code> 中每一个分区副本都对应一个<code>Log</code>，而<code>Log</code>又可以分为<code>多个日志分段</code>，这样也<code>便于日志的清理操作</code></p>\n<p>kafka中<code>默认</code>的日志<code>保存时间</code>为<code>7天</code>，可以通过<code>调整如下参数修改</code>保存<code>时间</code></p>\n<ul>\n<li><code>log.retention.hours</code>：最低优先级小时，默认7天</li>\n<li><code>log.retention.minutes</code>：分钟</li>\n<li><code>log.retention.ms</code>：最高优先级毫秒</li>\n<li><code>log.retention.check.interval.ms</code>：负责设置检查周期，默认5分钟</li>\n<li><code>file.delete.delay.ms</code>：延迟执行删除时间</li>\n<li><code>log.retention.bytes</code>：当设置为-1时表示运行保留日志最大值（相当于关闭）；当设置为1G时，表示日志文件最大值</li>\n</ul>\n<blockquote>\n<p><code>Kafka</code>提供了<code>两种日志清理策略</code></p>\n</blockquote>\n<ul>\n<li>日志删除(<code>delete</code>) :按照一定的保留策略直接删除不符合条件的日志分段。</li>\n<li>日志压缩(<code>compact</code>) :针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本。我们可以通过修改<code>broker</code>端参数<code> log.cleanup.policy</code> 来进行配置</li>\n</ul>\n<blockquote>\n<p><font color=\"red\">日志删除: 将过期数据删除</font></p>\n</blockquote>\n<ul>\n<li>\n<p><code>log.cleanup.policy = delete</code> 所有数据启用删除策略</p>\n</li>\n<li>\n<p>具体的<code>保留日志策略</code>有2种：</p>\n<ul>\n<li>\n<p>基于时间策略</p>\n<ul>\n<li>日志删除任务会<code>周期检查</code>当前日志文件中是否有<code>保留时间超过设定的阈值</code>，来寻找<code>可删除的日志段文件集合</code></li>\n<li>这里需要注意<code>log.retention</code>参数的优先级：<code>log.retention.ms &gt; log.retention.minutes &gt; log.retention.hours</code>，默认只会配置<code>log.retention.hours</code>参数，值为<code>168</code>，即为<code>7</code>天。</li>\n<li>删除过期的日志段文件，并不是简单的根据日志段文件的修改时间计算，而是要根据该日志段中<code>最大的时间戳</code>来计算的，首先要<code>查询</code>该日志分段所对应的<code>时间戳索引文件</code>，查找该时间戳索引文件的最后一条索引数据，如果时间戳大于0就取值，否则才会使用最近修改时间。</li>\n<li>在删除的时候<code>先从Log对象所维护的日志段的跳跃表中移除要删除的日志段</code>，用来确保已经<code>没有线程</code>来读取这些日志段；接着将日志段所对应的所有文件，包括索引文件都添加上**.deleted的后缀；最后交给一个以delete-file命名的<code>延迟任务</code>来删除这些以.deleted为后缀的文件，<code>默认是1分钟执行一次</code>，<a href=\"http://xn--file-955fz0ybn7i7sa.delete.delay.ms\">可以通过file.delete.delay.ms</a>**来配置。</li>\n</ul>\n</li>\n<li>\n<p>基于日志大小策略</p>\n<ul>\n<li>日志删除任务会周期性检查当前<code>日志总大小</code>是否超过<code>设定的阈值</code>（<code>log.retention.bytes</code>，默认是<code>-1</code>，表示无穷大），就从第一个日志分段中寻找可删除的日志段文件集合。如果<code>超过</code>阈值，就删除最早的<code>segment</code></li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>基于日志大小的保留策略和基于时间的保留策略是<code>可以同时使用的</code></p>\n</blockquote>\n</li>\n</ul>\n<blockquote>\n<p>思考:<code>如果一个 segment 中有一部分数据过期，一部分没有过期，怎么处理</code></p>\n<ul>\n<li>当一个 Segment 中部分数据过期，而部分数据未过期时，Kafka 会优先删除过期的数据。这是因为 Kafka 日志保留策略默认采用时间戳索引（timestamp index）来管理消息的过期时间，因此到达过期时间的消息更容易被标记为过期数据并被删除。</li>\n<li>Kafka 会在 Segment 的下一个 Offset 处创建新的 Segment，并将未过期的数据写入到新的 Segment 中。这样，旧的 Segment 就可以被删除了，同时 Segment 文件不会出现不连续的情况。</li>\n<li>如果消息的过期时间比较长，导致未过期和过期的数据混杂在同一个 Segment 中，并且新消息写入速度较慢，那么就可能导致 Kafka 无法及时删除过期数据，从而影响性能。在这种情况下，可以考虑手动触发一次日志清理操作来强制删除过期的数据，或者调整 Segment 的大小，使得消息过期的频率更高。</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><font color=\"red\">日志压缩</font></p>\n</blockquote>\n<p>日志压缩对于有相同key的不同value值，只保留最后一个版本。</p>\n<ul>\n<li>\n<p>如果应用只关心 key对应的最新 value值，则可以开启 Kafka相应的日志清理功能，Kafka会定期将相同 key的消息进行合并，只保留最新的 value值。</p>\n</li>\n<li>\n<p><code>log.cleanup.policy = compact</code>所有数据启用压缩策略</p>\n</li>\n<li>\n<p>压缩后的<code>offset</code>可能是<code>不连续</code>的，比如下图中没有6，当从这些offset消费消息时，将会拿到比这个offset大 的offset对应的消息，实际上会拿到offset为7的消息，并从这个位置开始消费。</p>\n</li>\n<li>\n<p>这种策略只适合特殊场景，比如消息的key是用户ID，value是用户的资料，通过这种压缩策略，整个消息集里就保存了所有用户最新的资料。</p>\n</li>\n</ul>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306192156662.png\" alt></p>\n<h3 id=\"高效读写数据\">高效读写数据</h3>\n<blockquote>\n<p><font color=\"red\">kafka可以快速读写的原因：</font></p>\n</blockquote>\n<ol>\n<li>kafka是<code>分布式集群</code>，采用<code>分区方式</code>，<code>并行</code>操作</li>\n<li>读取数据采用<code>稀疏索引</code>，可以<code>快速定位</code>消费数据</li>\n<li><code>顺序写磁盘</code></li>\n<li><code>页缓冲</code>和<code>零拷贝</code></li>\n</ol>\n<blockquote>\n<p><font color=\"red\">顺序写磁盘</font></p>\n</blockquote>\n<p><code>Kafka</code> 的 <code>producer</code> 生产数据，要写入到 <code>log</code> 文件中，<code>写的过程</code>是一直<code>追加</code>到<code>文件末端</code>，为<code>顺序写</code>;顺序写之所以快，是因为其<code>省去了大量磁头寻址</code>的时间。</p>\n<blockquote>\n<p><font color=\"red\"><strong>页缓存+零拷贝技术</strong></font></p>\n</blockquote>\n<p><code>零拷贝</code></p>\n<p>零拷贝<code>并不是不需要拷贝</code>，而是<code>减少不必要的拷贝次数</code>，通常使用在IO读写过程中。</p>\n<ul>\n<li>\n<p>常规应用程序<code>IO</code>过程会经过四次拷贝：&lt;<code>见Netty</code>&gt;</p>\n<ol>\n<li>\n<p>数据从磁盘经过<code>DMA</code>(直接存储器访问)到内核的<code>Read Buffer</code></p>\n</li>\n<li>\n<p>内核态的<code>Read Buffer</code>到用户态应用层的<code>Buffer</code></p>\n</li>\n<li>\n<p>用户态的<code>Buffer</code>到内核态的<code>Socket Buffer</code></p>\n</li>\n<li>\n<p><code>Socket Buffer</code>到网卡的<code>NIC Buffer</code></p>\n</li>\n</ol>\n</li>\n<li>\n<p>从上面的流程可以知道<code>内核态和用户态</code>之间的拷贝相当于执行<code>两次无用的操作</code>，之间切换也会花费很多资源；</p>\n</li>\n<li>\n<p>当数据从磁盘经过DMA 拷贝到内核缓存（页缓存）后，为了减少CPU拷贝的性能损耗，操作系统<code>会将该内核缓存与用户层进行共享</code>，减少一次<code>CPU copy</code>过程，同时用户层的读写也会直接访问该共享存储，本身由用户层到Socket缓存的数据拷贝过程也变成了从<code>内核到内核的CPU拷贝过程</code>，更加的快速，这就是零拷贝</p>\n</li>\n<li>\n<p>甚至如果我们的<code>消息存在页缓存PageCache中</code>，还避免了<code>硬盘到内核的拷贝过程</code>，更加一步提升了消息的吞吐量。 (大概就理解成传输的数据只保存在内核空间，不需要再拷贝到用户态的应用层)</p>\n</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306192219174.png\" alt=\"image-20230619221925124\" style=\"zoom:5 3%;\">\n<blockquote>\n<p><font color=\"red\">提升kafka性能的原因</font></p>\n</blockquote>\n<ul>\n<li><code>Kafka</code>的数据加工处理操作交由Kafka生产者和Kafka消费者处理。<code>Kafka Broker</code>应用层不关心存储的数据，所以就不用走应用层，传输效率高</li>\n</ul>\n<p><code>PageCache 页缓存</code>：</p>\n<ul>\n<li>Kafka 重度依赖底层操作系统提供的<code>PageCache</code> 功能\n<ul>\n<li>读流程\n<ul>\n<li>当一个进程要去读取磁盘上的文件内容时，操作系统会<code>先查看</code>要读取的数据页是否缓冲在<code>PageCache</code> 中，\n<ul>\n<li>如果存在则直接返回要读取的数据，这就减少了对于磁盘<code> I/O</code>的 操作；</li>\n<li>但是如果没有查到，操作系统会向磁盘<code>发起读取请求</code>并将读取的数据页存入 <code>PageCache</code> 中，之后再将数据返回给进程</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>当上层有写操作时 ，操作系统<code>只是</code>将数据<code>写入</code> <code>PageCache</code>\n<ul>\n<li>写流程\n<ul>\n<li>如果一个进程需要将数据写入磁盘，操作系统会检查数据页是否在PageCache 中已经存在，\n<ul>\n<li>如果不存在就在 <code>PageCache</code>中添加相应的数据页，接着将数据写入对应的数据页</li>\n<li>另外<code>被修改过后的数据页</code>也就变成了<code>脏页</code></li>\n<li>操作系统会在<code>适当时间</code>将脏页中的数据<code>写入磁盘</code>，以保持数据的<code>一致性</code></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>当读操作发生时，先从<code>PageCache</code>中查找，如果找不到，再去磁盘中读取</li>\n<li>实际上<code>PageCache</code>是<code>尽可能多</code>的把空闲内存当做了磁盘缓存来使用</li>\n<li>刷盘时机；\n<ul>\n<li><code>同步刷盘</code>可以提高消息的可靠性，防止由于异常造成处于页缓存而没有及时写入磁盘的消息丢失。</li>\n<li>一般并不建议这么做，刷盘任务就应<strong>交由操作系统去调配</strong>，消息的<code>可靠性</code>应该由<code>多副本机制</code>来保障，而不是由同步刷盘这 种严重影响性能的行为来保障</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Kafka消费者\">Kafka消费者</h3>\n<blockquote>\n<p><font color=\"red\">常见的消费模式</font></p>\n</blockquote>\n<ul>\n<li><code>pull(拉)</code>：消费者主动<code>向服务端拉</code>取消息。</li>\n<li><code>push(推)</code>：服务端主动<code>推送消息给</code>消费者。</li>\n</ul>\n<blockquote>\n<p><font color=\"red\">kafka的模式——采用的是<code>pull的模式</code></font></p>\n</blockquote>\n<ul>\n<li>\n<p>缺点</p>\n<ul>\n<li>如果服务端没有消息，消费端就会一直空轮询</li>\n</ul>\n</li>\n<li>\n<p><code>kafka</code>的改进</p>\n<ul>\n<li>如果没消息服务端就会<code>暂时保持该请求</code>，在一段时间内<code>有消息再回应</code>给客户端</li>\n</ul>\n</li>\n<li>\n<p><code>kafka</code>为什么不用<code>push</code>的模式</p>\n<ul>\n<li>因为由<code>broker</code>决定消息发送速率，<code>很难适应所有消费者</code>的消费速率</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p><font color=\"red\">工作流程</font></p>\n</blockquote>\n<ul>\n<li>消费者对消息进行消费，并且将已经消费的消息加入<code> _consumer_offsets</code> 中</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306192339774.png\" alt=\"image-20230619233944737\" style=\"zoom: 50%;\">\n<blockquote>\n<p><font color=\"red\"><strong>消费者组原理</strong></font></p>\n</blockquote>\n<p><code>Consumer Group（CG）</code>：消费者组，由多个consumer组成。形成一个消费者组的条件：是所有消费者的<code>groupid</code>相同。</p>\n<ul>\n<li>\n<p>消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费。</p>\n</li>\n<li>\n<p>消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>\n</li>\n<li>\n<p>如果向消费组中添加更多的消费者，超过主题分区数量，则有一部分消费者就会闲置，不会接收任何消息。</p>\n</li>\n<li>\n<p>消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>\n</li>\n</ul>\n<blockquote>\n<ul>\n<li>如果所有的消费者都隶属于同一个消费组，那么所有的消息都会被均衡地投递给每一个消费者，即每条消息只会被一个消费者处理，这就相当于<code>点对点模式</code>的应用。</li>\n<li>如果所有的消费者都隶属于不同的消费组，那么所有的消息都会被广播给所有的消费者，即每条消息会被所有的消费者处理，这就相当于<code>发布／订阅模式</code>的应用</li>\n</ul>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200004363.png\" alt=\"image-20230620000453313\" style=\"zoom:33%;\">\n<blockquote>\n<p><font color=\"red\">消费者组初始化流程</font></p>\n</blockquote>\n<ul>\n<li>\n<p><code>coordinator</code>：辅助实现消费者组的<code>初始化和分区</code>的分配。</p>\n<ul>\n<li>\n<p><code>coordinator</code>节点选择 = <code>groupid的hashcode值 % 50（ __consumer_offsets的分区数量）</code></p>\n</li>\n<li>\n<p>例如： groupid的hashcode值 = 1，1% 50 = 1，那么__consumer_offsets 主题的1号分区，在哪个broker上，就选择这个节点的coordinator作为这个消费者组的老大。消费者组下的所有的消费者提交offset的时候就往这个分区去提交offset。</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>流程：</p>\n<ol>\n<li>每个<code>consumer</code>都发送<code>JoinGroup</code>请求 ==[黄线]==</li>\n<li>随机选出一个<code>consumer</code>作为<code>leader</code></li>\n<li>把要消费的<code>topic</code>情况发送给<code>leader</code> 消费者==[蓝线]==</li>\n<li><code>leader</code>会负责制定消费方案</li>\n<li>把消费方案发给<code>coordinator </code>  ==[黄线]==</li>\n<li><code>Coordinator</code>就把消费方案下发给各个<code>consumer</code> ==[绿线]==</li>\n<li>每个消费者都会和<code>coordinator</code>保持心跳（默认3s），一旦<code>超时</code>（<code>session.timeout.ms</code>=45s），该消费者会被移除，并触发再平衡；或者<code>消费者处理消息的时间过长</code>（<code>max.poll.interval.ms</code>=5分钟），也会触发再平衡</li>\n</ol>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200010156.png\" alt></p>\n<blockquote>\n<p><font color=\"red\">消费者组详细消费流程</font></p>\n</blockquote>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200018059.png\" alt></p>\n<ul>\n<li><code>ConsumerNetworkClient</code>   消费者网络连接客户端，主要是来和<code>kafka</code>集群进行交互</li>\n<li><code>ConsumerNetworkClient</code> 先调用<code>sendFetches</code>进行抓取每批次字节<code>bytes</code>，指定超时时间，即使最小值未达到超时时间也会在到达默认时间值得时候对其进行抓取，同时也会设置最大的抓取的字节大小</li>\n<li>准备完毕之后会对抓取到的数据进行<code>send</code>，并会产生回调，将拉取到的数据放入到消息队列中，（会设置每批次抓取的数据量条数；）消费者就会根据设置的拉去的条数进行拉取，并随后进行反序列化，随后经过拦截器的处理数据，</li>\n</ul>\n<blockquote>\n<p><font color=\"red\">消费者重要参数</font></p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>bootstrap.servers</td>\n<td>向 Kafka 集群建立初始连接用到的 host/port 列表</td>\n</tr>\n<tr>\n<td>key.deserializer 和 value.deserializer</td>\n<td>指定接收消息的 key 和 value 的反序列化类型。一定要写全类名。</td>\n</tr>\n<tr>\n<td><a href=\"http://group.id\">group.id</a></td>\n<td>标记消费者所属的消费者组。</td>\n</tr>\n<tr>\n<td>enable.auto.commit</td>\n<td>默认值为 true，消费者会自动周期性地向服务器提交偏移量。</td>\n</tr>\n<tr>\n<td><a href=\"http://auto.commit.interval.ms\">auto.commit.interval.ms</a></td>\n<td>如果设置了 enable.auto.commit 的值为 true， 则该值定义了消费者偏移量向 Kafka 提交的频率，默认 5s。</td>\n</tr>\n<tr>\n<td>auto.offset.reset</td>\n<td>当 Kafka 中没有初始偏移量或当前偏移量在服务器中不存在（如，数据被删除了），该如何处理？<br> earliest：自动重置偏移量到最早的偏移量。<br> latest：默认，自动重置偏移量为最新的偏移量。<br> none：如果消费组原来的（previous）偏移量不存在，则向消费者抛异常。<br> anything：向消费者抛异常。<br>offsets.topic.num.partitions __consumer_offsets 的分区数，默认是 50 个分区。</td>\n</tr>\n<tr>\n<td><a href=\"http://heartbeat.interval.ms\">heartbeat.interval.ms</a></td>\n<td>Kafka 消费者和 coordinator 之间的心跳时间，默认 3s。<br>该条目的值必须小于 <a href=\"http://session.timeout.ms\">session.timeout.ms</a> ，<a href=\"http://xn--session-3w3kyxxoq96lrw3hqvsb.timeout.ms\">也不应该高于session.timeout.ms</a> 的 1/3。</td>\n</tr>\n<tr>\n<td><a href=\"http://session.timeout.ms\">session.timeout.ms</a></td>\n<td>Kafka 消费者和 coordinator 之间连接超时时间，默认 45s。超过该值，该消费者被移除，消费者组执行再平衡。</td>\n</tr>\n<tr>\n<td><a href=\"http://max.poll.interval.ms\">max.poll.interval.ms</a></td>\n<td>消费者处理消息的最大时长，默认是 5 分钟。超过该值，该消费者被移除，消费者组执行再平衡。</td>\n</tr>\n<tr>\n<td>fetch.min.bytes</td>\n<td>默认 1 个字节。消费者获取服务器端一批消息最小的字节数。</td>\n</tr>\n<tr>\n<td><a href=\"http://fetch.max.wait.ms\">fetch.max.wait.ms</a></td>\n<td>默认 500ms。如果没有从服务器端获取到一批数据的最小字节数。该时间到，仍然会返回数据。</td>\n</tr>\n<tr>\n<td>fetch.max.bytes</td>\n<td>默认 Default: 52428800（50 m）。<br>消费者获取服务器端一批消息最大的字节数。<br>如果服务器端一批次的数据大于该值（50m）仍然可以拉取回来这批数据，因此，这不是一个绝对最大值。<br>一批次的大小受 message.max.bytes （broker config）or max.message.bytes （topic config）影响。</td>\n</tr>\n<tr>\n<td>max.poll.records</td>\n<td>一次 poll 拉取数据返回消息的最大条数，默认是 500 条。</td>\n</tr>\n<tr>\n<td>partition.assignment.strategy</td>\n<td>消 费 者 分 区 分 配 策 略 ， 默 认 策 略 是 Range +  CooperativeSticky。<br>Kafka 可以同时使用多个分区分配策略。<br>可 以 选 择 的 策 略 包 括 ： Range 、 RoundRobin 、 Sticky 、CooperativeSticky</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"消费者API\">消费者API</h4>\n<blockquote>\n<p>在消费者 <code>API</code> 代码中必须配置<code>消费者组 id</code>。</p>\n<p><code>命令行</code>启动消费者不填写消费者组id 会被<code>自动填写</code>随机的消费者组 id。</p>\n</blockquote>\n<blockquote>\n<p><font color=\"red\">消费者——单消费者</font></p>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200054231.png\" alt=\"image-20230620005412120\" style=\"zoom:33%;\">\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">CustomConsumer</span> &#123;</span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">static</span> <span class=\"keyword\">void</span> <span class=\"title function_\">main</span><span class=\"params\">(String[] args)</span> &#123;</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 1.创建消费者的配置对象</span></span><br><span class=\"line\">        <span class=\"type\">Properties</span> <span class=\"variable\">properties</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">Properties</span>();</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 2.给消费者配置对象添加参数</span></span><br><span class=\"line\">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class=\"string\">&quot;centos7:9092&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 配置序列化 必须</span></span><br><span class=\"line\">        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());</span><br><span class=\"line\">        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,StringDeserializer.class.getName());</span><br><span class=\"line\">        <span class=\"comment\">// 配置消费者组（组名任意起名） 必须</span></span><br><span class=\"line\">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class=\"string\">&quot;test&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 3.创建消费者对象</span></span><br><span class=\"line\">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class=\"keyword\">new</span> <span class=\"title class_\">KafkaConsumer</span>&lt;String, String&gt;(properties);</span><br><span class=\"line\">        <span class=\"comment\">// 注册要消费的主题（可以消费多个主题）</span></span><br><span class=\"line\">        ArrayList&lt;String&gt; topics = <span class=\"keyword\">new</span> <span class=\"title class_\">ArrayList</span>&lt;&gt;();</span><br><span class=\"line\">        topics.add(<span class=\"string\">&quot;first&quot;</span>);</span><br><span class=\"line\">        kafkaConsumer.subscribe(topics);</span><br><span class=\"line\">        <span class=\"comment\">// 拉取数据打印</span></span><br><span class=\"line\">        <span class=\"keyword\">while</span> (<span class=\"literal\">true</span>) &#123;</span><br><span class=\"line\">            <span class=\"comment\">// 设置 1s 中消费一批数据</span></span><br><span class=\"line\">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class=\"number\">1</span>));</span><br><span class=\"line\">            <span class=\"comment\">// 打印消费到的数据</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class=\"line\">                System.out.println(consumerRecord);</span><br><span class=\"line\">            &#125;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125; &#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><font color=\"red\">独立消费者案例（订阅分区）</font></p>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200100342.png\" alt=\"image-20230620010056266\" style=\"zoom:43%;\">\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 注册要消费的主题（可以消费多个主题）</span></span><br><span class=\"line\">        ArrayList&lt;String&gt; topics = <span class=\"keyword\">new</span> <span class=\"title class_\">ArrayList</span>&lt;&gt;();</span><br><span class=\"line\">        topics.add(<span class=\"string\">&quot;first&quot;</span>);</span><br><span class=\"line\">        kafkaConsumer.subscribe(topics);</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><font color=\"red\">消费者组——多消费者</font></p>\n</blockquote>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200054514.png\" alt=\"image-20230620005424455\" style=\"zoom:33%;\">\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">复制多份 `单消费者` 的代码，在 IDEA 中同时启动，即可启动 `多个消费者`</span><br></pre></td></tr></table></figure>\n<h4 id=\"分区的分配以及再平衡\"><strong>分区的分配以及再平衡</strong></h4>\n<ul>\n<li>\n<p>一个<code>consumer group</code>中有多个<code>consumer</code>组成，一个 <code>topic</code>有多个<code>partition</code>组成，现在的问题是，到底由哪个<code>consumer</code>来消费哪个<code>partition</code>的数据。</p>\n</li>\n<li>\n<p><code>Kafka</code>有四种主流的分区分配策略：<code> Range、RoundRobin、Sticky、CooperativeSticky</code></p>\n<ul>\n<li>可以通过配置参数<code>partition.assignment.strategy</code>，修改分区的分配策略。默认策略是<code>Range + CooperativeSticky</code></li>\n<li><code>Kafka</code>可以<code>同时使用多个分区分配策略</code></li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 修改分区分配策略</span></span><br><span class=\"line\">properties.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, <span class=\"string\">&quot;org.apache.kafka.clients.consumer.XXX&quot;</span>);</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><font color=\"red\">分区分配策略之Range——Range以及再平衡</font></p>\n</blockquote>\n<p>==分配==</p>\n<p>Range 是对每个 <code>topic</code> 而言的。首先对同一个 <code>topic</code> 里面的分区<code>按照序号进行排序</code>，并对消费者<code>按照字母顺序</code>进行排序。</p>\n<ul>\n<li>假如现在有 7 个分区，3 个消费者，排序后的分区将会是0,1,2,3,4,5,6；消费者排序完之后将会是C0,C1,C2。</li>\n</ul>\n<p>通过 <code>partitions数/consumer数</code> 来<code>决定每个消费者应该消费几个分区</code>。如果除不尽，那么前面几个消费者将会多消费 1 个分区。</p>\n<ul>\n<li>例如，7/3 = 2 余 1 ，除不尽，那么 消费者 C0 便会多消费 1 个分区。 8/3=2余2，除不尽，那么C0和C1分别多消费一个。</li>\n</ul>\n<p>注意：如果只是针对 1 个 topic 而言，C0消费者多消费1个分区影响不是很大。但是如果有 N 多个 topic，那么针对每个 topic，消费者 C0都将多消费 1 个分区，topic越多，C0消费的分区会比其他消费者明显多消费 N 个分区。<code>容易产生数据倾斜</code></p>\n<p>==再平衡==</p>\n<p>停止掉 某个消费者之后，消费者组<code>需要按照超时时间 45s </code>来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把<code>该消费者的任务</code>分配(分配的原则还是<code>重新按照 range 方式分配</code>)给其他 <code>broker</code> 执行,并且该消费者已经被踢出消费者组</p>\n<blockquote>\n<p>注意：kafka 中的分区数可以增多，但是不能减少</p>\n</blockquote>\n<blockquote>\n<p><font color=\"red\"><strong>RoundRobin</strong> <strong>分配以及再平衡</strong></font></p>\n</blockquote>\n<p>==分配==</p>\n<ul>\n<li>\n<p><code>RoundRobin</code> 针对集群中所有<code>Topic</code>而言</p>\n</li>\n<li>\n<p><code>RoundRobin轮询分区</code> 策略</p>\n<ul>\n<li>是把所有的 <code>partition</code> 和所有的<code>consumer</code> 都列出来，然后按照 <code>hashcode</code> 进行排序，最后通过<code>轮询算法</code>来分配 <code>partition</code> 给到各个消费者。</li>\n</ul>\n</li>\n</ul>\n<p>==再平衡==</p>\n<p>停止掉 某个消费者之后，消费者组<code>需要按照超时时间 45s </code>来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把<code>该消费者的任务</code>分配(分配的原则还是<code>重新按照 RoundRobin方式分配</code>)给其他 <code>broker</code> 执行,并且该消费者已经被踢出消费者组</p>\n<p><font color=\"red\"><strong>Sticky 分配以及再平衡</strong></font></p>\n<p>==分配==</p>\n<p>**粘性分区定义：**可以理解为分配的结果带有“粘性的”。</p>\n<ul>\n<li>\n<p>即在<code>执行一次新的分配之前</code>，考虑上一次分配的结果，<code>尽量少的调整分配的变动</code>，可以节省大量的开销。</p>\n</li>\n<li>\n<p>粘性分区是 <code>Kafka</code> 从 0.11.x 版本开始<code>引入这种分配策略</code></p>\n</li>\n<li>\n<p>首先会<code>尽量均衡的放置分区</code>到消费者上面，在出现 一个消费者<code>组内</code>某个消费者出现问题的时候，会尽量<code>保持原有分配的分区不变化</code></p>\n</li>\n</ul>\n<p>==再平衡==</p>\n<p>停止掉 某个消费者之后，消费者组<code>需要按照超时时间 45s </code>来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把<code>该消费者的任务</code>分配(分配的原则还是<code>重新按照 sticky 方式分配</code>)给其他 <code>broker</code> 执行,并且该消费者已经被踢出消费者组</p>\n<blockquote>\n<p><code>精髓</code>在于:  重分配后，还能尽量与上一次结果保持一致，进而达到消费者故障下线，故障恢复后的均衡问题</p>\n</blockquote>\n<h4 id=\"offset位移\"><strong>offset位移</strong></h4>\n<blockquote>\n<p><font color=\"red\"><strong>offset的默认维护位置</strong></font></p>\n</blockquote>\n<ul>\n<li>之前，<code>consumer</code>默认将<code>offset</code>保存在<code>Zookeeper</code>中</li>\n<li>现在，<code>consumer</code>默认将<code>offset</code>保存在<code>Kafka</code>一个内置的<code>topic</code>中，该<code>topic</code>为<code>_consumer_offsets</code></li>\n</ul>\n<p><code>_consumer_offsets </code>的<code>主题</code>里面采用 <code>key 和 value </code>的方式存储数据。<code>key</code> 是 <code>group.id+topic+分区号</code>，<code>value</code> 就是当前 <code>offset</code> 的值。每隔一段时间，kafka 内部会对这个 topic 进行<code>compact</code>，也就是让 每个 <code>group.id+topic+分区号</code>就保留最新数据</p>\n<ul>\n<li>\n<p>消费者提交的<code>offset</code>值维护在**_consumer_offsets这个Topic中，但是具体维护在哪个分区中，是由消费者所在的消费者组<code>groupid</code>**决定</p>\n</li>\n<li>\n<p>计算方式是：<code>groupid</code>的<code>hashCode % 50</code>。当<code>kafka</code>环境正常而<code>消费者不能消费时</code>的原因：有可能是对应的<code>_consumer_offsets</code>分区<code>leader</code>为<code>none</code>或<code>-1</code>，或者<code>分区中的日志文件损坏导致</code></p>\n</li>\n<li>\n<p>一般情况下， 当集群中第一次有消费者消费消息时会自动创建主题 <code>_consumer_offsets</code>, 不过它的副本因子还受<code>offsets.topic .replication.factor</code>参数的约束，这个参数的默认值为3 (下载安装的包中此值可能为1)，分区数可以通过<code>offsets.topic.num.partitions</code>参数设置，默认为<code>50</code>。</p>\n</li>\n<li>\n<p>在配置文件 <code>config/consumer.properties </code>中添加配置<code> exclude.internal.topics=false</code>，默认是 true，表示<code>不能消费系统主题</code>。为了查看该系统主题数据，所以该参数修改为 false。</p>\n</li>\n</ul>\n<blockquote>\n<p><font color=\"red\">提交offset</font></p>\n</blockquote>\n<p>消费者提交offset的方式有两种，<strong>自动提交</strong>和<strong>手动提交</strong></p>\n<ul>\n<li>\n<p><strong>自动提交offset</strong></p>\n<ul>\n<li>\n<p><code>Kafka</code>提供了<code>自动提交</code> <code>offset</code>的功能</p>\n</li>\n<li>\n<p>参数设置</p>\n<ul>\n<li><code>enable.auto.commit</code>：是否开启自动提交offset功能，<code>默认是true</code></li>\n<li><code>auto.commit.interval.ms</code>：自动提交offset的时间间隔，<code>默认是5s</code></li>\n</ul>\n</li>\n<li>\n<p>弊端</p>\n<ul>\n<li>自动提交有可能出现<code>消息消费失败</code>，但是<code>却提交了offset的情况</code>，导致<strong>消息丢失</strong>。为了能够实现消息<code>消费offset</code>的精确控制，更推荐<code>手动提交。</code></li>\n</ul>\n</li>\n<li>\n<p>java</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 自动提交</span></span><br><span class=\"line\">properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class=\"literal\">true</span>);</span><br><span class=\"line\"><span class=\"comment\">// 提交时间间隔</span></span><br><span class=\"line\">properties.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG,<span class=\"number\">1000</span>);</span><br></pre></td></tr></table></figure>\n</li>\n<li>\n<p>流程演示</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200207817.png\" alt=\"image-20230620020730779\" style=\"zoom:43%;\">\n</li>\n</ul>\n</li>\n<li>\n<p><strong>手动提交offset</strong></p>\n<ul>\n<li>\n<p>手动提交offset的方法有两种：分别是<code>commitSync</code>（同步提交）和<code>commitAsync</code>（异步提交）。</p>\n</li>\n<li>\n<p>两者的<code>相同点</code>是，都会将本次提交的<code>一批数据最高的偏移量</code>提交</p>\n</li>\n<li>\n<p>两者的<code>不同点</code>是</p>\n<ul>\n<li>\n<p>同步提交会阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）</p>\n</li>\n<li>\n<p>而异步提交则没有失败重试机制，故有可能提交失败。</p>\n</li>\n</ul>\n</li>\n<li>\n<p>commitSync（同步提交）：必须等待offset<code>提交完毕</code>，<code>再去</code>消费下一批数据。由于同步提交 offset 有失败重试机制，故更加可靠，但是由于一直等待提交结果，提交的效率比较低。</p>\n<ul>\n<li>\n<p>java</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 是否自动提交 offset</span></span><br><span class=\"line\">properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class=\"literal\">false</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 同步提交 offset</span></span><br><span class=\"line\">consumer.commitSync();</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>commitAsync（异步提交） ：发送完<code>提交offset请求</code>后，<code>就开始</code>消费下一批数据了。虽然同步提交 offset 更可靠一些，但是由于其会阻塞当前线程，直到提交成功。因此吞吐量会受到很大的影响。因此更多的情况下，会选用异步提交 offset 的方式</p>\n<ul>\n<li>\n<p>java</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 是否自动提交 offset</span></span><br><span class=\"line\">properties.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, <span class=\"literal\">false</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 异步提交 offset</span></span><br><span class=\"line\">consumer.commitAsync();</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p><font color=\"red\"><strong>指定消费Offset位置</strong></font></p>\n</blockquote>\n<p><code>auto.offset.reset = earliest | latest | none </code>      默认是 <code>latest</code></p>\n<p>当 <code>Kafka</code> 中<code>没有初始偏移量</code>（消费者组第一次消费）或<code>服务器上不再存在</code>当前偏移量时（例如该数据已被删除），该怎么办？</p>\n<p>（1）<code>earliest</code>：自动将偏移量重置为最<code>早</code>的偏移量;<code>--from-beginning</code> 的位置</p>\n<p>（2）<code>latest</code>(默认值)：自动将偏移量重置为最<code>新</code>偏移量</p>\n<p>（3）<code>none</code>：如果未找到消费者组的<code>先前偏移量</code>，则向消费者<code>抛出异常</code></p>\n<p>（4）任意指定 offset 位移开始消费</p>\n<ul>\n<li>Kafka中的<code>消费位移</code>是<code>存储</code>在一个<code>内部主题</code>中的， 而我们可以使用**<code>seek()</code>**方法可以突破这一限制\n<ul>\n<li><code>消费位移</code>可以保存在<code>任意的存储介质</code>中， 例如数据库、 文件系统等。</li>\n<li>以数据库为例， 我们将消费位移保存在其中的一个表中， 在下次消费的时候可以<code>读取</code>存储在数据表中的<code>消费位移</code>并通过<code>seek()</code>方法指向这个具体的位置</li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//配置信息</span></span><br><span class=\"line\"><span class=\"type\">Properties</span> <span class=\"variable\">properties</span> <span class=\"operator\">=</span> <span class=\"keyword\">new</span> <span class=\"title class_\">Properties</span>();</span><br><span class=\"line\">properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class=\"string\">&quot;latest&quot;</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 指定位置进行消费</span></span><br><span class=\"line\">Set&lt;TopicPartition&gt; assignment = kafkaConsumer.assignment();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//  保证分区分配方案已经制定完毕</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> (assignment.size() == <span class=\"number\">0</span>)&#123;</span><br><span class=\"line\">    kafkaConsumer.poll(Duration.ofSeconds(<span class=\"number\">1</span>));</span><br><span class=\"line\">    assignment = kafkaConsumer.assignment();</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 遍历所有分区，并指定 offset 从 1700 的位置开始消费</span></span><br><span class=\"line\"> <span class=\"keyword\">for</span> (TopicPartition tp: assignment) &#123;</span><br><span class=\"line\"> \tkafkaConsumer.seek(tp, <span class=\"number\">1700</span>);</span><br><span class=\"line\"> &#125;</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><font color=\"red\"><strong>指定时间消费</strong></font></p>\n</blockquote>\n<ul>\n<li>原理：\n<ul>\n<li>通过查到<code>时间对应</code>的<code>offset</code>去指定位移消费，为了确保能够同步到分区信息，我们还需要确保能<code>获取到分区</code>，再去<code>查询分区时间</code></li>\n</ul>\n</li>\n</ul>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//...</span></span><br><span class=\"line\"><span class=\"comment\">// 希望把时间转换为对应的offset</span></span><br><span class=\"line\">HashMap&lt;TopicPartition, Long&gt; topicPartitionLongHashMap = <span class=\"keyword\">new</span> <span class=\"title class_\">HashMap</span>&lt;&gt;();</span><br><span class=\"line\"><span class=\"comment\">// 封装对应集合</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (TopicPartition topicPartition : assignment) &#123;</span><br><span class=\"line\">    topicPartitionLongHashMap.put(topicPartition,System.currentTimeMillis() - <span class=\"number\">1</span> * <span class=\"number\">24</span> * <span class=\"number\">3600</span> * <span class=\"number\">1000</span>);</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\">Map&lt;TopicPartition, OffsetAndTimestamp&gt; topicPartitionOffsetAndTimestampMap = kafkaConsumer.offsetsForTimes(topicPartitionLongHashMap);</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 指定消费的offset</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> (TopicPartition topicPartition : assignment) &#123;</span><br><span class=\"line\">    <span class=\"type\">OffsetAndTimestamp</span> <span class=\"variable\">offsetAndTimestamp</span> <span class=\"operator\">=</span> topicPartitionOffsetAndTimestampMap.get(topicPartition);</span><br><span class=\"line\">    kafkaConsumer.seek(topicPartition,offsetAndTimestamp.offset());</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h4 id=\"漏消费和重复消费\">漏消费和重复消费</h4>\n<blockquote>\n<p><font color=\"red\"><strong>漏消费和重复消费</strong></font></p>\n</blockquote>\n<ul>\n<li>**重复消费：**已经消费了数据，但是 offset 没提交；自动提交offset引起。</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200227303.png\" alt=\"image-20230620022700263\" style=\"zoom:33%;\">\n<ul>\n<li>**漏消费：**先提交 offset 后消费，有可能会造成数据的漏消费；设置<code>offset</code>为手动提交，当<code>offset</code>被提交时，数据还在内存中未落盘，此时刚好消费者线程被<code>kill</code>掉，那么<code>offset</code>已经提交，但是数据未处理，导致这部分内存中的数据丢失。</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200228663.png\" alt=\"image-20230620022824605\" style=\"zoom:33%;\">\n<ul>\n<li>要想 既不漏消费也不重复消费; 可以使用 <code>消费者事务</code></li>\n</ul>\n<h4 id=\"消费者事务\">消费者事务</h4>\n<blockquote>\n<p><font color=\"red\">消费者事务</font></p>\n</blockquote>\n<p>如果想完成Consumer端的精准一次性消费，那么需要Kafka消费端将<code>消费过程和提交offset</code>过程做<code>原子绑定</code>。此时我们需要将Kafka的<code>offset</code>保存到支持事务的<code>自定义介质</code>（比 如MySQL）</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200230103.png\" alt=\"image-20230620023040073\" style=\"zoom:33%;\">\n<h4 id=\"数据积压\">数据积压</h4>\n<blockquote>\n<p><font color=\"red\"><strong>数据积压（提高吞吐量）</strong></font></p>\n</blockquote>\n<ul>\n<li>\n<p>产生原因</p>\n<ul>\n<li>如果是<code>Kafka</code>消费能力不足，则可以考虑增加<code>Topic</code>的<code>分区数</code>，并且同时提升<code>消费组的消费者</code>数量，<code>消费者数 = 分区数</code>（两者缺一不可）</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200233092.png\" alt=\"image-20230620023320059\" style=\"zoom:43%;\">\n<ul>\n<li>如果是下游的数据处理不及时：<code>提高每批次拉取的数量</code>。批次拉取数据过少（<code>拉取数据/处理时间 &lt; 生产速度</code>），使处理的数据小于生产的数据，也会造成数据积压</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200233966.png\" alt=\"image-20230620023329943\" style=\"zoom:43%;\">\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>参数名称</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>fetch.max.bytes</td>\n<td>默认Default: 52428800（50 m）。消费者获取服务器端一批消息最大的字节数。<br>如果服务器端一批次的数据大于该值（50m）仍然可以拉取回来这批数据<br>因此，这不是一个绝对最大值。<br>一批次的大小受<code> message.max.bytes （broker config）</code>or<code>max.message.bytes （topic config）</code>影响。</td>\n</tr>\n<tr>\n<td>max.poll.records</td>\n<td>一次 poll 拉取数据返回消息的最大条数，默认是 500 条</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"拦截器\">拦截器</h4>\n<blockquote>\n<p>消费者也有拦截器</p>\n</blockquote>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">interface</span> <span class=\"title class_\">ConsumerInterceptor</span>&lt;K, V&gt; <span class=\"keyword\">extends</span> <span class=\"title class_\">Configurable</span>, AutoCloseable &#123;</span><br><span class=\"line\">    ConsumerRecords&lt;K, V&gt; <span class=\"title function_\">onConsume</span><span class=\"params\">(ConsumerRecords&lt;K, V&gt; records)</span>;</span><br><span class=\"line\">    <span class=\"keyword\">void</span> <span class=\"title function_\">onCommit</span><span class=\"params\">(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets)</span>;</span><br><span class=\"line\">    <span class=\"keyword\">void</span> <span class=\"title function_\">close</span><span class=\"params\">()</span>;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p><code>onConsume详解</code></p>\n<ul>\n<li>Kafka <code>Consumer</code>会在<code>poll()</code>方法返回<code>之前</code>调用拦截器的<code>onConsume()</code>方法来对消息进行相应的<code>定制化操作</code>，比如修改返回的消息内容、按照某种规则过滤消息（可能会减少poll()方法返回 的消息的个数）。如果<code>onConsume()</code>方法中<code>抛出异常</code>， 那么会被捕获并记录到<code>日志中</code>， 但是异常不会再向上传递。</li>\n<li>Kafka <code>Consumer</code>会在提交完消费位移之后调用拦截器的**<code>onCommit()</code>**方法， 可以使用这个方法来记录跟踪所提交的<code>位移信息</code>，比如当消费者使用<code>commitSync</code>的无参方法时，我们不知道提交的消费位移的具体细节， 而使用拦截器的<code>onCommit()</code>方法却可以做到这 一点</li>\n</ul>\n<h3 id=\"Kafka压测\">Kafka压测</h3>\n<blockquote>\n<p><font color=\"red\"><strong>Kafka压测</strong></font></p>\n</blockquote>\n<p>用 Kafka 官方自带的脚本，对 Kafka 进行压测。</p>\n<ul>\n<li>\n<p>生产者压测：<a href=\"http://kafka-producer-perf-test.sh\">kafka-producer-perf-test.sh</a></p>\n</li>\n<li>\n<p>消费者压测：<a href=\"http://kafka-consumer-perf-test.sh\">kafka-consumer-perf-test.sh</a></p>\n</li>\n</ul>\n<blockquote>\n<p><font color=\"red\"><strong>Kafka Producer压力测试</strong></font></p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>record-size</td>\n<td>一条信息有多大，单位是字节</td>\n</tr>\n<tr>\n<td>num-records</td>\n<td>总共发送多少条信息</td>\n</tr>\n<tr>\n<td>throughput</td>\n<td>每秒多少条信息，设成-1，表示不限流，尽可能快的生产数据，可测出生产者最大吞吐量</td>\n</tr>\n<tr>\n<td>producer-props</td>\n<td>后面可以配置生产者相关参数，batch.size 配置为 16k</td>\n</tr>\n</tbody>\n</table>\n<blockquote>\n<p><font color=\"red\"><strong>Kafka Consumer压力测试</strong></font></p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>参数</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>–bootstrap-server</td>\n<td>指定 Kafka 集群地址</td>\n</tr>\n<tr>\n<td>–topic</td>\n<td>指定 topic 的名称</td>\n</tr>\n<tr>\n<td>–messages</td>\n<td>总共要消费的消息个数</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"进阶\">进阶</h2>\n<h3 id=\"Springboot的集成\">Springboot的集成</h3>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200303101.png\" alt=\"image-20230620030326056\" style=\"zoom:33%;\">\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">dependencies</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-starter-web<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.kafka<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-kafka<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\"></span><br><span class=\"line\">       <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.projectlombok<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>lombok<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">optional</span>&gt;</span>true<span class=\"tag\">&lt;/<span class=\"name\">optional</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.boot<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-boot-starter-test<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">groupId</span>&gt;</span>org.springframework.kafka<span class=\"tag\">&lt;/<span class=\"name\">groupId</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">artifactId</span>&gt;</span>spring-kafka-test<span class=\"tag\">&lt;/<span class=\"name\">artifactId</span>&gt;</span></span><br><span class=\"line\">           <span class=\"tag\">&lt;<span class=\"name\">scope</span>&gt;</span>test<span class=\"tag\">&lt;/<span class=\"name\">scope</span>&gt;</span></span><br><span class=\"line\">       <span class=\"tag\">&lt;/<span class=\"name\">dependency</span>&gt;</span></span><br><span class=\"line\">   <span class=\"tag\">&lt;/<span class=\"name\">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight properties\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 应用名称</span></span><br><span class=\"line\"><span class=\"attr\">spring.application.name</span>=<span class=\"string\">kafkademo</span></span><br><span class=\"line\"><span class=\"comment\"># 指定 kafka 的地址</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.bootstrap.servers</span>=<span class=\"string\">centos7:9092</span></span><br><span class=\"line\"><span class=\"comment\">#指定 key 和 value 的序列化器</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.producer.key.serializer</span>=<span class=\"string\">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.producer.value.serializer</span>=<span class=\"string\">org.apache.kafka.common.serialization.StringSerializer</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">spring.kafka.consumer.group-id</span>=<span class=\"string\">test</span></span><br></pre></td></tr></table></figure>\n<blockquote>\n<p><font color=\"red\"><code>Springboot</code>当做消费者</font></p>\n</blockquote>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">@Configuration</span></span><br><span class=\"line\"><span class=\"keyword\">public</span> <span class=\"keyword\">class</span> <span class=\"title class_\">KafkaConfiguration</span>&#123;</span><br><span class=\"line\">    <span class=\"meta\">@KafkaListener(topics = &#123;&quot;first&quot;&#125;)</span>   <span class=\"comment\">//监听的 topic </span></span><br><span class=\"line\">    <span class=\"keyword\">public</span> <span class=\"keyword\">void</span> <span class=\"title function_\">message1</span><span class=\"params\">(ConsumerRecord&lt;?, ?&gt; record)</span>&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 消费的哪个topic、partition的消息,打印出消息内容</span></span><br><span class=\"line\">        System.out.println(<span class=\"string\">&quot;点对点消费1：&quot;</span>+record.topic()+<span class=\"string\">&quot;-&quot;</span>+record.partition()+<span class=\"string\">&quot;-&quot;</span>+record.value());</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<h2 id=\"面试\">面试</h2>\n<ol>\n<li>\n<p>生产者原理?<br>\n简述： 首先main线程作为消息生产的主线程，经过拦截器（处理消息），再到序列化器（非JDK自带），最后到分区器，分区器维护 Record Accumulator（消息累加器），用于将多个消息合并成一个批次。</p>\n<p>Sender线程是专门用于消息发送的线程，当 Record Accumulator中的 双端队列的batch size 大小达到16k 或者 超出等待时间 就会触发Sender线程，sender线程有一个请求池，请求消息累加器中的消息发送给Kafka Broker 就会得到ack 应答 ，ack应答成功就会生成累加器中的消息批次、失败则会进行重试，默认能接受五个请求没有被应答（避免消息丢失，且异步），没有 拉取消费发送至Kafka集群。</p>\n</li>\n<li>\n<p>为什么需要额外实现序列化器<br>\nJDK自带的序列化器太重</p>\n</li>\n<li>\n<p>数据乱序怎么解决<br>\nKafka单分区内的数据有序，原因是In Flight Requests，默认每个broker缓存五个请求，当出现乱序时会自动排序。</p>\n</li>\n<li>\n<p>在存储日志的时候，它的索引是按照什么方法存储的？<br>\n日志是按照稀疏索引的方式存储的，每往log文件写入4kb数据，就会往index文件写入一条索引。且保存的是相对的offset，避免占用过多的空间。</p>\n</li>\n<li>\n<p>如何高效的读写数据？<br>\n**顺序读写：**磁盘分为顺序读写与随机读写，基于磁盘的随机读写确实很慢，但磁盘的顺序读写性能却很高，kafka 这里采用的就是顺序读写。<br>\nPage Cache：为了优化读写性能，Kafka 利用了操作系统本身的 Page Cache。数据直接写入page cache定时刷新脏页到磁盘即可。消费者拉取消息时，如果数据在page cache中，甚至能不需要去读磁盘io。读操作可直接在 Page Cache 内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过 Page Cache）交换数据。<br>\nBroker 收到数据后，写磁盘时只是将数据写入 Page Cache，并不保证数据一定完全写入磁盘。从这一点看，可能会造成机器宕机时，Page Cache 内的数据未写入磁盘从而造成数据丢失。但是这种丢失只发生在机器断电等造成操作系统不工作的场景，而这种场景完全可以由 Kafka 层面的 Replication 机制去解决。如果为了保证这种情况下数据不丢失而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。也正因如此，Kafka 虽然提供了flush.messages和flush.ms两个参数将 Page Cache 中的数据强制 Flush 到磁盘，但是 Kafka 并不建议使用。</p>\n<p>**零拷贝：**Kafka使用了零拷贝技术，也就是直接将数据从内核空间的读缓冲区直接拷贝到内核空间的 socket 缓冲区，然后再写入到 NIC 缓冲区，避免了在内核空间和用户空间之间穿梭。<br>\n分区分段+稀疏索引Kafka 的 message 是按 topic分 类存储的，topic 中的数据又是按照一个一个的 partition 即分区存储到不同 broker 节点。每个 partition 对应了操作系统上的一个文件夹，partition 实际上又是按照segment分段存储的。通过这种分区分段的设计，Kafka 的 message 消息实际上是分布式存储在一个一个小的 segment 中的，每次文件操作也是直接操作的 segment。为了进一步的查询优化，Kafka 又默认为分段后的数据文件建立了索引文件，就是文件系统上的.index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。</p>\n<p>**批量读写：**生产者可以借助累加器，批量发送消息，消费者也可以批量拉取消费。Kafka 数据读写也是批量的而不是单条的,这样可以避免在网络上频繁传输单个消息带来的延迟和带宽开销。假设网络带宽为10MB/S，一次性传输10MB的消息比传输1KB的消息10000万次显然要快得多。<br>\n数据压缩:Producer 可将数据压缩后发送给 broker，从而减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4。数据压缩一般都是和批处理配套使用来作为优化手段的。</p>\n</li>\n<li>\n<p>零拷贝原理是什么？<br>\n**零拷贝：**Kafka使用了零拷贝技术，也就是直接将数据从内核空间的读缓冲区直接拷贝到内核空间的 socket 缓冲区，然后再写入到 NIC 缓冲区，避免了在内核空间和用户空间之间穿梭。</p>\n</li>\n<li>\n<p>什么是用户态？ 什么是内核态？<br>\n用户态（User Mode）：当进程在执行用户自己的代码时，则称其处于用户运行态。<br>\n内核态（Kernel Mode）：当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态，此时处理器处于特权级最高的内核代码中执行。</p>\n<p>为什么分内核态和用户态？<br>\n假设没有内核态和用户态之分，程序就可以随意读写硬件资源了，比如随意读写和分配内存，这样如果程序员一不小心将不适当的内容写到了不该写的地方，很可能就会导致系统崩溃。</p>\n<p>而有了用户态和内核态的区分之后，程序在执行某个操作时会进行一系列的验证和检验之后，确认没问题之后才可以正常的操作资源，这样就不会担心一不小心就把系统搞坏的情况了，也就是有了内核态和用户态的区分之后可以让程序更加安全的运行，但同时两种形态的切换会导致一定的性能开销。</p>\n</li>\n<li>\n<p>消费者初始化流程是什么样的？<br>\n通过对GroupId进行Hash得到那台服务器的coordinator ，coordinator负责选出消费组中的Leader ，并且协调信息。真正存储消费记录的是 _consumer_offsets_partition 。</p>\n</li>\n<li>\n<p>如何做到精确一次性消费？<br>\n开启事务 ，以及幂等性</p>\n<p>生产者端 -&gt; 集群</p>\n<p>集群 -&gt; 消费者</p>\n<p>消费者-&gt; 框架(数据库)</p>\n</li>\n<li>\n<p>为什么kafka不做读写分离？<br>\n读写分离是指生产者发送到Leader副本，消费者从Follower副本读取。</p>\n<ol>\n<li>\n<p>延时问题：数据从leader副本到follow副本是需要过程的，从网络&gt;主节点内存 -&gt;主节点磁盘 -&gt; 网络 -&gt; 从节点内存 -&gt; 从节点磁盘，比较耗时不适合对实时性要求高的应用。</p>\n</li>\n<li>\n<p>负载均衡：读写分离，很大一部分原因是怕同一个节点负载过大。但是kafka通过分区的负载均衡，天然的就均衡了各个broker的压力。</p>\n</li>\n</ol>\n</li>\n<li>\n<p>如何保证Kafka消息可靠性？<br>\n生产端：ack设置为-1，保证消息同步到follower副本。发送消息方式设置为同步或者异步，做好失败回滚措施<br>\nbroker端：页缓存pagecache设置直接刷盘模式，确保不会有消息在页缓存中的时候宕机。<br>\n消费端：关闭消息自动提交，改为手动提交。避免消息没消费完就提交了offset导致消息丢失<br>\n总得来说，要保证严格的可靠性，就会失去很大的可用性，这是一个平衡的过程。</p>\n</li>\n<li>\n<p>消息堆积怎么办？<br>\n我们都知道，消息的消费速度取决于消费者的速度，在消费速度不变的情况下，增加分组内消费者的个数，能倍速的提高消费速度。而消费者的个数又受限于分区个数，消费者个数超过分区数后，再提高消费者个数就没有意义。</p>\n<p>为了能够再提高临时的速度，我们还可以设置临时topic在临时主题中，去加大分区数，将所有原消费者直接将消息再次投递到临时topic中，进行更大规模消费群的消费。这是一个取巧的方案，适合解决临时大量消息的堆积。</p>\n</li>\n<li>\n<p>分区数越多，吞吐量就会越高吗？<br>\n在一定条件下，分区数的数量是和吞吐量成正比的，分区数和性能也是成正比的。但是超过了限度后，不升反降。</p>\n<p>从以下四个方面来阐述：</p>\n<ol>\n<li>\n<p>客户端/服务器端需要使用的内存就越多</p>\n<p>服务端在很多组件中都维护了分区级别的缓存，比如controller，FetcherManager等，分区数越大，缓存成本也就越大。<br>\n消费端的消费线程数是和分区数挂钩的，分区数越大消费线程数也就越多，线程的开销成本也就越大<br>\n生产者发送消息有缓存的概念，会为每个分区缓存消息，当积累到一定程度或者时间时会将消息发送到分区，分区越多，这部分的缓存也就越大</p>\n</li>\n<li>\n<p>文件句柄的开销</p>\n<p>每个 partition 都会对应磁盘文件系统的一个目录。在 Kafka 的数据日志文件目录中，每个日志数据段都会分配两个文件，一个索引文件和一个数据文件。每个 broker 会为每个日志段文件打开一个 index 文件句柄和一个数据文件句柄。因此，随着 partition 的增多，所需要保持打开状态的文件句柄数也就越多，最终可能超过底层操作系统配置的文件句柄数量限制。</p>\n</li>\n<li>\n<p>越多的分区可能增加端对端的延迟</p>\n<p>Kafka 会将分区 HW 之前的消息暴露给消费者。分区越多则副本之间的同步数量就越多，在默认情况下，每个 broker 从其他 broker 节点进行数据副本复制时，该 broker 节点只会为此工作分配一个线程，该线程需要完成该 broker 所有 partition 数据的复制。</p>\n</li>\n<li>\n<p>降低高可用性</p>\n<p>Kafka通过副本(replica)机制来保证高可用。具体做法就是为每个分区保存若干个副本(replica_factor指定副本数)。每个副本保存在不同的broker上。其中的一个副本充当leader 副本，负责处理producer和consumer请求。其他副本充当follower角色，由Kafka controller负责保证与leader的同步。如果leader所在的broker挂掉了，contorller会检测到然后在zookeeper的帮助下重选出新的leader——这中间会有短暂的不可用时间窗口，虽然大部分情况下可能只是几毫秒级别。但如果你有10000个分区，10个broker，也就是说平均每个broker上有1000个分区。此时这个broker挂掉了，那么zookeeper和controller需要立即对这1000个分区进行leader选举。比起很少的分区leader选举而言，这必然要花更长的时间，并且通常不是线性累加的。如果这个broker还同时是controller情况就更糟了。</p>\n</li>\n</ol>\n</li>\n<li>\n<p>kafka如何提升吞吐量</p>\n<ul>\n<li><strong>提升生产吞吐量</strong></li>\n<li><strong>增加分区</strong></li>\n<li><strong>消费者提高吞吐量</strong></li>\n<li><strong>增加下游消费者处理能力</strong></li>\n</ul>\n</li>\n<li>\n<p><strong>数据精准一次如何实现</strong></p>\n<ul>\n<li>\n<p><strong>生产者角度</strong></p>\n<ul>\n<li>acks 设置为-1 （acks=-1）</li>\n<li>幂等性（enable.idempotence = true） + 事务 。</li>\n</ul>\n</li>\n<li>\n<p><strong>broker</strong> <strong>服务端角度</strong></p>\n<ul>\n<li>\n<p>分区副本大于等于 2 （–replication-factor 2）。</p>\n</li>\n<li>\n<p>ISR 里应答的最小副本数量大于等于 2 （min.insync.replicas = 2）。</p>\n</li>\n</ul>\n</li>\n<li>\n<p>消费者**</p>\n<ul>\n<li>\n<p>事务 + 手动提交 offset （enable.auto.commit = false）</p>\n</li>\n<li>\n<p>消费者输出的目的地必须支持事务（MySQL、Kafka）</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>服务器挂了怎么办</strong></p>\n<p>在生产环境中，如果某个 Kafka 节点挂掉。</p>\n<p>正常处理办法：</p>\n<p>（1）先尝试重新启动一下，如果能启动正常，那直接解决。</p>\n<p>（2）如果重启不行，考虑增加内存、增加 CPU、网络带宽。</p>\n<p>（3）如果将 kafka 整个节点误删除，如果副本数大于等于 2，可以按照服役新节点的方式重新服役一个新节点，并执行负载均衡</p>\n</li>\n</ol>\n<h2 id=\"终极\">终极</h2>\n<h3 id=\"源码\">源码</h3>\n","_path":"post/9a7d5a13.html","_link":"http://rycan.top/post/9a7d5a13.html","_id":"cln1a3w9d000bgg0p99ns9b47"}}