{"type":"getPostByPath","data":{"title":"MQ","date":"2023-09-13T15:38:19.000Z","description":"面试精选","categories":[{"name":"FaceToFace","_id":"clnscmc9g0011a80p8n9c3iso"}],"tags":[{"name":"MQ","_id":"clnscmc9m002ca80p8toghxif"}],"content":"<meta name=\"referrer\" content=\"no-referrer\">\n\n<h1 id=\"MQ\"><a href=\"#MQ\" class=\"headerlink\" title=\"MQ\"></a>MQ</h1><p>1、同步通信</p>\n<p>​    优点：实时响应，可以立即得到结果</p>\n<p>​    缺点：每次都要等待提供者的响应，调用链的长度决定最后的响应时长；</p>\n<p>​                每次产生新的需求之后的都要修改原来的代码，耦合度都太高；</p>\n<p>​                调用链上的服务都在等待响应，所以不能释放请求占用的资源，高并发场景下极度浪费资源；</p>\n<p>​                可能会出现级联故障</p>\n<p>2、异步通信</p>\n<p>​        收发双方通过一个broker进行通信，收发双方对broker进行订阅获取消息；从而达到不需要花费时间等待响应结果就能直接返回</p>\n<p>3、MQ</p>\n<p>​        一种常见的上下游的消息通信服务。使用了 MQ 之后，消息发送的<code>上游</code>只需要依赖 MQ，不用依赖其他服务</p>\n<p>​    3.1、作用</p>\n<p>​        <strong>3.1.1、流量削峰：</strong>使用消息队列做缓冲，秒杀活动中 也可以控制活动人数，超过此一定阀值的订单直接丢弃，还可以缓解短时间的高流量压垮应用</p>\n<p>​        <strong>3.1.2、应用解耦：</strong>比如物流系统因为发生故障，需要几分钟来修复。在这几分钟的时间里，物流系统要处理的内存被缓存在消息队列中，用户的下单操作可以正常完成。当物流系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性。</p>\n<p>​        <strong>3.1.3、异步处理：</strong>比如用户注册后，需要发注册邮件和注册短信,引入消息队列后，把发送邮件、短信这些不是必须的业务逻辑异步处理</p>\n<p>​    3.2、分类</p>\n<p>​        <strong>ActiveMQ</strong>  —优点：单机吞吐量万级，可用性高，基于<code>主从架构</code>实现高可用性，消息可靠性以较低的概率丢失数据    —缺点：高吞吐量场景较少使用</p>\n<p>​        <strong>Kafka</strong>—优点：百万级 TPS 的吞吐量；吞吐量高；时效性 ms 级可用性非常高，kafka 是分布式的，一个数据有多个副本，少数机器宕机，不会丢失数据，不会导致不可用；消费者采用 Pull 方式获取消息，消息有序，通过控制能够保证所有消息被消费且仅被消费一次；—缺点：Kafka 单机超过 64 个队列/分区，Load 会发生明显的飙高现象，队列越多，load 越高，发送消息响应时间变长；使用短轮询方式，实时性取决于轮询间隔时间，<code>消费失败不支持重试；支持消息顺序，但是一台代理宕机后，就会产生消息乱序</code>，</p>\n<p>​        <strong>RocketMQ</strong>—优点：单机吞吐量十万级，可用性非常高，分布式架构,消息可以做到 <code>0 丢失</code>,MQ 功能较为完善，还是<code>分布式的</code>，扩展性好,支持 10 亿级别的消息堆积，不会因为堆积导致性能下降  —缺点：支持的客户端语言不多</p>\n<p>​        <strong>RabbitMQ</strong> —优点：性能较好；吞吐量到万级，MQ 功能比较完备,健壮、稳定、易用、跨平台、支持多种语言 如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等，支持 AJAX 文档齐全</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\"></th>\n<th><strong>RabbitMQ</strong></th>\n<th><strong>ActiveMQ</strong></th>\n<th><strong>RocketMQ</strong></th>\n<th><strong>Kafka</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">可用性</td>\n<td>高</td>\n<td>一般</td>\n<td>高</td>\n<td>高</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">单机吞吐量</td>\n<td>一般</td>\n<td>差</td>\n<td>高</td>\n<td>非常高</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">消息延迟</td>\n<td>微秒级</td>\n<td>毫秒级</td>\n<td>毫秒级</td>\n<td>毫秒以内</td>\n</tr>\n<tr>\n<td style=\"text-align:left\">消息可靠性</td>\n<td>高</td>\n<td>一般</td>\n<td>高</td>\n<td>一般</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>4、</p>\n<h2 id=\"RabbitMQ\"><a href=\"#RabbitMQ\" class=\"headerlink\" title=\"RabbitMQ\"></a>RabbitMQ</h2><h3 id=\"1、作用\"><a href=\"#1、作用\" class=\"headerlink\" title=\"1、作用\"></a>1、作用</h3><p>​        接收存储转发消息</p>\n<h3 id=\"2、基本概念\"><a href=\"#2、基本概念\" class=\"headerlink\" title=\"2、基本概念\"></a>2、基本概念</h3><p>生产者（产生数据，发送消息）、交换机（接受生产者发送的消息并推送消息到队列中）、队列（本质是一个大的消息缓冲区，暂存消息的）、消费者</p>\n<h3 id=\"3、基本组成\"><a href=\"#3、基本组成\" class=\"headerlink\" title=\"3、基本组成\"></a>3、基本组成</h3><p><code>Broker</code>：接收和分发消息的应用、<code>Connection</code>：publisher／consumer 和 broker 之间的 TCP 连接、<code>Channel</code>：在 connection 内部建立的逻辑连接、<code>Exchange</code>：根据分发规则，匹配<code>routing key</code>;将消息分发到 queue 中去、<code>Queue</code>：消息最终被送到这里被 consumer 消费、<code>Binding</code>：exchange 和 queue 之间的虚拟连接，binding 中可以包含 routing key，Binding 信息被保 存到 exchange 中的查询表中，用于 message 的分发依据</p>\n<h3 id=\"4、支持的消息模型\"><a href=\"#4、支持的消息模型\" class=\"headerlink\" title=\"4、支持的消息模型\"></a>4、支持的消息模型</h3><p>1、<strong>简单队列</strong></p>\n<p>​         简单直连的方式 ：   P (发消息)—&gt;queue —&gt; C（收消息）   <code>1P1C</code></p>\n<p>2、<strong>任务队列（work queue）</strong>    <code>nC1P</code></p>\n<p>​        消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度,防止此时的消息就会堆积越来越多，无法及时处理；此时就可以让多个消费者绑定到一个队列，共同消费队列中的消息。队列中的消息一旦消费，就会消失，因此任务是不会被重复执行的。</p>\n<p>​        主要思想就是：将任务封装为消息然后发送到队列中，后台的工作进程进行取出任务并执行，有多个工作线程的时候就会一起处理这些任务</p>\n<p>​        轮询消费：轮流消费消息，即每个工作队列都会获取一个消息进行消费，并且获取的次数按照顺序依次往下轮流。注意此时的消息只要被处理一次就直接丢掉</p>\n<p>3、广播模型（fanout）</p>\n<p><img src=\"https://img2020.cnblogs.com/blog/1552936/202010/1552936-20201024111132337-2067061320.png\" alt=\"img\"></p>\n<p>生产者将消息给交换机，交换机根据自身的类型（fanout）将会把所有消息复制同步到所有与其绑定的队列，每个队列可以有一个消费者接收消息进行消费逻辑。需要我们自己创建交换器并进行绑定，创建多个队列进行绑定即可，若一个消费者绑定多个队列则进行轮询，因为mq有阅后即焚的特点，只能保证一个消费者阅读接受。常用于群发消息。</p>\n<p>4、路由模型（direct）</p>\n<p><img src=\"https://img2020.cnblogs.com/blog/1552936/202010/1552936-20201024111740732-646083741.png\" alt=\"img\"></p>\n<p>生产者将消息发送到交换机信息携带具体的路由key,交换机的类型是direct，将接收到的信息中的routingKey,比对与之绑定的队列routingkey。消费者监听一个队列，获取消息，执行消费逻辑。一个队列可以绑定一个routingKey也可以绑定多个。在消息进行路由时会携带一个routingKey寻找对应的队列。</p>\n<p>5、订阅模型（动态路由模型 topic）</p>\n<p><img src=\"https://img2020.cnblogs.com/blog/1552936/202010/1552936-20201024112007131-2087515653.png\" alt=\"img\"></p>\n<p>生产者发送消息，消息中带有具体的路由key，交换机的类型是topic，队列绑定交换机不在使用具体的路由key而是一个范围值，例如: <em>.yell.</em>,hlll.iii,jjj.#。其中* 表示一个字符串（不能携带特殊字符）#表示任意</p>\n<h3 id=\"5、消息应答\"><a href=\"#5、消息应答\" class=\"headerlink\" title=\"5、消息应答\"></a>5、消息应答</h3><p>1、什么是消息应答： 消费者在<code>接收到消息并且处理完</code>该消息之后，告诉 rabbitmq 它已经处理了，rabbitmq 可以把该消息删除了。</p>\n<p>2、作用：保证消息在发送过程中不丢失</p>\n<p>3、应答机制：</p>\n<p>​    3.1、自动应答(自动确认机制) ： 消息发送后立即被认为已经传送成功，仅适用于：消费者可以高效并以某种速率   <code>默认的应答方式</code></p>\n<p>​        弊端:</p>\n<p>​            1、如果消息在接收到之前，消费者那边出现连接或者 channel 关闭，那么消息就丢失了</p>\n<p>​            2、或者消费者这边由于接收太多还来不及处理的消息，导致这些消息的积压，最终使得内存耗尽，最终这些消费者线程被操作系统杀死</p>\n<p>​    3.2、手动消息应答： 可以<code>批量</code>应答并且减少网络拥堵</p>\n<p>​        方法：<code>Channel.basicAck</code> (肯定确认应答)、    <code>Channel.basicReject</code> (否定确认应答)、    <code>Channel.basicNack</code> (用于否定确认)：表示己拒绝处理该消息，可以将其丢弃了、    <code>Channel.basicRecover</code>是否恢复消息到队列</p>\n<p>​    3.3、消息自动重新入队  ：</p>\n<p>​        如果消费者由于某些原因失去连接(其通道已关闭，连接已关闭或 TCP 连接丢失)，导致消息未发送 ACK 确认，RabbitMQ 将了解到消息未完全处理，并将对其重新排队。如果此时其他消费者可以处理，它将很快将其重新分发给另一个消费者。这样，即使某个消费者偶尔死亡，也可以确保不会丢失任何消息。</p>\n<h3 id=\"6、持久化\"><a href=\"#6、持久化\" class=\"headerlink\" title=\"6、持久化\"></a>6、持久化</h3><p>确保消息不会丢失需要做两件事：我们需要将<code>队列和消息</code>都标记为<code>`持久化</code>。</p>\n<p>1、队列持久化</p>\n<p>之前我们创建的队列都是<code>非持久化的</code>，RabbitMQ 如果重启的话，该队列就会被删除掉，如果要队列实现持久化需要在声明队列的时候把<code>durable 参数设置为true</code>，代表开启<code>持久化</code></p>\n<p>2、消息持久化  需要在<strong>生产者</strong>发布消息的时候，开启消息的持久化并在 <code>basicPublish</code> 方法第二个参数添加这个属性 <code>MessageProperties.PERSISTENT_TEXT_PLAIN</code></p>\n<p>注意：将消息标记为持久化<code>并不能完全保证不会丢失消息</code>。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是这里依然存在。当消息刚准备存储在磁盘的时候 但是还没有存储完，消息还在缓存的某一个间隔点。此时并没有真正写入磁盘。持久性保证并不强。</p>\n<h3 id=\"7、消息分发\"><a href=\"#7、消息分发\" class=\"headerlink\" title=\"7、消息分发\"></a>7、消息分发</h3><p>1、轮询分发：对于消费速度不一致的消费者要是采用轮询分发就会导致 处理速度快的这个消费者很大一部分时间处于空闲状态，处理慢的那个消费者一直在干活</p>\n<p>2、不公平分发：</p>\n<p>​    做法：在消费者中消费消息之前，设置参数 <code>channel.basicQos(1);</code></p>\n<p>​    思想：如果只有一个工作队列<code>还没有处理完或者没有应答签收</code>一个消息，则<code>拒绝</code> RabbitMQ 分配新的消息到该工作队列。此时 RabbitMQ 会<code>优先分配给其他已经处理完消息或者空闲的工作队列</code>。如果所有的消费者都没有完成手上任务，队列还在<code>不停的添加新任务</code>，队列有可能就会遇到队列被<code>撑满</code>的情况，这个时候就只能添加新的 worker (工作队列)或者改变其他存储任务的策略。</p>\n<p>3、预取值分发——带权的消息分发（有点类似于一个<code>滑动窗口</code>）</p>\n<p>​    思想： 默认消息的发送是异步发送的，这样就会存在一个<code>未确认的消息缓冲区</code>，可以通过  限制此缓冲区的大小<strong>，</strong>以避免缓冲区里面无限制堆叠未确认消息问题。这个时候就可以通过使用 <code>basic.qos</code> 方法设置<code>「预取计数」值</code>，该值定义通道上允许的未确认消息的最大数量。一旦数量达到配置的数量， RabbitMQ 将<code>停止</code>在通道上传递更多消息，除非至少有一个未处理的消息被确认</p>\n<p>​    弊端：预取计数 决定了向消费者的发送消息的速率，但是这样会导致<code>已传递但尚未处理的消息的数量</code>也会增加，从而增加了消费者的 RAM 消耗</p>\n<p>==不公平分发和预取值分发都用到 <code>basic.qos</code> 方法，如果取值为 1，代表不公平分发，取值不为1，代表预取值分发==</p>\n<h3 id=\"8、发布确认\"><a href=\"#8、发布确认\" class=\"headerlink\" title=\"8、发布确认\"></a>8、发布确认</h3><p>背景：在生产环境中由于一些不明原因，会导致 RabbitMQ 重启，在 RabbitMQ 重启期间生产者消息投递失败，导致消息丢失，需要手动处理和恢复。为了保证mq能可靠的接收消息，需要使用<code>发布确认机制</code>。</p>\n<h5 id=\"初级\"><a href=\"#初级\" class=\"headerlink\" title=\"初级\"></a>初级</h5><p>生产者发布消息到 RabbitMQ 后，需要 RabbitMQ 返回「ACK（已收到）」给生产者，这样生产者才知道自己生产的消息成功发布出去</p>\n<p>1、发布确认的逻辑</p>\n<p>​    生产者会发送到 <code>confirm</code>模式的信道中，将消息传递到匹配的队列之后，broker 就会发送一个确认给生产者，生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，消息写入磁盘之后，broker发送一个确认给生产者，并在确认消息中包含消息的序列号。</p>\n<p>​     <code>confirm</code>模式是异步的，发送一条消息之后就可以等待返回的确认并发送下一条消息，通过回调方法来处理该返回的确认消息，如果RabbitMQ 因为自身内部错误导致消息丢失，就会发送一条 nack 消息，并进行处理</p>\n<p>2、3 种发布确认  ==确认发布指的是成功发送到了队列，并不是消费者消费了消息。==</p>\n<p>​    2.1、单个确认发布</p>\n<p>​        是一种<strong>同步确认发布</strong>的方式，在发布一个消息之后只有它被确认发布，后续的消息才能继续发布，如果在指定时间范围内这个消息没有被确认那么它将抛出异常。这种确认方式有一个最大的缺点就是：<strong>发布速度特别的慢</strong>，如果没有确认发布的消息就会<code>阻塞</code>所有后续消息的发布</p>\n<p>​    2.2、批量确认发布</p>\n<p>​        发布一批消息然后一起确认可以极大地提高吞吐量，缺点就是：当发生故障导致发布出现问题时，不知道是哪个消息出问题了，<code>我们必须将整个批处理保存在内存中，以记录重要的信息而后重新发布消息。</code>也是同步的，会阻塞消息的发布。</p>\n<p>​    2.3、异步确认发布</p>\n<p>​        利用了回调函数来达到消息可靠性传递的，这个中间件也是通过函数回调来保证是否投递成功，下面详细讲解异步确认是怎么实现</p>\n<p>​            ==异步回调（Asynchronous Callback）：==</p>\n<p>​                1、为了接收发布确认的结果，生产者可以通过设置回调函数来处理确认消息。</p>\n<p>​                2、生产者在发送消息时，可以指定一个回调函数，当收到确认消息时，RabbitMQ 会调用该回调函数来处理确认结果。</p>\n<p>​                3、回调函数可以根据确认结果进行相应的逻辑处理，例如记录日志、重试发送等。</p>\n<p>​        <strong>如何处理异步未确认消息?</strong>将未确认的消息放到一个基于内存的能被发布线程访问的队列，比如说用 <code>ConcurrentLinkedQueue</code>这个队列在 <code>confirm callbacks</code> 与发布线程之间进行消息的传递。</p>\n<ol>\n<li>重试发送（Retry Sending）：<ul>\n<li>当生产者收到异步未确认消息时，可以选择重新发送该消息。</li>\n<li>通过重新发送消息，可以尝试将消息再次发送到消息队列中，以确保消息被正确地传递和处理。</li>\n</ul>\n</li>\n<li>增加重试次数和延迟（Increase Retry Attempts and Delay）：<ul>\n<li>如果消息发送失败或未被确认，可以通过增加重试次数和延迟时间来进行更多次的重试。</li>\n<li>逐渐增加重试的间隔时间，以避免过多地占用系统资源和频繁地发送无效的消息。</li>\n</ul>\n</li>\n<li>错误日志记录（Error Logging）：<ul>\n<li>在处理未确认消息时，可以将相关的错误信息记录到日志中，以便后续分析和排查问题。</li>\n<li>错误日志记录可以帮助定位问题所在，并采取相应的纠正措施。</li>\n</ul>\n</li>\n<li>人工干预和处理（Manual Intervention）：<ul>\n<li>如果持续重试发送仍然无法解决未确认消息的问题，可能需要进行人工干预和处理。</li>\n<li>人工干预可以包括检查网络连接、检查消息队列服务器状态、检查消费者的可用性等操作。</li>\n</ul>\n</li>\n</ol>\n<p>3、答和发布区别</p>\n<p>​    <code>应答功能属于消费者</code>，消费完消息告诉 RabbitMQ 已经消费成功。</p>\n<p>​    <code>发布功能属于生产者</code>，生产消息到 RabbitMQ，RabbitMQ 需要告诉生产者已经收到消息。</p>\n<h5 id=\"高级\"><a href=\"#高级\" class=\"headerlink\" title=\"高级\"></a>高级</h5><p>1、发布消息后进行备份在<code>缓存</code>里，如果消息成功发布到交换机，则从缓存里删除该消息，如果没有成功发布，则设置一个定时任务，重新从缓存里获取消息发布到交换机，直到成功发布到交换机。 P—————————（发送消息）—————————————&gt;<code>confirm.exchange</code>–&gt;confirm.queue—&gt;confirm.consumer</p>\n<p>​                                                          |（发送备份消息）—&gt;缓存（定时任务会对未成功接受的消息进行传递）——|（交换机收到消息会将缓存中的消息清除）</p>\n<p>2、springboot中的发布确认的三种类型 <code>publisher-confirm-type</code></p>\n<p>​    1、<code>NONE</code> 值是禁用发布确认模式，是默认值</p>\n<p>​    2、<code>CORRELATED</code> 值是发布消息成功到交换器后会触发回调方法</p>\n<p>​    3、<code>SIMPLE</code> 值经测试有两种效果，其一效果和 CORRELATED 值一样会触发回调方法，其二在发布消息成功后使用 rabbitTemplate 调用 waitForConfirms 或 waitForConfirmsOrDie 方法等待 broker 节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是 waitForConfirmsOrDie 方法如果返回 false 则会关闭 channel，则接下来无法发送消息到 broker</p>\n<p>3、回退消息</p>\n<p>在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，如果发现该消息<code>不可路由，那么消息会可能被直接丢弃</code>，此时生产者是不知道消息被丢弃这个事件的。</p>\n<p>那么如何让无法被路由的消息帮我想办法处理一下？可以通过设置 <code>mandatory</code> 参数在当消息传递过程中不可达目的地时将消息<code>返回给生产者</code>处理消息</p>\n<p>4、备份交换机</p>\n<p>1、有了 mandatory 参数和回退消息，我们获得了对无法投递消息的感知能力，有机会在生产者的消息无法被投递时发现。但有时候，我们并<code>不知道该如何处理这些无法路由的消息，最多打个日志，然后触发报警，再来手动处理</code>。但是比较复杂和麻烦；如果既不想丢失消息，又不想增加生产者的复杂性，此时就<code>可以为队列设置死信交换机来存储那些处理失败的消息，可是这些不可路由消息根本没有机会进入到队列，因此无法使用死信队列来保存消息</code>。 在 RabbitMQ 中，有一种<code>备份交换机的机制存在</code>，可以很好的应对这个问题。</p>\n<p>2、什么是备份交换机呢？</p>\n<p>​    当交换机接收到一条不可路由消息时，将会把这条消息转发到备份交换机中，由备份交换机来进行转发和处理，通常备份交换机的类型为 <code>Fanout</code> ；这样就能把所有消息都投递到与其绑定的队列中，然后我们在备份交换机下绑定一个队列，这样所有那些原交换机无法被路由的消息，就会都进 入这个队列了；也可以建立一个报警队列，用<code>独立的消费者来进行监测和报警</code>。</p>\n<blockquote>\n<p>Mandatory 参数与备份交换机可以一起使用的时候，如果两者同时开启，就只会由备份交换机处理消息，因为备份交换机优先级高。</p>\n</blockquote>\n<h3 id=\"9、交换机\"><a href=\"#9、交换机\" class=\"headerlink\" title=\"9、交换机\"></a>9、交换机</h3><p>1、作用：接收生产者发送的消息。并将消息按照规则路由到与之绑定的队列，根据交换机的类型传递消息给队列，但是不能缓存消息，一旦路由失败消息就会丢失</p>\n<p>2、交换机有以下3种类型：</p>\n<ul>\n<li><strong>Fanout</strong>：广播、扇出，将消息交给所有绑定到交换机的队列</li>\n<li><strong>Direct</strong>：定向，把消息交给符合指定routing key 的队列，<code>完全匹配</code>；如果队列绑定键<code>当中没有 # 和 * 出现</code>，那么该队列绑定类型就是<code>direct</code> 了</li>\n<li><strong>Topic</strong>：通配符，把消息交给符合routing pattern（路由模式） 的队列，<code>模糊匹配，RoutingKey必须是多个单词，以 **.**分割</code></li>\n<li><strong>标题(headers)</strong>：不处理路由键。而是根据发送的消息内容中的headers属性进行匹配</li>\n</ul>\n<p>3、临时队列： 一旦我们断开了消费者的连接，队列将被自动删除。</p>\n<p>4、绑定bindings：binding 其实是 exchange 和 queue 之间的桥梁，它告诉我们 exchange 和那个队列进行了绑定关系。</p>\n<p>5、消息转换器：Spring会把发送的消息序列化为字节发送给MQ，接收消息的时候，还会把字节反序列化为Java对象。</p>\n<h3 id=\"10、死信队列\"><a href=\"#10、死信队列\" class=\"headerlink\" title=\"10、死信队列\"></a>10、死信队列</h3><p>1、由于<strong>特定的原因导致 queue 中的某些消息无法被消费</strong>，这样的消息如果没有后续的处理，就变成了死信，有死信自然就有了死信队列</p>\n<p>2、作用:</p>\n<p>​    保证消息数据的不丢失，当消息消费发生异常时，将消息投入死信队列中，死信交换机收集所有消费者处理失败的消息（死信），交由人工处理，进一步提高消息队列的可靠性</p>\n<p>3、死信来源：</p>\n<p>​    1、消息 TTL(生存时间) 过期                 超时分为：   <code>消息所在的队列设置了超时时间</code>  或者 <code>消息本身设置了超时时间</code>  ；TTL指的就是<code>一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒</code> ； 如果同时配置了队列的 TTL 和消息的 TTL，那么较小的那个值将会被使用</p>\n<blockquote>\n<p>如何实现发送一个消息20秒后消费者才收到消息？</p>\n<p>给消息的目标队列指定死信交换机；将消费者监听的队列绑定到死信交换机；发送消息时给消息设置超时时间为20秒</p>\n</blockquote>\n<p>​    2、队列达到最大长度            队列满了，无法再添加数据到 MQ 中</p>\n<p>​    3、消息被拒绝                     (basic.reject 或 basic.nack) 并且 requeue = false</p>\n<p>4、结构就是：正常队列通过配置<code>dead-letter-exchange</code>属性，会和死信交换机进行绑定，死信交换机再去绑定死信队列</p>\n<p>5、队列将死信投递给死信交换机时，必须知道两个信息：死信交换机名称   +    死信交换机与死信队列绑定的RoutingKey</p>\n<h3 id=\"11、延迟队列\"><a href=\"#11、延迟队列\" class=\"headerlink\" title=\"11、延迟队列\"></a>11、延迟队列<TTL的死信队列></TTL的死信队列></h3><p>​    是基于死信队列的，是队列，所以内部是有序的，最重要的特性是在于它的<code>延时属性</code>上，延时队列的元素就是  希望再到达指定的时间之后取出来进行处理的，也就是说，延时队列就是用来存放需要在<code>指定时间</code>被处理的 元素的队列。</p>\n<p>​    使用场景：订单在十分钟之内未支付则自动取消、新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒、用户注册成功后，如果1minus内没有登陆则进行短信提醒、用户发起退款，如果三天内没有得到处理则通知相关运营人员、预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议</p>\n<p>​    使用场景的特点：需要在<code>某个事件发生之后或者之前的指定时间点</code>完成某一项任务；如果<code>数据量比较少</code>可以使用定时任务进行检查，但是对于数据量比较大，并且<code>时效性较强</code>的场景不可行，对于庞大的数据量要是仍旧使用轮询的方式是不可取的，很可能在一秒内无法完成所有订单的检查，同时会给数据库带来很大压力</p>\n<p>​    使用上</p>\n<p>​    1、手动的配置<code>队列或者消息的TTL</code>      P –&gt; 交换机（延迟）–&gt;队列（TTL） —&gt; 死信交换机—&gt;死信队列—&gt; C</p>\n<p>​        两者的区别</p>\n<p>​        1、如果设置了<code>队列</code>的 TTL 属性，那么一旦消息<code>过期</code>，就会被队列<code>丢弃</code>(如果配置了死信队列被丢到死信队列中)，</p>\n<p>​        2、如果设置了<code>消息</code>的 TTL 属性,消息即使过期，也<code>不一定会被马上丢弃</code>，因为消息是否过期是在即将投递到消费者之前判定的，如果当前<code>队列</code>有严重的消息<code>积压</code>情况，则已过期的消息也许还能存活较长时间；就是说：RabbitMQ 只会检查第一个消息是否过期，如果过期则丢到死信队列， 如果第一个消息的延时时长很长，而第二个消息的延时时长很短，第二个消息并不会优先得到执行</p>\n<blockquote>\n<p>注意： 如果不设置 TTL，表示消息永远不会过期，如果将 TTL 设置为 0，则表示除非此时可以<code>直接</code>投递该消息到消费者，否则该消息将会被<code>丢弃</code></p>\n</blockquote>\n<p>​    2、使用延时队列插件       P –&gt; 交换机（延迟）–&gt;队列 —&gt; C</p>\n<p>​    如果不能实现在消息粒度上的 TTL，并使其在设置的 TTL 时间及时死亡，就无法设计成一个通用的延时队列。此时就是使用 延时插件</p>\n<blockquote>\n<p>延时队列在需要延时处理的场景下非常有用，使用 RabbitMQ 来实现延时队列可以很好的利用 RabbitMQ 的特性，如：消息可靠发送、消息可靠投递、死信队列来<code>保障消息至少被消费一次以及未被正确处理的消息不会被丢弃。</code></p>\n<p>通过 RabbitMQ 集群的特性，可以很好的解决单点故障问题，不会因为单个节点挂掉导致延时队列不可用或者消息丢失。</p>\n<p>延时队列还有很多其它选择，比如利用 Java 的 DelayQueue，利用 Redis 的 zset，利用 Quartz 或者利用 kafka 的时间轮</p>\n</blockquote>\n<h3 id=\"12、延时交换机\"><a href=\"#12、延时交换机\" class=\"headerlink\" title=\"12、延时交换机\"></a>12、延时交换机</h3><p>原理/流程：给交换机声明为delayed类型，当我们发送消息到延时交换机时，交换机先接收消息，判断消息是否具备x-delay属性；如果有x-delay属性，说明是延迟消息，持久化到硬盘，读取x-delay值，作为延迟时间；返回routing not found结果给消息发送者；x-delay时间到期后，重新投递消息到指定队列</p>\n<h3 id=\"13、幂等性\"><a href=\"#13、幂等性\" class=\"headerlink\" title=\"13、幂等性\"></a>13、幂等性</h3><p>1、幂等性：用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。</p>\n<p>​    1.1、重复消费：</p>\n<p>​        是什么：消费者在消费 MQ 中的消息时，MQ 已把消息发送给消费者，消费者在给 MQ 返回 ack 时网络中断， 故 MQ 未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息。</p>\n<p>​        解决：MQ 消费者的幂等性的解决  一般 使用<code>全局 ID</code> 或者<code>唯一标识</code>「比如时间戳、 UUID 、订单消费者消费 MQ 中的消息     、也可利用 MQ 的该 id 来判断 、可按自己的规则生成一个全局唯一 id，每次消费消息时用该 id 先判断该消息是否已消费过。」</p>\n<p>​        消费端幂等性的保障的两种操作：</p>\n<p>​        1、 <code>唯一 ID+ 指纹码机制</code>,利用数据库主键去重；指纹码：<code>我们的一些规则或者时间戳加别的服务给到的唯一信息码</code>,它并<code>不一定是我们系统生成</code>的，基本都是由我们的<code>业务规则拼接</code>而来，但是<code>一定要保证唯一性</code>，然后就利用查询语句进行判断这个 id 是否存在数据库中，优势就是实现简单就一个拼接，然后查询判断是否重复；劣势就是在高并发时，如果是单个数据库就会有写入性能瓶颈当然也可以采用分库分表提升性能，但<code>也不是我们最推荐的方式</code>。</p>\n<p>​        2、 <code>Redis 的原子性</code>： 利用 redis 执行 setnx 命令，天然具有幂等性。从而实现不重复消费</p>\n<p>2、优先队列</p>\n<p>​    背景：催付款的发送短信的业务一般可以使用 redis 来存放的定时器进行轮询，但是redis 只能用 List 做一个简简单单的消息队列，并不能实现一个优先级的场景，所以可以使用mq的设置队列的优先级达到优先队列的效果</p>\n<p>​    优先级的使用：队列需要设置为<code>优先级队列</code>，消息需要设置<code>消息的优先级</code>，消费者需要等待消息已经发送到队列中才去消费，因为这样才有机会对消息进行排序</p>\n<h3 id=\"14、可靠性\"><a href=\"#14、可靠性\" class=\"headerlink\" title=\"14、可靠性\"></a>14、可靠性</h3><p>1、消息从发送，到消费者接收，其中的每一步都可能导致消息丢失，常见的丢失原因包括：</p>\n<p>​    1、<code>发送时丢失</code> ： 生产者发送的消息未送达exchange   <code>或者</code>  消息到达exchange后未到达queue——————生产者确认机制</p>\n<p>​    2、<code>在队列中丢失</code>：MQ宕机，queue将消息丢失————————持久化机制</p>\n<p>​    3、<code>接收时丢失</code>  ：消费者成功的接收到了消息，但是并未消费消费者就宕机了</p>\n<p>2、解决的方法</p>\n<p>​    1、生产者确认机制     就是  发布确认机制，使用这个机制 来避免消息发送到MQ过程中丢失，需要给每个消息指定一个唯一ID（避免ACK冲突）。消息发送到MQ以后，会返回一个结果给发送者，表示消息是否发送成功 和 消息是否被处理成功。</p>\n<p>​    2、持久化</p>\n<p>​        <code>消息持久化</code>（利用SpringAMQP发送消息时，可以设置消息的属性（MessageProperties））、<code>交换机持久化</code>、<code>队列持久化</code>（RabbitMQ队列默认是非持久化的，mq重启后就丢失）「默认情况下，SpringAMQP发出的任何消息、声明的交换机/队列  都是持久化的，不用特意指定」</p>\n<p>​    3、消费者确认机制</p>\n<p>​        RabbitMQ是<strong>阅后即焚</strong>机制，RabbitMQ确认消息被消费者消费后会立刻删除,而RabbitMQ是通过<code>消费者回执</code>来确认消费者是否成功处理消息的：消费者获取消息后，应该向RabbitMQ发送ACK回执，表明自己已经处理消息。防止消费者未消费消息宕机的情况应该特别注意<code>消费者返回ACK的时机</code>「而SpringAMQP则允许配置三种确认模式：<code>manual：手动ack，需要在业务代码结束后，调用api发送ack。</code>、<code>auto：自动ack，由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack</code>、<code>none：关闭ack，MQ假定消费者获取消息后会成功处理，因此消息投递后立即被删除</code></p>\n<p>所以： <code>none</code>模式下，消息投递是不可靠的，可能丢失、<code>auto</code>模式类似事务机制，出现异常时返回nack，消息回滚到mq；没有异常，返回ack、<code>manual</code>：自己根据业务情况，判断什么时候该ack；一般，我们都是使用默认的auto即可。」</p>\n<p>​    4、失败重试机制</p>\n<p>当消费者出现异常后，消息会不断<code>requeue</code>（重入队）到队列，再重新发送给消费者，然后再次异常，再次<code>requeue</code>，无限循环，导致mq的消息处理飙升，带来不必要的压力;可以利用Spring的retry机制，在消费者出现异常时利用本地重试，而不是无限制的requeue到mq队列。设置为3次： <code>max-attempts: 3 # 最大重试次数</code></p>\n<p>在开启本地重试时，消息处理过程中抛出异常，就不会requeue到队列，而是在消费者本地重试；重试达到最大次数后，Spring会返回ack，消息会被丢弃</p>\n<p>​        4.1、开启重试模式后，重试次数耗尽，如果消息依然失败，它包含三种不同的实现：</p>\n<p>​            1、<code>RejectAndDontRequeueRecoverer</code>：重试耗尽后，直接reject，丢弃消息。默认就是这种方式</p>\n<p>​            2、<code>ImmediateRequeueMessageRecoverer</code>：重试耗尽后，返回nack，消息重新入队</p>\n<p>​            3、<code>RepublishMessageRecoverer</code>：重试耗尽后，将失败消息投递到指定的交换机，再将消息投递到专门存放异常消息的队列，后续由人工集中处理。</p>\n<h3 id=\"15、处理消息堆积\"><a href=\"#15、处理消息堆积\" class=\"headerlink\" title=\"15、处理消息堆积\"></a>15、处理消息堆积</h3><p>​    1、是什么：当生产者发送消息的速度超过了消费者处理消息的速度或者消费者下线、宕机，就会导致队列中的消息堆积，直到队列存储消息达到上限。之后发送的消息就会成为死信，可能会被丢弃</p>\n<p>​    2、解决：</p>\n<p>​        1、增加更多消费者，提高消费速度。也就是我们之前说的work queue模式</p>\n<p>​        2、扩大队列容积，提高堆积上限，此时就不能将消息保存到内存中，可以使用惰性队列</p>\n<p>​            惰性队列： 相比于正常情况的将消息保存到内存中，惰性队列会把消息保存到磁盘上；消费者要消费消息时才会从磁盘中读取并加载到内存；惰性队列的目的是能够支持更长的队列、支持更多的消息存储，但是它基于磁盘存储，消息时效性会降低，并且性能受限于磁盘的IO</p>\n<blockquote>\n<p>默认情况下，当生产者将消息发送到 RabbitMQ 的时候，队列中的消息会尽可能的存储在内存之中，这样可以更加的将消息发送给消费者。即使是持久化的消息，在被写入磁盘的同时也会在内存中驻留一份备份。当 RabbitMQ 需要释放内存的时候，会将内存中的消息换页至磁盘中，这个操作会耗费较长的时间，也会阻塞队列的操作，进而无法接收新的消息。</p>\n</blockquote>\n<h3 id=\"16、MQ集群\"><a href=\"#16、MQ集群\" class=\"headerlink\" title=\"16、MQ集群\"></a>16、MQ集群</h3><p>使用集群的原因：因为 单台 RabbitMQ 服务器可以满足每秒 1000 条消息的吞吐量，所以搭建集群是可以提高吞吐量的； RabbitMQ 服务器遇到内存崩溃、机器掉电或者主板故障等情况导致的某一时刻master节点宕机,可以对Quene中信息进行备份</p>\n<p>1、普通集群：</p>\n<p>​    1.1、是一种分布式集群，将队列分散到集群的各个节点，从而提高整个集群的并发能力。</p>\n<p>​    1.2、在普通集群中，各个节点会共享部分数据，包括队列和消息。因此，如果队列所在的节点宕机，集群中的其他节点仍可以继续处理该队列的消息，保证了高可用性和容错性。</p>\n<p>​    1.3、当访问集群中的某个节点时，无论队列在哪个节点上，客户端都可以通过任何一个节点进行访问。节点之间会进行内部的消息传递和协调，以确保消息能够正确地路由到队列所在的节点，并返回处理结果。这样可以实现跨节点的消息传递和处理，提供了分布式的消息处理能力。</p>\n<p>2、镜像集群：</p>\n<p>​    2.1、是一种主从集群，普通集群的基础上，添加了主从备份功能，提高集群的数据可用性。</p>\n<p>​    2.2、创建队列的节点被称为该队列的<strong>主节点，</strong>备份到的其它节点叫做该队列的<strong>镜像</strong>节点。</p>\n<p>​    2.3、一个队列的主节点可能是另一个队列的镜像节点（主节点和镜像节点之间可以互相备份）</p>\n<p>​    2.4、交换机、队列、队列中的消息会在各个mq的镜像节点之间同步备份。</p>\n<p>​    2.5、所有操作都是主节点完成，然后同步给镜像节点，主宕机后，镜像节点会替代成新的主节点</p>\n<p>​    2.6、虽然支持主从，但主从同步并不是强一致的，某些情况下可能有数据丢失的风险，后续的版本使用<strong>仲裁队列</strong>来代替镜像集群，底层采用Raft协议确保主从的数据一致性。</p>\n<p>​    2.7、镜像队列</p>\n<p>​        使用镜像的原因：</p>\n<p>​        如果RabbitMQ集群中<code>只有一个Broker节点，那么该节点的失效</code>将导致整体服务的临时性不可用，并且也可能会导致消息的丢失。可以将所有消息都设置为持久化,并且对应队列的durable属性也设置为true,但是这样仍然无法避免由于缓存导致的问题；因为消息在发送之后和被写入磁盘并执行刷盘动作之间存在一个短暂却会产生问题的时间窗。虽然可以通过发布确认机制能够确保客户端知道哪些消息己经存入磁盘，但是还是会出现因单点故障导致的服务不可用。所以镜像队列（Mirror Queue）的机制，可以将队列镜像到集群中的其他Broker节点之上，如果集群中的一个节点失效了，队列能自动地切换到镜像中的另一个节点上以保证服务的可用性。</p>\n<p>3、仲裁队列：</p>\n<p>​    3.1、与镜像队列一样，都是主从模式，支持主从数据同步</p>\n<p>​    3.2、主从同步基于Raft协议，底层可以保证强一致</p>\n<h2 id=\"KafKa\"><a href=\"#KafKa\" class=\"headerlink\" title=\"KafKa\"></a>KafKa</h2><h3 id=\"1、介绍\"><a href=\"#1、介绍\" class=\"headerlink\" title=\"1、介绍\"></a>1、介绍</h3><p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306182321214.png\" alt=\"image-20230618232149155\"></p>\n<p>​    1、作用</p>\n<p>​        是一个分布式的基于<code>发布/订阅模式</code>的消息队列 (Message Queue)，是一个开源的<code>分布式事件流平台</code> ( Event  Streaming Platform) ，用于高性能数据管道、流分析、数据集成和关键任务应用</p>\n<p>​    2、消息队列的两种模式</p>\n<p>​        2.1、<code>点对点模式</code>       ： 消费者主动拉取数据，消息收到后清除消息；消息只能发布到一个主题， 消费完成就删除消息，且只有一个消费者</p>\n<p>​        2.2、<code>发布订阅模式</code>    ： 可以有多个<code>topic</code>主题(浏览、点赞、收藏、评论等)；消费者<code>消费数据</code>之后，<code>不删除数据</code>；每个消费者相互独立，都可以消费到数据；消息可以发布到多个主题， 消息一般保留七天，且有多个消费者</p>\n<p>​    3、基本概念</p>\n<p>​        <code>broker</code>：表示的就是一个服务器,一个集群由多个 <code>broker</code> 组成。一个<code>broker</code> 可以容纳多个 <code>topic</code></p>\n<p>​        <code>Topic</code>：理解为队列，生产者和消费者面向的都是同一个 topic</p>\n<p>​        <code>Partition</code>：表示的就是对 <code>Kafka</code>进行分区，注意：一个分区中的一份数据就只能有一个消费者进行消费;一个非常大的 <code>topic</code> 可以分布到多个 <code>broker</code>（即服务器）上，一个 <code>topic</code> 可以分为多个 <code>partition</code>，每个 <code>partition</code> 是一个有序的队列</p>\n<p>​        <code>leader</code> 表示原来的数据，<strong>生产者发送数据的对象，以及消费者消费数据的对象都是 <code>Leader</code></strong>； <code>follower</code>表示副本数据，只进行备份，实时从 <code>Leader</code> 中同步数据，保持和<code>Leader</code> 数据的同步。<code>Leader</code> 发生故障时，某个 <code>Follower</code> 会成为新的 <code>Leader</code></p>\n<p>​        Zookeeper会记录有哪些<code>Broker上线了</code>，还会记录<code>leader</code>副本的相关信息，同时，Zookeeper的Consumer文件中存放消息被消费的记录（offset）；但是在Kafka2.8版本后，消息被消费的记录（offset）存放在Kafka中zk就是可选的了</p>\n<p>​        <code>Consumer Group（CG）</code>：消费者组，由多个 <code>consumer</code> 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p>\n<p>​    4、消息的发送原理</p>\n<ul>\n<li>在消息发送的过程中，涉及到了<strong>两个线程——<code>main</code></strong> <strong>线程和</strong> <strong><code>Sender</code></strong> <strong>线程</strong>。</li>\n<li>在 <code>main</code> 线程中创建了<strong>一个<code>双端队列</code></strong> <strong><code>RecordAccumulator</code></strong>,<code>main</code>线程是消息的<code>生产线程</code>并将会消息发送给 <code>RecordAccumulator</code></li>\n<li><code>sender</code>线程是<code>jvm</code>单例的线程，专门用于消息的发送，即：不断从 <code>RecordAccumulator（缓冲区总大小，默认 32m）</code> 中拉取消息发送到<code>Kafka Broker</code></li>\n<li>在<code>jvm</code>的内存中开辟了一块缓存空间叫<strong>RecordAccumulator（消息累加器）</strong>，用于将多条消息<code>合并成一个批次</code>，然后由sender线程发送给kafka集群。</li>\n</ul>\n<p>​    5、消息的发送流程</p>\n<ul>\n<li>消息在生产过程会调用<code>send</code>==方法== 、经过<code>拦截器</code>、经过序列化器、再经过分区器确定消息发送在<code>topic</code>下的哪个分区</li>\n<li>然后发送到对应的<code>消息累加器</code>中「消息累加器是多个双端队列」；消息在累加器中，进行合并，达到了对应的<code>size（batch.size）默认16K</code>或者等待<code>超过对应的等待时间(linger.ms)默认0ms</code>，都会触发<code>sender</code>==线程== 的发送</li>\n<li><code>sender</code>线程有一个请求池，<code>默认缓存最多接受五个请求</code>（ ==max.in.flight.requests.per.connection== ），通过<code>seletor选择器</code>发送消息后，<code>seletor选择器</code>会等待服务端（kafka集群）发送应答的<code>acks「0：生产者发过来就会应答,1：leader 收到之后才会应答，-1（all）:leader和ISR队列中的所有节点收到全部数据之后应答」</code>，如果没收到<code>ack</code>就会重试。如果<code>ack</code>成功就会删除累加器中的消息批次，并响应给<code>生产者</code></li>\n</ul>\n<h3 id=\"2、生产者\"><a href=\"#2、生产者\" class=\"headerlink\" title=\"2、生产者\"></a>2、生产者</h3><p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191630066.png\" alt=\"image-20230619163053034\"></p>\n<p>​    1、异步发送</p>\n<p>​        1、普通异步发送API: send；  main 线程进行发送</p>\n<p>​        2、异步回调函数：回调函数收到ack的时候会调用带有参数的send 回调函数，失败会自动重试不用手动重试</p>\n<p>​        3、同步调用：    先处理已经堆积在 <code>DQueue</code> 中的数据；随后 <code>RecordAccumulator</code> 再处理外部数据放入<code>DQueue</code>，就是带有回调函数的阻塞式（<code>.get()</code>）</p>\n<p>​    2、生产者拦截器（可以通过实现接口自定义拦截器）</p>\n<p>​        1、可以在分区前对消息或者 topic 进行修改，如果需要使用kafka实现<code>延时队列高级应用</code>，我们就可以通过<code>拦截器对消息进行判断</code>，并修改，暂时放入我们的<code>延时主题</code>中，等时间达到再放回<code>普通主题队列</code>。</p>\n<p>​        2、可以让服务端对<code>sender</code>线程进行<code>消息确认</code>，或消息发送失败后进行回调</p>\n<p>​        3、在关闭拦截器时，进行一些资源的释放</p>\n<p>​    <strong>3、生产者分区</strong></p>\n<p>​        1、分区的好处：合理使用存储资源、实现<code>负载均衡</code>的效果、提高消费者消费的并行度</p>\n<p>​        2、生产者发送消息的分区策略：     指定分区、指定<code>key</code> , 计算 <code>hash</code> 得到分区、指定随机粘性分区</p>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191401432.png\" alt=\"image-20230619140157399\" style=\"zoom:47%;\"></p>\n<p>​    4、如何提高生产者的吞吐量</p>\n<p>​        目的： 通过<code>提高吞吐量</code>达到<code>降低延迟的效果</code></p>\n<p>​        思路：</p>\n<p>​            1、<strong>Batch.size<code>默认 16k</code> 与 linger.ms<code>等待时间</code> 配合使用，根据生成数据的大小指定。</strong></p>\n<p>​            2、<strong>RecordAccumlator<code>缓冲区大小</code>：在异步发送并且分区很多的情况下，<code>32M</code>的数据量容易被满足，进程交互加大，可以适当提高到64M。</strong></p>\n<p>​            3、<strong>compression.type<code>压缩类型</code>：压缩snappy</strong>，通过<strong>消息压缩</strong>的方式，在生产端将消息追加进<code>ProducerBatch</code> <code>就</code>对每一条消息进行压缩了。常用的有Gzip、Snappy、Lz4 和 Zstd，这是时间换空间的手段。压缩的消息会在<code>消费端进行解压</code>。进一步减小网络中消息传输的带宽</p>\n<p>​        方案：</p>\n<p>​            1、通过累加器将多条消息<code>合并</code>成一批之后进行统一发送。在broker中将消息<code>批量存入</code>。<code>减少多次的网络IO</code>。</p>\n<p>​    5、消息发送线程(Sender)</p>\n<ul>\n<li>消息保存在内存后，Sender线程就会把符合条件的消息<code>按照批次进行发送</code>。除了发送消息，<code>元数据的加载</code>也是通过<code>Sender</code>线程来处理的。</li>\n<li><code>Sender</code>线程发送消息以及接收消息，都是基于<code>java NIO的Selector</code>。通过<code>Selector</code>把消息发出去，并通过<code>Selector</code>接收消息。</li>\n<li><code>Sender</code>线程默认容纳5个未确认的消息，消息发送失败后会进行重试。</li>\n</ul>\n<h3 id=\"3、消息的可靠性\"><a href=\"#3、消息的可靠性\" class=\"headerlink\" title=\"3、消息的可靠性\"></a>3、消息的可靠性</h3><p>主要是基于<code>ACKs</code>应答；</p>\n<ul>\n<li><p><code>acks</code>为<code>0</code>时， 表示生产者将数据发送出去就不管了，不等待任何返回。这种情况下数据<code>传输效率最高</code>，但是数据<code>可靠性最低</code>，当 server挂掉的时候就会<code>丢失</code>数据；</p>\n</li>\n<li><p><code>acks</code>为<code>1</code>时（默认），表示数据发送到<code>Kafka</code>后，经过leader成功接收消息的的确认，才算发送成功，如果leader宕机了，就会<code>丢失</code>数据。</p>\n</li>\n<li><p><code>acks</code>为<code>-1/all</code>时，表示生产者需要等待<code>ISR</code>中的所有<code>follower</code>都确认接收到数据后才算发送完成，这样数据不会丢失，因此<code>可靠性最高，性能最低</code>。</p>\n</li>\n</ul>\n<p>1、<strong>思考：</strong></p>\n<p>Leader收到数据，所有Follower都开始同步数据，但有一个Follower,因为某种故障，迟迟不能与Leader进行同步，那这个问题怎么解决呢？<br>Leader维护了一个动态的<code>in-sync replica set(ISR)</code>,意为和Leader保持同步的Follower+Leader集合(leader:0,isr:0,l,2)。如果Follower长时间未向Leader发送通信请求或同步数据，则该Follower将被踢出ISR。该时间阈值由<code>replica.lag.time.max.ms</code>参数设定，默认30s。例如2超时，ISR就为(leader:0,isr:0,1)。这样就不用等长期联系不上或者已经故障的节点。</p>\n<p>2、<strong>数据可靠性分析：</strong>如果分区副本设置为1个，或者ISR里应答的最小副本数量(min.insync.replicas默认为1 )设置为1,和ack=1的效果是一样的，仍然有丢数的风险(leader:0,isr:0)。</p>\n<p>3、<font color=\"red\"><strong>数据完全可靠条件</strong></font>： <code>ACK级别设置为   -1 + 分区副本大于等于  2 + ISR里应答的最小副本数量大于等于  2</code></p>\n<p>4、<strong><code>ISR</code></strong> ： 是<code>leader</code> 副本保持同步的副本集合，ISR 中的副本和 leader 副本之间的数据<code>保持一致</code>。当 <code>Kafka</code> 集群中的 <code>broker</code> 出现故障或网络问题时，<code>ISR</code> 可以作为新的 <code>leader</code> 副本的候选者来保证集群的<code>高可用性</code></p>\n<p>5、<strong><code>AR = ISR + ORS</code></strong>：表示一个主题分区的<code>全部副本集合</code>，它包括了 ISR（in-sync replica set）和 ORS（out-of-sync replica set）两部分；</p>\n<p>​    正常情况下，如果所有的<code>follower</code>副本都应该与<code>leader</code>副本保持一定程度的同步，即：<code>AR = ISR，OSR = null</code></p>\n<p>​    <code>ORS</code>表示不能在指定的时间内和<code>leader</code>保持数据同步集合，即 表示跟 <code>leader</code> 副本数据有差异的副本集合,就是说其表示的是：<code>Follower</code> 与 <code>Leader</code> 副本同步时<code>延迟过多</code>的副本。</p>\n<p>​    当 <code>ISR</code>中的副本出现故障或不可用时，Kafka 将会从 <code>AR</code> 的 <code>ORS</code> 中选择一个副本作为新的 <code>leader</code> 副本，此时已经处于<code>ISR 中的</code>副本就不再可用，诸如此类的改变可能会影响到整个集群的性能表现。</p>\n<p>6、消息可靠性的保障：由<code>多副本机制</code>来保障   +   <code>同步刷盘</code>（但是会影响性能）</p>\n<h3 id=\"4、消息的重复性\"><a href=\"#4、消息的重复性\" class=\"headerlink\" title=\"4、消息的重复性\"></a>4、消息的重复性</h3><font color=\"red\">**数据重复分析：**</font>`acks = -1(all) `：生产者发送过来的数据，`Leader`和`ISR队列`里面的所有节点收齐数据后应答。\n\n**<font color=\"red\"> 数据的传递语义</font>**\n\n- 至少一次（At Least Once）： `ACK级别设置为-1 + 分区副本>=2 + ISR里应答的最小副本数量>=2`。可以保证数据不丢失，但是不能保证数据不重复。\n- 最多一次（At Most Once）：ACK级别设置为`0` 。可以保证数据不重复，但是不能保证数据不丢失。\n- 精确一次（Exactly Once）：至少一次 + 幂等性 。( Kafka 0.11版本引入一项重大特性：**幂等性和事务**。)\n\n**幂等性**\n\n对接口的多次调用所产生的结果和调用一次是一致的。生产者在进行重试的时候有可能会`重复写入消息`，而使用Kafka 的`幂等性`功能之后就可以`避免这种情况`。`（不产生重复数据）`\n\n重复数据的判断标准：具有`<PID, partition, seqnumber>`相同主键的消息提交时，`Broker`只会持久化一条，所以`broker`中会在内存维护一个`pid+分区对应的序列号`，所以如果收到的序列号正好` 等于  内存序列号+1`，才存储消息，如果小于内存序列号，意味着消息重复，那么会丢弃消息，并应答。如果远大于内存序列号，意味着消息丢失，会抛出异常。\n\n解决的是`sender到broker间`，由于网络波动可能造成的`重发问题`。此时是用`幂等来标识唯一的消息`。幂等性只能保证的是在`单分区单会话内不重复`。\n\n开启幂等性功能的方式：只需要显式地将生产者客户端参数`enable.idempotence`设置为`true`即可(这个参数的默认值为`true`)；并且需要确保生产者客户端的`retries、acks、max.in.filght.request.per.connection`参数不被配置，默认值就是对的\n\n**<font color=\"red\"> 消息事务</font>**\n\n- 开启事务必须开启幂等性，事务的底层是依赖`幂等性`的\n\n- 由于`幂等性不能跨分区运作`，为了保证同时发的多条消息，要么全成功，要么全失败,所以kafka 引入了事务的概念\n\n- 通过`事务协调器，来实现事务`，工作`API` 与 `流程`如下\n\n  ![image-20230619155037328](https://gitee.com/Ryang1118/typora/raw/master/images/202306191550362.png)\n\n### 5、消息的顺序性\n\n> ProducerNetworkClient中保证的\n\n**<font color=\"red\">数据有序</font>**\n\n- kafka 的消息在`单分区内`有序（在`特定的条件`下），`多分区内无序`（如果对多分区进行排序，造成分区无法工作需要等待排序，浪费性能）\n\n**<font color=\"red\">数据乱序</font>**\n\nkafka只能保证单分区下的消息顺序性，为了保证消息的顺序性,需要进行设置的条件是：\n\n- 如果`未开启幂等性`，需要 `max.in.flight.requests.per.connection` 设置`为1`（缓冲队列最多放置1个请求）\n\n- 如果`开启幂等性`，需要` max.in.flight.requests.per.connection `设置为`小于5`\n\n  原因： 启用幂等后，`kafka`服务端会缓存`producer`发来的最近5个`request`的元数据，所以无论如何，都可以保证`最近5个request`的数据都是`有序的`\n\n### 6、Broker\n\n1、为了提高吞吐量，每个`topic`也会有多个分区，同时为了保持可靠性，每个分区还会有多个副本，副本被`均匀的散落`在每个`broker`上，其中每个分区副本中有一个副本为`leader`，其他的为`follower`，kafka集群中，会有多台`broker`，每台`broker`分别在不同的机器上\n\n2、`Kafka`的选举`Leader`的方式有三种\n\n​    2.1、`broker（控制器）选leader`：每个broker都有`唯一`的`brokerId`，他们在启动后会去竞争注册`zookeeper`上的`Controller`结点，谁先抢到，谁就是`broker leader`。而其他`broker会监听`该结点事件，以便后续`leader下线后触发重新选举`\n\n​    2.2、分区多副本（Replica）选leader\n\n​        1、副本的作用：提高数据可靠性，同一分区的多个副本保存的数据是一样的，当节点发生故障的时候可以保证分区的数据不丢失；但是一旦副本太多就会导致：增加磁盘存储空间，增加网络上数据传输，降低效率\n\n​        2、**LEO**:每个副本都有内部的LEO，代表当前队列消息的最后一条偏移量,其值为`最后一个offset + 1`；**HW**:高水位，代表所有ISR中的LEO`值最低`的那个offset，也是消费者可见的最大消息offset\n\n​        3、副本故障处理:\n\n​                3.1、**`Follower`的故障处理:**如果`follower`落后`leader`过`多`，体现在落后时间 `repca.lag.time.max.ms `或者落后偏移量`repca.lag.max.messages`,`follower`就会被`移除ISR队列`，Leader和Follower继续接收数据；待该Follower恢复后， Follower会读取本地磁盘记录的上次的HW，并将`log`文件高于`HW`的部分截取掉，从HW开始 向Leader进行同步，最后等待该`队列LEO追上HW`，才会`重新加入ISR`中\n\n​                3.2、**`leader`的故障处理:**Leader发生故障之后，会从`ISR`中选出一个新的`Leader`,为保证多个副本之间的数据一致性，其余的`Follower`会先将各自的`log`文件高于`HW`的部分截掉，然后从新的`Leader`同步数据;但是这只能保证`副本之间`的数据一致性，并不能保证数据`不丢失或者不重复`\n\n​        4、手动调整分区副本存储：防止每台服务器的配置和性能不一致导致个别服务器存储压力较大\n\n​            4.1、<font color=\"red\">**Leader Partition负载平衡**</font>：可以解决：正常情况下，`Kafka`本身会自动把`Leader Partition` `均匀分散`在各个机器上，来保证每台机器的读写吞吐量都是均匀的。但是如果某些`broker`宕机，会导致`Leader Partition`过于集中在其他少部分几台`broker`上，这会导致少数几台`broker`的读写请求压力过高，其他宕机的`broker`重启之后都是`follower partition`，读写请求很低，造成集群负载不均衡。\n\n​            4.2、<font color=\"red\">**增加副本因子**</font>：由于`某个主题的重要等级需要提升`，我们考虑增加副本。副本数的增加需要先制定计划，然后根据计划执行\n\n​        5、选举机制：Kafka 集群中有一个 `broker` 的 `Controller` 会被选举为 `Controller Leader`，负责管理集群`broker` 的上下线，所有 `topic` 的分区副本分配和 Leader 选举等工作。`Controller` 的信息同步工作是依赖于 `Zookeeper` 的；**如果leader副本下线；`选举的原则`就是：以 在`ISR`队列中存活为前提，按照`AR`中排在前面的优先。**见下面的Controller 的选举原则\n\n​    2.3、消费者选Leader\n\n3、broker的工作流程\n\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306191913101.png\" alt=\"image-20230619191308041\" style=\"zoom:53%;\">\n\n4、zookeeper 的作用：kafka使用zookeeper进行元数据管理；保存broker注册信息，包括主题（Topic）、分区（Partition）信息等；选择分区leader\n\n### 7、文件存储\n\n1、文件存储机制\n\n​    1.1、topic数据的存储机制：kafka中`主题（Topic）`是一个`逻辑`上的概念，`分区（partition）`是`物理`上的存在的。每个`partition`对应一个`log`文件，该`log`文件中存储的就是`Producer`生产的数据。`Producer`生产的数据会被不断追加到该`log文件末端`。为防止`log`文件过大导致数据定位效率低下，`Kafka`采用了分片和索引机制，将每个`partition`分为多个`segment`，每个`segment`默认`1G`（ `log.segment.bytes `）， 每个`segment`包括: `.index文件、.log文件和.timeindex等文件`\n\n​    `index文件`：`Index`文件中保存的offset为相对offset，这样能确保offset的值所占空间不会过大，因此能将offset的值控制在固定大小;`index`为稀疏索引，==大约每往log文件写入4kb数据，会往index文件写入一条索引==。这样的index索引文件就是一个**稀疏索引**，它并不会每条日志都建立索引信息。\n\n​    `时间戳索引(timeindex)文件`： 可以通过 时间戳（8byte）+ 相对offset（4byte）查询某一个时间段内的消息；先要通过`时间范围`找到对应的`offset`；然后再去找对应的`index`文件找到`position`信息；最后在`遍历log文件`，这个过程也是`需要用到index索引文件的`\n\n2、文件清理策略\n\n​    2.1、主要基于log日志文件（Kafka将消息存储在磁盘中，为了控制磁盘占用空间，避免不断增加就需要对消息做一定的`清理操作`。`Kafka` 中每一个分区副本都对应一个`Log`，而`Log`又可以分为`多个日志分段`，这样也`便于日志的清理操作`）\n\n​    2.2、`Kafka`提供了`两种日志清理策略`\n\n- 日志删除(`delete`) :按照一定的保留策略直接删除不符合条件的日志分段。`将过期数据删除`  可以使用 `基于时间`和`基于日志大小`的`两`种策略进行删除;这两个策略是可以同时使用的\n- 日志压缩(`compact`) :针对每个消息的key进行整合，对于有相同key的不同value值，只保留最后一个版本。注意这个时候：压缩后的`offset`可能是`不连续`的\n\n### 8、高效读写数据\n\n1、<font color=\"red\">kafka可以快速读写的原因：</font>\n\n<p>kafka是<code>分布式集群</code>，采用<code>分区方式</code>，<code>并行</code>操作   +    读取数据采用<code>稀疏索引</code>，可以<code>快速定位</code>消费数据   +    <code>顺序写磁盘</code>    +    <code>页缓冲</code>和<code>零拷贝</code></p>\n<p>​    1.1、顺序写磁盘： 生产者是生产数据的时候要写到 <code>log</code> 文件中，<code>写的过程</code>是一直<code>追加</code>到<code>文件末端</code>，为<code>顺序写</code>;顺序写之所以快，是因为其<code>省去了大量磁头寻址</code>的时间。</p>\n<p>​    1.2、<code>页缓冲</code>和<code>零拷贝</code>：</p>\n<p>​        零拷贝：只是减少拷贝的次数，并不是不要拷贝。使用在IO读写过程中</p>\n<p>​        为了实现零拷贝，那么会进行两个操作：</p>\n<p>​        1、将内核缓存与用户层进行共享，以减少一次拷贝</p>\n<p>​        2、用户层的读写也会直接访问该共享存储，此时原先由用户层到Socket缓存的数据拷贝过程 就 变成了从<code>内核到内核的CPU拷贝过程</code>，这就是零拷贝</p>\n<p>​        3、甚至可以将 消息存在页缓存PageCache中，那么此时就可以  避免第一步的   磁盘到内核的拷贝过程</p>\n<blockquote>\n<p>常规应用程序<code>IO</code>过程会经历拷贝次数为4次</p>\n<ol>\n<li><p>数据从磁盘经过<code>DMA</code>(直接存储器访问)到内核的<code>Read Buffer</code></p>\n</li>\n<li><p>内核态的<code>Read Buffer</code>到用户态应用层的<code>Buffer</code></p>\n</li>\n<li><p>用户态的<code>Buffer</code>到内核态的<code>Socket Buffer</code></p>\n</li>\n<li><p><code>Socket Buffer</code>到网卡的<code>NIC Buffer</code>，随后用户层到网卡初获取数据</p>\n</li>\n</ol>\n<p>可以看到的是3、 2、1操作是两次无用的操作，也就是<code>内核态和用户态</code>之间的拷贝相当于执行<code>两次无用的操作</code>  零拷贝就是对2 3 4 步骤的优化</p>\n</blockquote>\n<p>2、<font color=\"red\">提升kafka性能的原因</font></p>\n<p>​    2.1、数据加工处理操作交由Kafka生产者和Kafka消费者处理。<code>Kafka Broker</code>应用层不关心存储的数据，所以就不用走应用层，传输效率高</p>\n<blockquote>\n<p>P、C 的 数据加工主要就是针对<code>PageCache 页缓存</code>的读写</p>\n</blockquote>\n<p>3、<font color=\"red\">PageCache 页缓存</font>：实际上是把空闲内存当做磁盘缓存进行使用的</p>\n<p>​        2.2.1、读操作</p>\n<p>​            一个进程要去读磁盘的文件时候，先判断 数据是否在 页缓存 中，在的话直接返回数据，减少了一次IO操作，不在的话就发起读取请求，去磁盘中查找，并将数据写到也缓存中</p>\n<p>​        2.2.2、写操作</p>\n<p>​            一个进程需要将数据写入磁盘，先检查 数据是否在 页缓存 中，不存在就在 <code>PageCache</code>中添加相应的数据页，接着将数据写入对应的数据页，此时<code>被修改过后的数据页</code>也就变成了<code>脏页</code>；操作系统会在<code>适当时间</code>将脏页中的数据<code>写入磁盘</code>，以保持数据的<code>一致性</code></p>\n<h3 id=\"9、Kafka-消费者\"><a href=\"#9、Kafka-消费者\" class=\"headerlink\" title=\"9、Kafka 消费者\"></a>9、Kafka 消费者</h3><p><img src=\"/Users/yangrui/Library/Application Support/typora-user-images/image-20230902135041778.png\" alt=\"image-20230902135041778\" style=\"zoom: 33%;\"></p>\n<p>1、常见的消费模式： 从服务器拉取 ： pull / 向消费者推送：push</p>\n<p>2、kafka 就是基于 pull 的模式</p>\n<p>​        这种模式的缺点就是：如果服务端没有消息，消费端就会一直空轮询；</p>\n<p>​        kafka 的改进就是：如果没消息服务端就会<code>暂时保持该请求</code>，在一段时间内<code>有消息再回应</code>给客户端</p>\n<p>​        <code>kafka</code>不用<code>push</code>的模式是因为  kafka 是由<code>broker</code>决定消息发送速率，<code>很难适应所有消费者</code>的消费速率</p>\n<p>3、消费者消费消息：</p>\n<p>​    1、每个分区只会被CG中一个消费者消费，并且将已经消费的消息加到系统主题中进行保存，一个消费者可以消费多个分区数据</p>\n<p>​    2、消费者组：多个消费者构成，消费者组之间互不影响；形成一个消费者组的条件：是所有消费者的<code>groupid</code>相同</p>\n<p>​    3、如果所有的消费者都属于<code>同一个消费组</code>，那么所有的消息都会被<code>均衡地投递给每一个消费者</code>，即每条消息<code>只会被一个消费者处理</code>，这就相当于<code>点对点模式</code>的应用；如果所有的消费者都隶属于<code>不同的消费组</code>，那么所有的消息都会被<code>广播给所有的消费者</code>，即每条消息会<code>被所有的消费者处理</code>，这就相当于<code>发布／订阅模式</code>的应用</p>\n<p>4、消费者组初始化流程：</p>\n<p>​    <code>coordinator</code>：辅助实现消费者组的<code>初始化和分区</code>的分配。<code>coordinator</code>节点选择 = <code>groupid 的 hashcode值 % 50（ __consumer_offsets的分区数量）</code></p>\n<ol>\n<li>每个<code>consumer</code>都发送<code>JoinGroup</code>请求 ==[黄线]==</li>\n<li>随机选出一个<code>consumer</code>作为<code>leader</code></li>\n<li>把要消费的<code>topic</code>情况发送给<code>leader</code> 消费者==[蓝线]==</li>\n<li><code>leader</code>会负责制定消费方案</li>\n<li>把消费方案发给<code>coordinator</code>  ==[黄线]==</li>\n<li><code>Coordinator</code>就把消费方案下发给各个<code>consumer</code> ==[绿线]==</li>\n<li>每个消费者都会和<code>coordinator</code>保持心跳（默认3s），一旦<code>超时</code>（<code>session.timeout.ms</code>=45s），该消费者会被移除，并触发再平衡；或者<code>消费者处理消息的时间过长</code>（<code>max.poll.interval.ms</code>=5分钟），也会触发再平衡</li>\n</ol>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202306200010156.png\" alt=\"image-20230620001052125\"></p>\n<p>5、消费者组的消费流程</p>\n<p>​    1、消费者组会发送消费请求给 <code>ConsumerNetworkClient</code>   ，指定每批次抓取指定字节 以及设置超时时间，</p>\n<p>​    2、<code>ConsumerNetworkClient</code>  在抓取完数据之后， 再向kafka 集群发送请求，产生回调，将拉取到的数据放入到消息队列中，</p>\n<p>​    3、消费者再根据设置去队列中拉取指定规格的数据，进行反序列化，经过拦截器处理得到数据</p>\n<p>6、分区的分配和再平衡</p>\n<p>​    分配的策略:  解决的问题是： 一个消费者组中的哪个<code>consumer</code>来消费一个topic中的哪个<code>partition</code>的数据  默认策略是<code>Range + CooperativeSticky</code></p>\n<p>​    <strong>6.1、<font color=\"red\">Range以及再平衡</font>  ：</strong></p>\n<p>​        6.1.1范围分区分配策略</p>\n<p>​        是对每个 <code>topic</code> 而言的。首先对同一个 <code>topic</code> 里面的分区<code>按照序号进行排序</code>，并对消费者<code>按照字母顺序</code>进行排序；通过 <code>partitions数/consumer数</code> 来<code>决定每个消费者应该消费几个分区</code>。如果除不尽，那么前面几个消费者将会多消费 1 个分区。</p>\n<p>​        弊端：容易产生<code>数据倾斜</code>； 如果只是针对 1 个 topic 而言，C0消费者多消费1个分区影响不是很大。但是如果有 N 多个 topic，那么针对每个 topic，消费者 C0都将多消费 1 个分区，topic越多，C0消费的分区会比其他消费者明显多消费 N 个分区。</p>\n<p>​        6.1.2 再平衡</p>\n<p>​        停止掉 某个消费者之后，消费者组<code>需要按照超时时间 45s</code>来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把<code>该消费者的任务</code>分配(分配的原则还是<code>重新按照 range 方式分配</code>)给其他 <code>broker</code> 执行,并且该消费者已经被踢出消费者组</p>\n<blockquote>\n<p>kafka 中的分区数可以增多，但是不能减少</p>\n</blockquote>\n<p>​        <strong>6.2、</strong><font color=\"red\"><strong>RoundRobin</strong> <strong>分配以及再平衡</strong></font></p>\n<p>​        6.2.1轮询分区分配策略</p>\n<p>​        即在<code>执行一次新的分配之前</code>，考虑上一次分配的结果，<code>尽量少的调整分配的变动</code>，可以节省大量的开销。首先会<code>尽量均衡的放置分区</code>到消费者上面，在出现 一个消费者<code>组内</code>某个消费者出现问题的时候，会尽量<code>保持原有分配的分区不变化</code></p>\n<p>​        6.2.2 再平衡</p>\n<p>​        是对每个 <code>topic</code> 而言的。<code>粘性分区</code> 策略是把所有的 <code>partition</code> 和所有的<code>consumer</code> 都列出来，然后按照 <code>hashcode</code> 进行排序，最后通过<code>轮询算法</code>来分配 <code>partition</code> 给到各个消费者。</p>\n<p>​        <strong>6.3、</strong><font color=\"red\"><strong>Sticky 分配以及再平衡</strong></font></p>\n<p>​        6.3.1粘性分区分配</p>\n<p>​        即在<code>执行一次新的分配之前</code>，考虑上一次分配的结果，<code>尽量少的调整分配的变动</code>，可以节省大量的开销。首先会<code>尽量均衡的放置分区</code>到消费者上面，在出现 一个消费者<code>组内</code>某个消费者出现问题的时候，会尽量<code>保持原有分配的分区不变化</code></p>\n<p>​        6.3.2 再平衡</p>\n<p>​        停止掉 某个消费者之后，消费者组<code>需要按照超时时间 45s</code>来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把<code>该消费者的任务</code>分配(分配的原则还是<code>重新按照 sticky 方式分配</code>)给其他 <code>broker</code> 执行,并且该消费者已经被踢出消费者组</p>\n<blockquote>\n<p><code>精髓</code>在于:  重分配后，还能尽量与上一次结果保持一致，进而达到消费者故障下线，故障恢复后的均衡问题</p>\n</blockquote>\n<p>​        <strong>6.4、</strong><font color=\"red\"><strong>CooperativeSticky 分配以及再平衡</strong></font></p>\n<p>​        6.4.1、合作粘性分区分配策略：</p>\n<p>​        类似于<code>Sticky</code>策略，根据消费者的标识符将分区分配给消费者。不同之处在于，<code>CooperativeSticky</code>策略允许消费者协作地重新分配分区，以实现更好的负载均衡和故障恢复。</p>\n<p>​        6.4.2 再平衡、</p>\n<p>​        停止掉 某个消费者之后，消费者组<code>需要按照超时时间 45s</code>来判断它是否退出，所以需要等待，时间到了 45s 后，判断它真的退出就会把<code>该消费者的任务</code>分配(分配的原则还是<code>重新按照 CooperativeSticky 方式分配</code>)给其他 <code>broker</code> 执行,并且该消费者已经被踢出消费者组</p>\n<p><strong>7、offset位移</strong></p>\n<blockquote>\n<p><code>offset</code> 作用：标识消费者在分区中消费的位置。消费者可以<code>通过记录偏移量来跟踪自己消费的位置</code>，以便在<code>断开连接或重新启动后继续消费</code>。消费者可以自主决定从哪个偏移量开始消费，也可以根据需要重置偏移量。通过管理偏移量，消费者可以实现消息的精确消费和处理。</p>\n<p><code>_consumer_offsets</code>介绍</p>\n<p>这个主题里面采用 <code>key 和 value</code>的方式存储数据。<code>key</code> 是 <code>group.id+topic+分区号</code>，<code>value</code> 就是当前 <code>offset</code> 的值。</p>\n<p>这个主题是用于存储消费者组的偏移量信息；可以记录消费者组在每个分区上消费的偏移量，以便在消费者组重新加入或者发生故障时能够继续消费未处理的消息。通过维护这个特殊主题，Kafka 可以跟踪每个消费者组的消费进度，以便进行负载均衡、容错和故障恢复</p>\n<p><code>coordinator</code> 和 <code>__consumer_offsets</code> 是一对多的关系，一个 <code>coordinator</code> 可以管理多个消费者组的偏移量信息。每个消费者组在 <code>__consumer_offsets</code> 主题中都会有<code>一个或多个分区</code>来存储其对应的分区的偏移量</p>\n</blockquote>\n<p>​    7.1、消费者提交offset的方式有两种</p>\n<p>​        7.1.1、<strong>自动提交</strong>（自动提交有可能出现<code>消息消费失败</code>，但是<code>却提交了offset的情况</code>，导致<strong>消息丢失</strong>）</p>\n<p>​        7.1.2、<strong>手动提交</strong> 两种方式</p>\n<p>​            1、<code>commitSync</code>（同步提交）：必须等待offset<code>提交完毕</code>，<code>再去</code>消费下一批数据。由于同步提交 offset 有失败重试机制，故更加可靠；但是由于会阻塞当前线程，直到提交成功。因此吞吐量会受到很大的影响，提交的效率比较低。</p>\n<p>​            2、<code>commitAsync</code>（异步提交）：发送完<code>提交offset请求</code>后，<code>就开始</code>消费下一批数据了。因此更多的情况下，会选用异步提交 offset 的方式</p>\n<p>​                同：本次提交的<code>一批数据都会以最高的偏移量</code>提交</p>\n<p>​                异： 同步提交会阻塞当前线程，一直到提交成功，并且会自动失败重试（由不可控因素导致，也会出现提交失败）；而异步提交则没有失败重试机制，故有可能提交失败。</p>\n<p>​    7.2、<font color=\"red\"><strong>指定消费Offset位置</strong></font></p>\n<p>当 <code>Kafka</code> 中<code>没有初始偏移量</code>（消费者组第一次消费）或<code>服务器上不再存在</code>当前偏移量时（例如该数据已被删除），该怎么办？ 自己指定消费位移</p>\n<p>（1）<code>earliest</code>：自动将偏移量重置为最<code>早</code>的偏移量</p>\n<p>（2）<code>latest</code>(默认值)：自动将偏移量重置为最<code>新</code>偏移量</p>\n<p>（3）<code>none</code>：如果未找到消费者组的<code>先前偏移量</code>，则向消费者<code>抛出异常</code></p>\n<p>（4）任意指定 offset 位移开始消费：Kafka中的<code>消费位移</code>是<code>存储</code>在一个<code>内部主题</code>中的， 而我们可以使用<strong><code>seek()</code></strong>方法可以突破这一限制；就是将<code>消费位移</code>保存在<code>任意的存储介质</code>中，在下次消费的时候可以<code>读取</code>存储在数据表中的<code>消费位移</code>并通过<code>seek()</code>方法指向这个具体的位置</p>\n<p>​    7.3、<font color=\"red\"><strong>指定时间消费</strong></font></p>\n<p>​    通过查到<code>时间对应</code>的<code>offset</code>去指定位移消费，为了确保能够同步到分区信息，我们还需要确保能<code>获取到分区</code>，再去<code>查询分区时间</code></p>\n<h3 id=\"10、消费问题及解决\"><a href=\"#10、消费问题及解决\" class=\"headerlink\" title=\"10、消费问题及解决\"></a>10、消费问题及解决</h3><p>​    1、<strong>重复消费：</strong>已经消费了数据，但是 offset 没提交；自动提交offset引起。</p>\n<p>​    2、<strong>漏消费：</strong>先提交 offset 后消费，有可能会造成数据的漏消费；设置<code>offset</code>为手动提交，当<code>offset</code>被提交时，数据还在内存中未落盘，此时刚好消费者线程被<code>kill</code>掉，那么<code>offset</code>已经提交，但是数据未处理，导致这部分内存中的数据丢失。</p>\n<blockquote>\n<p>解决：要想 既不漏消费也不重复消费; 可以使用 <code>消费者事务</code></p>\n</blockquote>\n<p>​    3、<strong>消费者事务</strong></p>\n<p>如果想完成Consumer端的精准一次性消费，那么需要Kafka消费端将<code>消费过程和提交offset</code>过程做<code>原子绑定</code>。此时我们需要将Kafka的<code>offset</code>保存到支持事务的<code>自定义介质</code></p>\n<p>​    4、<strong>数据积压</strong>：</p>\n<p>​        1、原因和解决</p>\n<p>​            1、如果是<code>Kafka</code>消费能力不足，则可以考虑增加<code>Topic</code>的<code>分区数</code>，并且同时提升<code>消费组的消费者</code>数量，<code>消费者数 = 分区数</code>（两者缺一不可）</p>\n<p>​            2、如果是下游的数据处理不及时，批次拉取数据过少（<code>处理速度 &lt; 生产速度</code>），使处理的数据小于生产的数据，也会造成数据积压。<code>提高每批次拉取的数量</code>。</p>\n<p>​    5、<strong>拦截器作用</strong></p>\n<p>​        1、使用拦截器的<code>onConsume()</code>方法来对消息进行相应的<code>定制化操作</code></p>\n<p>​        2、提交完消费位移之后调用拦截器的<strong><code>onCommit()</code></strong>方法， 可以使用这个方法来记录跟踪所提交的<code>位移信息</code>的具体细节</p>\n<h3 id=\"11、面试\"><a href=\"#11、面试\" class=\"headerlink\" title=\"11、面试\"></a>11、面试</h3><ol>\n<li><p>生产者原理?<br>简述： 首先main线程作为消息生产的主线程，经过拦截器（处理消息），再到序列化器（非JDK自带），最后到分区器，分区器维护 Record Accumulator（消息累加器），用于将多个消息合并成一个批次。</p>\n<p>Sender线程是专门用于消息发送的线程，当 Record Accumulator中的 双端队列的batch size 大小达到16k 或者 超出等待时间 就会触发Sender线程，sender线程有一个请求池，请求消息累加器中的消息发送给Kafka Broker 就会得到ack 应答 ，ack应答成功就会生成累加器中的消息批次、失败则会进行重试，默认能接受五个请求没有被应答（避免消息丢失，且异步），没有 拉取消费发送至Kafka集群。</p>\n</li>\n<li><p>为什么需要额外实现序列化器<br>JDK自带的序列化器太重</p>\n</li>\n<li><p>数据乱序怎么解决<br>Kafka单分区内的数据有序，原因是In Flight Requests，默认每个broker缓存五个请求，当出现乱序时会自动排序。</p>\n</li>\n<li><p>在存储日志的时候，它的索引是按照什么方法存储的？<br>日志是按照稀疏索引的方式存储的，每往log文件写入4kb数据，就会往index文件写入一条索引。且保存的是相对的offset，避免占用过多的空间。</p>\n</li>\n<li><p>如何高效的读写数据？<br><strong>顺序读写：</strong>磁盘分为顺序读写与随机读写，基于磁盘的随机读写确实很慢，但磁盘的顺序读写性能却很高，kafka 这里采用的就是顺序读写。<br>Page Cache：为了优化读写性能，Kafka 利用了操作系统本身的 Page Cache。数据直接写入page cache定时刷新脏页到磁盘即可。消费者拉取消息时，如果数据在page cache中，甚至能不需要去读磁盘io。读操作可直接在 Page Cache 内进行。如果消费和生产速度相当，甚至不需要通过物理磁盘（直接通过 Page Cache）交换数据。<br>Broker 收到数据后，写磁盘时只是将数据写入 Page Cache，并不保证数据一定完全写入磁盘。从这一点看，可能会造成机器宕机时，Page Cache 内的数据未写入磁盘从而造成数据丢失。但是这种丢失只发生在机器断电等造成操作系统不工作的场景，而这种场景完全可以由 Kafka 层面的 Replication 机制去解决。如果为了保证这种情况下数据不丢失而强制将 Page Cache 中的数据 Flush 到磁盘，反而会降低性能。也正因如此，Kafka 虽然提供了flush.messages和flush.ms两个参数将 Page Cache 中的数据强制 Flush 到磁盘，但是 Kafka 并不建议使用。</p>\n<p><strong>零拷贝：</strong>Kafka使用了零拷贝技术，也就是直接将数据从内核空间的读缓冲区直接拷贝到内核空间的 socket 缓冲区，然后再写入到 NIC 缓冲区，避免了在内核空间和用户空间之间穿梭。<br>分区分段+稀疏索引Kafka 的 message 是按 topic分 类存储的，topic 中的数据又是按照一个一个的 partition 即分区存储到不同 broker 节点。每个 partition 对应了操作系统上的一个文件夹，partition 实际上又是按照segment分段存储的。通过这种分区分段的设计，Kafka 的 message 消息实际上是分布式存储在一个一个小的 segment 中的，每次文件操作也是直接操作的 segment。为了进一步的查询优化，Kafka 又默认为分段后的数据文件建立了索引文件，就是文件系统上的.index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度。</p>\n<p><strong>批量读写：</strong>生产者可以借助累加器，批量发送消息，消费者也可以批量拉取消费。Kafka 数据读写也是批量的而不是单条的,这样可以避免在网络上频繁传输单个消息带来的延迟和带宽开销。假设网络带宽为10MB/S，一次性传输10MB的消息比传输1KB的消息10000万次显然要快得多。<br>数据压缩:Producer 可将数据压缩后发送给 broker，从而减少网络传输代价，目前支持的压缩算法有：Snappy、Gzip、LZ4。数据压缩一般都是和批处理配套使用来作为优化手段的。</p>\n</li>\n<li><p>零拷贝原理是什么？<br><strong>零拷贝：</strong>Kafka使用了零拷贝技术，也就是直接将数据从内核空间的读缓冲区直接拷贝到内核空间的 socket 缓冲区，然后再写入到 NIC 缓冲区，避免了在内核空间和用户空间之间穿梭。</p>\n</li>\n<li><p>什么是用户态？ 什么是内核态？<br>用户态（User Mode）：当进程在执行用户自己的代码时，则称其处于用户运行态。<br>内核态（Kernel Mode）：当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态，此时处理器处于特权级最高的内核代码中执行。</p>\n<p>为什么分内核态和用户态？<br>假设没有内核态和用户态之分，程序就可以随意读写硬件资源了，比如随意读写和分配内存，这样如果程序员一不小心将不适当的内容写到了不该写的地方，很可能就会导致系统崩溃。</p>\n<p>而有了用户态和内核态的区分之后，程序在执行某个操作时会进行一系列的验证和检验之后，确认没问题之后才可以正常的操作资源，这样就不会担心一不小心就把系统搞坏的情况了，也就是有了内核态和用户态的区分之后可以让程序更加安全的运行，但同时两种形态的切换会导致一定的性能开销。</p>\n</li>\n<li><p>消费者初始化流程是什么样的？<br>通过对GroupId进行Hash得到那台服务器的coordinator ，coordinator负责选出消费组中的Leader ，并且协调信息。真正存储消费记录的是 _consumer_offsets_partition 。</p>\n</li>\n<li><p>如何做到精确一次性消费？<br>开启事务 ，以及幂等性</p>\n<p>生产者端 -&gt; 集群</p>\n<p>集群 -&gt; 消费者</p>\n<p>消费者-&gt; 框架(数据库)</p>\n</li>\n<li><p>为什么kafka不做读写分离？  读写分离是指生产者发送到Leader副本，消费者从Follower副本读取。</p>\n<ol>\n<li><p>延时问题：数据从leader副本到follow副本是需要过程的，从网络&gt;主节点内存 -&gt;主节点磁盘 -&gt; 网络 -&gt; 从节点内存 -&gt; 从节点磁盘，比较耗时不适合对实时性要求高的应用。</p>\n</li>\n<li><p>负载均衡：读写分离，很大一部分原因是怕同一个节点负载过大。但是kafka通过分区的负载均衡，天然的就均衡了各个broker的压力。</p>\n</li>\n</ol>\n</li>\n<li><p>如何保证Kafka消息可靠性？<br>生产端：ack设置为-1，保证消息同步到follower副本。发送消息方式设置为同步或者异步，做好失败回滚措施<br>broker端：页缓存pagecache设置直接刷盘模式，确保不会有消息在页缓存中的时候宕机。<br>消费端：关闭消息自动提交，改为手动提交。避免消息没消费完就提交了offset导致消息丢失<br>总得来说，要保证严格的可靠性，就会失去很大的可用性，这是一个平衡的过程。</p>\n</li>\n<li><p>消息堆积怎么办？<br>我们都知道，消息的消费速度取决于消费者的速度，在消费速度不变的情况下，增加分组内消费者的个数，能倍速的提高消费速度。而消费者的个数又受限于分区个数，消费者个数超过分区数后，再提高消费者个数就没有意义。</p>\n<p>为了能够再提高临时的速度，我们还可以设置临时topic在临时主题中，去加大分区数，将所有原消费者直接将消息再次投递到临时topic中，进行更大规模消费群的消费。这是一个取巧的方案，适合解决临时大量消息的堆积。</p>\n</li>\n<li><p>分区数越多，吞吐量就会越高吗？<br>在一定条件下，分区数的数量是和吞吐量成正比的，分区数和性能也是成正比的。但是超过了限度后，不升反降。</p>\n<p>从以下四个方面来阐述：</p>\n<ol>\n<li><p>客户端/服务器端需要使用的内存就越多</p>\n<p>服务端在很多组件中都维护了分区级别的缓存，比如controller，FetcherManager等，分区数越大，缓存成本也就越大。<br>消费端的消费线程数是和分区数挂钩的，分区数越大消费线程数也就越多，线程的开销成本也就越大<br>生产者发送消息有缓存的概念，会为每个分区缓存消息，当积累到一定程度或者时间时会将消息发送到分区，分区越多，这部分的缓存也就越大</p>\n</li>\n<li><p>文件句柄的开销</p>\n<p>每个 partition 都会对应磁盘文件系统的一个目录。在 Kafka 的数据日志文件目录中，每个日志数据段都会分配两个文件，一个索引文件和一个数据文件。每个 broker 会为每个日志段文件打开一个 index 文件句柄和一个数据文件句柄。因此，随着 partition 的增多，所需要保持打开状态的文件句柄数也就越多，最终可能超过底层操作系统配置的文件句柄数量限制。</p>\n</li>\n<li><p>越多的分区可能增加端对端的延迟</p>\n<p>Kafka 会将分区 HW 之前的消息暴露给消费者。分区越多则副本之间的同步数量就越多，在默认情况下，每个 broker 从其他 broker 节点进行数据副本复制时，该 broker 节点只会为此工作分配一个线程，该线程需要完成该 broker 所有 partition 数据的复制。</p>\n</li>\n<li><p>降低高可用性</p>\n<p>Kafka通过副本(replica)机制来保证高可用。具体做法就是为每个分区保存若干个副本(replica_factor指定副本数)。每个副本保存在不同的broker上。其中的一个副本充当leader 副本，负责处理producer和consumer请求。其他副本充当follower角色，由Kafka controller负责保证与leader的同步。如果leader所在的broker挂掉了，contorller会检测到然后在zookeeper的帮助下重选出新的leader——这中间会有短暂的不可用时间窗口，虽然大部分情况下可能只是几毫秒级别。但如果你有10000个分区，10个broker，也就是说平均每个broker上有1000个分区。此时这个broker挂掉了，那么zookeeper和controller需要立即对这1000个分区进行leader选举。比起很少的分区leader选举而言，这必然要花更长的时间，并且通常不是线性累加的。如果这个broker还同时是controller情况就更糟了。</p>\n</li>\n</ol>\n</li>\n<li><p>kafka如何提升吞吐量</p>\n<ul>\n<li><strong>提升生产吞吐量</strong></li>\n<li><strong>增加分区</strong></li>\n<li><strong>消费者提高吞吐量</strong></li>\n<li><strong>增加下游消费者处理能力</strong></li>\n</ul>\n</li>\n<li><p><strong>数据精准一次如何实现</strong></p>\n<ul>\n<li><p><strong>生产者角度</strong></p>\n<ul>\n<li>acks 设置为-1 （acks=-1）</li>\n<li>幂等性（enable.idempotence = true） + 事务 。</li>\n</ul>\n</li>\n<li><p><strong>broker</strong> <strong>服务端角度</strong></p>\n</li>\n</ul>\n</li>\n</ol>\n<ul>\n<li><p>分区副本大于等于 2 （—replication-factor 2）。</p>\n</li>\n<li><p>ISR 里应答的最小副本数量大于等于 2 （min.insync.replicas = 2）。</p>\n</li>\n<li><p><strong>消费者</strong></p>\n<ul>\n<li><p>事务 + 手动提交 offset （enable.auto.commit = false）</p>\n</li>\n<li><p>消费者输出的目的地必须支持事务（MySQL、Kafka）</p>\n</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li><p><strong>服务器挂了怎么办</strong></p>\n<p>在生产环境中，如果某个 Kafka 节点挂掉。</p>\n<p>正常处理办法：</p>\n<p>（1）先尝试重新启动一下，如果能启动正常，那直接解决。</p>\n<p>（2）如果重启不行，考虑增加内存、增加 CPU、网络带宽。</p>\n<p>（3）如果将 kafka 整个节点误删除，如果副本数大于等于 2，可以按照服役新节点的方式重新服役一个新节点，并执行负载均衡</p>\n</li>\n<li><p>如果一个 segment 中有一部分数据过期，一部分没有过期，怎么处理：</p>\n</li>\n</ol>\n<p>​    Kafka 会优先删除过期的数据，因为Kafka 日志保留策略默认采用时间戳索引，来管理消息的过期时间，因此到达过期时间的消息更容易被标记为过期数据并被删除；Kafka 会在 Segment 的下一个 Offset 处创建新的 Segment，并将未过期的数据写入到新的 Segment 中，从而将旧的 Segment 就可以被删除了，同时 Segment 文件不会出现不连续的情况。如果消息的过期时间比较长，导致未过期和过期的数据混杂在同一个 Segment 中，并且新消息写入速度较慢，那么就可能导致 Kafka 无法及时删除过期数据，从而影响性能。在这种情况下，可以考虑<code>手动触发</code>一次<code>日志清理操作</code>来<code>强制删除过期的数据</code>，<code>或者调整 Segment 的大小</code>，使得消息过期的频率更高。</p>\n</PID,>","_path":"post/186242d5.html","_link":"http://rycan.top/post/186242d5.html","_id":"clnscmc9f000va80ph4ssan3a"}}