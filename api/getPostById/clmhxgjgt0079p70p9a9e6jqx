{"type":"getPostById","data":{"title":"计算机网络","date":"2023-09-13T15:45:37.000Z","description":"面试精选","categories":[{"name":"FaceToFace","_id":"clmhxgjfz000tp70pg45khpkv"}],"tags":[{"name":"计算机网络","_id":"clmhxgjgv007qp70pc7ebadn9"}],"content":"<meta name=\"referrer\" content=\"no-referrer\">\n<h3 id=\"1、键入网址到网页显示，期间发生了什么？\">1、键入网址到网页显示，期间发生了什么？</h3>\n<p>1、第一步工作是解析 URL，从而生成发送给 <code>Web</code> 服务器的请求信息</p>\n<h3 id=\"2、域名解析的工作流程\">2、域名解析的工作流程</h3>\n<blockquote>\n<p>本地–&gt;根—&gt;顶级—&gt;权威</p>\n</blockquote>\n<ol>\n<li>客户端首先会发出一个 DNS 请求，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。</li>\n<li>本地域名服务器收到客户端的请求后，如果缓存中能找到对应的URL，则它直接返回 IP 地址。如果没有，本地 DNS 会访问根域名服务器。</li>\n<li>根 DNS 收到来自本地 DNS 的请求后，会根据后缀进行解析分配对应的顶级域名服务器。</li>\n<li>本地 DNS 收到顶级域名服务器的地址后，进行寻找；</li>\n<li>顶级域名服务器分配对应的权威 DNS 服务器的地址。</li>\n<li>本地 DNS 于是转向问权威 DNS 服务器，从而获取域名解析结果的原出处。</li>\n<li>权威 DNS 服务器查询后将对应的 IP 地址告诉本地 DNS。</li>\n<li>本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。</li>\n</ol>\n<blockquote>\n<p>那是不是每次解析域名都要经过那么多的步骤呢？</p>\n<p>不是，有缓存</p>\n<p>浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」</p>\n</blockquote>\n<h3 id=\"3、TCP三次握手\">3、TCP三次握手</h3>\n<blockquote>\n<p>TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而<strong>建立连接是通过三次握手来进行的</strong>。</p>\n</blockquote>\n<ul>\n<li>一开始，客户端和服务端都处于 <code>CLOSED</code> 状态。先是服务端主动监听某个端口，处于 <code>LISTEN</code> 状态。</li>\n<li>然后客户端主动发起连接 <code>SYN</code>，之后处于 <code>SYN-SENT</code> 状态。</li>\n<li>服务端收到发起的连接，返回 <code>SYN</code>，并且 <code>ACK</code> 客户端的 <code>SYN</code>，之后处于 <code>SYN-RCVD</code> 状态。</li>\n<li>客户端收到服务端发送的 <code>SYN</code> 和 <code>ACK</code> 之后，发送对 <code>SYN</code> 确认的 <code>ACK</code>，之后处于 <code>ESTABLISHED</code> 状态，因为它一发一收成功了。</li>\n<li>服务端收到 <code>ACK</code> 的 <code>ACK</code> 之后，处于 <code>ESTABLISHED</code> 状态，因为它也一发一收了。</li>\n</ul>\n<p>所以三次握手目的是<strong>保证双方都有发送和接收的能力</strong>。</p>\n<blockquote>\n<h3 id=\"为什么是三次握手？不是两次、四次？\">为什么是三次握手？不是两次、四次？</h3>\n<p>相信大家比较常回答的是：“因为三次握手才能保证双方具有接收和发送的能力。”</p>\n<p>这回答是没问题，但这回答是片面的，并没有说出主要的原因。</p>\n<p>在前面我们知道了什么是 <strong>TCP 连接</strong>：</p>\n<ul>\n<li>用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 <strong>Socket、序列号和窗口大小</strong>称为连接。</li>\n</ul>\n<p>所以，重要的是<strong>为什么三次握手才可以初始化 Socket、序列号和窗口大小并建立 TCP 连接。</strong></p>\n<p>接下来，以三个方面分析三次握手的原因：</p>\n<ul>\n<li>三次握手才可以阻止重复历史连接的初始化（主要原因）；三次握手的<strong>首要原因是为了防止旧的重复连接初始化造成混乱。</strong></li>\n<li>三次握手才可以同步双方的初始序列号 ；<strong>确保双方的初始序列号能被可靠的同步。</strong></li>\n<li>三次握手才可以避免资源浪费</li>\n</ul>\n<p><strong>如果是两次握手连接，就无法阻止历史连接</strong>，那为什么 TCP 两次握手为什么无法阻止历史连接呢？</p>\n<p>我先直接说结论，主要是因为<strong>在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费</strong>。</p>\n<p>四次握手其实也能够可靠的同步双方的初始化序号，但由于<strong>第二步和第三步可以优化成一步</strong>，所以就成了「三次握手」。而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。</p>\n<p>如果只有「两次握手」，当客户端发生的 <code>SYN</code> 报文在网络中阻塞，客户端没有接收到 <code>ACK</code> 报文，就会重新发送 <code>SYN</code> ，<strong>由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 <code>ACK</code> 报文，所以服务端每收到一个 <code>SYN</code> 就只能先主动建立一个连接</strong>，这会造成什么情况呢？如果客户端发送的 <code>SYN</code> 报文在网络中阻塞了，重复发送多次 <code>SYN</code> 报文，那么服务端在收到请求后就会<strong>建立多个冗余的无效链接，造成不必要的资源浪费。</strong></p>\n<p>两次握手会造成消息滞留情况下，服务端重复接受无用的连接请求 <code>SYN</code> 报文，而造成重复分配资源。</p>\n</blockquote>\n<blockquote>\n<p>不使用「两次握手」和「四次握手」的原因：</p>\n<ul>\n<li>「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；</li>\n<li>「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>第一次握手丢失了，会发生什么？</p>\n<p>当客户端想和服务端建立 TCP 连接的时候，首先第一个发的就是 SYN 报文，然后进入到 <code>SYN_SENT</code> 状态。</p>\n<p>在这之后，如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，而且<strong>重传的 SYN 报文的序列号都是一样的</strong>。</p>\n<p>第二次握手丢失了，会发生什么？</p>\n<p>当服务端收到客户端的第一次握手后，就会回 SYN-ACK 报文给客户端，这个就是第二次握手，此时服务端会进入 <code>SYN_RCVD</code> 状态。</p>\n<p>第二次握手的 <code>SYN-ACK</code> 报文其实有两个目的 ：</p>\n<ul>\n<li>第二次握手里的 ACK， 是对第一次握手的确认报文；</li>\n<li>第二次握手里的 SYN，是服务端发起建立 TCP 连接的报文；</li>\n</ul>\n<p>所以，如果第二次握手丢了，因为第二次握手报文里是包含对客户端的第一次握手的 ACK 确认报文，所以，如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是<strong>客户端就会触发超时重传机制，重传 SYN 报文</strong>。然后，因为第二次握手中包含服务端的 SYN 报文，所以当客户端收到后，需要给服务端发送 ACK 确认报文（第三次握手），服务端才会认为该 SYN 报文被客户端收到了。那么，如果第二次握手丢失了，服务端就收不到第三次握手，于是<strong>服务端这边会触发超时重传机制，重传 SYN-ACK 报文</strong>。因此，当第二次握手丢失了，客户端和服务端都会重传：客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 <code>tcp_syn_retries</code>内核参数决定；服务端会重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 <code>tcp_synack_retries</code> 内核参数决定。</p>\n<p>第三次握手丢失了，会发生什么？</p>\n<p>客户端收到服务端的 SYN-ACK 报文后，就会给服务端回一个 ACK 报文，也就是第三次握手，此时客户端状态进入到 <code>ESTABLISH</code> 状态。</p>\n<p>因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。</p>\n<p>注意，<strong>ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文</strong>。</p>\n</blockquote>\n<p><strong>syn攻击是什么</strong></p>\n<p>SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样<strong>当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃</strong>，导致客户端无法和服务端建立连接。</p>\n<p>避免 SYN 攻击方式，可以有以下四种方法：</p>\n<ul>\n<li>调大 netdev_max_backlog；</li>\n<li>增大 TCP 半连接队列；</li>\n<li>开启 tcp_syncookies；</li>\n<li>减少 SYN+ACK 重传次数</li>\n</ul>\n<h3 id=\"4、Linux-接收网络包的流程\">4、Linux 接收网络包的流程</h3>\n<p>1、最简单的一种方式就是触发中断，也就是每当网卡收到一个网络包，就触发一个中断告诉操作系统。但是高并发的时候会导致效率低下</p>\n<p>2、 <strong>NAPI 机制</strong>：是混合「中断和轮询」的方式来接收网络包，它的核心概念就是<strong>不采用中断的方式读取数据</strong>，而是首先采用中断唤醒数据接收的服务程序，然后 <code>poll</code> 的方法来轮询数据。当有网络包到达时，会通过 DMA 技术，将网络包写入到指定的内存地址，接着网卡向 CPU 发起硬件中断，当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数</p>\n<h3 id=\"5、HTTP\">5、HTTP</h3>\n<p>1、是什么：超文本传输协议：双向协议；是一个在计算机世界里专门用来在<strong>两点之间传输数据</strong>的约定和规范</p>\n<p>2、POST VS. GET</p>\n<p>​\t<strong>GET 的语义是从服务器获取指定的资源</strong>，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）</p>\n<p>​\t<strong>POST 的语义是根据请求负荷（报文body）对指定的资源做出处理</strong>，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中，body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。</p>\n<p>3、安全性和幂等性</p>\n<ul>\n<li>在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。</li>\n</ul>\n<p><strong>GET 方法就是安全且幂等的</strong>，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，<strong>可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签</strong>。</p>\n<p><strong>POST</strong> 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是<strong>不安全</strong>的，且多次提交数据就会创建多个资源，所以<strong>不是幂等</strong>的。所以，<strong>浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签</strong>。</p>\n<p>做个简要的<strong>小结</strong>，就与RFC规范定义的语义分析：</p>\n<p>GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。</p>\n<p>POST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。</p>\n<p>但是实际过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。比如：</p>\n<p>可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。</p>\n<p>可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。</p>\n<p>4、GET 请求可以带 body 吗？</p>\n<p>RFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。</p>\n<p>5、HTTP缓存技术</p>\n<p>实现方式：</p>\n<p>​\t1、<strong>缓存在本地</strong>：下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。</p>\n<p>​\t2、HTTP 缓存有两种实现方式，分别是<strong>强制缓存和协商缓存</strong>。可以避免发送 http 请求</p>\n<p>强制缓存： 只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。</p>\n<p>协商缓存：通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存，<strong>就是与服务端协商之后，通过协商结果来判断是否使用本地缓存</strong>。</p>\n<p>6、特点</p>\n<p>优点：简单，易于拓展，灵活，应用广泛和跨平台，</p>\n<p>缺点：</p>\n<p>​\t1、<em>无状态双刃剑</em>（无状态的<strong>好处</strong>，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务；但是无状态的<strong>坏处</strong>，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦）「对于无状态的问题，解法方案有很多种，其中比较简单的方式用 <strong>Cookie</strong> 技术。」、</p>\n<p>​\t2、<em>明文传输双刃剑</em>（方便阅读的，但是信息的内容都毫无隐私可言，很容易就能被窃取）</p>\n<p>​\t3、<em>不安全</em></p>\n<p>性能：</p>\n<p><em>1. 长连接</em>：减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载；持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态</p>\n<p><em>2. 管道网络传输</em>：可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以<strong>减少整体的响应时间。</strong></p>\n<p><em>3. 队头阻塞</em>:「请求 - 应答」的模式会造成 HTTP 的性能问题;因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「<strong>队头阻塞</strong>」</p>\n<p>7、http 和 https</p>\n<ul>\n<li>HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。</li>\n<li>HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。</li>\n<li>两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。</li>\n<li>HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。</li>\n</ul>\n<p>8、https-解决了-http-的哪些问题</p>\n<p>http 明文传输所以会有下面的风险</p>\n<ul>\n<li><strong>窃听风险</strong>，比如通信链路上可以获取通信内容，用户号容易没。</li>\n<li><strong>篡改风险</strong>，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。</li>\n<li><strong>冒充风险</strong>，比如冒充淘宝网站，用户钱容易没。</li>\n</ul>\n<p>https 加入的 <code>SSL/TLS</code> 协议是怎么解决的</p>\n<ul>\n<li><strong>信息加密</strong>：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。</li>\n<li><strong>校验机制</strong>：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。</li>\n<li><strong>身份证书</strong>：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。</li>\n</ul>\n<p>HTTPS 是如何解决上面的三个风险的？</p>\n<ul>\n<li><strong>混合加密</strong>的方式实现信息的<strong>机密性</strong>，解决了窃听的风险。</li>\n<li><strong>摘要算法</strong>的方式来实现<strong>完整性</strong>，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。</li>\n<li>将服务器公钥放入到<strong>数字证书</strong>中，解决了冒充的风险。</li>\n</ul>\n<p><strong>HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全</strong>。</p>\n<p>9、如何避免http发送请求</p>\n<p>对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求-响应」的数据都<strong>缓存在本地</strong>，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。</p>\n<p>客户端会把第一次请求以及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，而响应作为 value，两者形成映射关系。这样当后续发起相同的请求时，就可以先在本地磁盘上通过 key 查到对应的 value，也就是响应，如果找到了，就直接从本地读取该响应。</p>\n<p>10、如何减少http发送请求</p>\n<p>1、<em>减少重定向请求次数</em>；如果<strong>重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数了</strong>；而且当代理服务器知晓了重定向规则后，可以进一步减少消息传递次数</p>\n<p>2、<em>合并请求</em>；把多个访问小文件的请求合并成一个大的请求，虽然传输的总资源还是一样，但是减少请求，也就意味着<strong>减少了重复发送的 HTTP 头部</strong>。<strong>合并请求的方式就是合并资源，以一个大资源的请求替换多个小资源的请求</strong>。但是这样的合并请求会带来新的问题，<strong>当大资源中的某一个小资源发生变化后，客户端必须重新下载整个完整的大资源文件</strong>，这显然带来了额外的网络消耗</p>\n<p>3、<em>延迟发送请求</em>；一般 HTML 里会含有很多 HTTP 的 URL，当前不需要的资源，我们没必要也获取过来，于是可以通过「<strong>按需获取</strong>」的方式，来减少第一时间的 HTTP 请求次数；请求网页的时候，没必要把全部资源都获取到，而是只获取当前用户所看到的页面资源，当用户向下滑动页面的时候，再向服务器获取接下来的资源，这样就达到了延迟发送请求的效果</p>\n<p>11、如何减少 HTTP 响应的数据大小</p>\n<p>对于 HTTP 的请求和响应，通常 HTTP 的响应的数据大小会比较大，也就是服务器返回的资源会比较大。</p>\n<p>于是，我们可以考虑对响应的资源进行<strong>压缩</strong>，这样就可以减少响应的数据大小，从而提高网络传输的效率。</p>\n<p>压缩的方式一般分为 2 种，分别是：</p>\n<p>​\t1、<em>无损压缩</em>：无损压缩是指资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样，适合用在文本文件、程序可执行文件、程序源代码。</p>\n<p>​\t2、<em>有损压缩</em>：与无损压缩相对的就是有损压缩，经过此方法压缩，解压的数据会与原始数据不同但是非常接近。有损压缩主要将次要的数据舍弃，牺牲一些质量来减少数据量、提高压缩比，这种方法经常用于压缩多媒体数据，比如音频、视频、图片。</p>\n<blockquote>\n<p>这次主要从 3 个方面介绍了优化 HTTP/1.1 协议的思路。</p>\n<p>第一个思路是，通过缓存技术来避免发送 HTTP 请求。客户端收到第一个请求的响应后，可以将其缓存在本地磁盘，下次请求的时候，如果缓存没过期，就直接读取本地缓存的响应数据。如果缓存过期，客户端发送请求的时候带上响应数据的摘要，服务器比对后发现资源没有变化，就发出不带包体的 304 响应，告诉客户端缓存的响应仍然有效。</p>\n<p>第二个思路是，减少 HTTP 请求的次数，有以下的方法：</p>\n<ol>\n<li>将原本由客户端处理的重定向请求，交给代理服务器处理，这样可以减少重定向请求的次数；</li>\n<li>将多个小资源合并成一个大资源再传输，能够减少 HTTP 请求次数以及 头部的重复传输，再来减少 TCP 连接数量，进而省去 TCP 握手和慢启动的网络消耗；</li>\n<li>按需访问资源，只访问当前用户看得到/用得到的资源，当客户往下滑动，再访问接下来的资源，以此达到延迟请求，也就减少了同一时间的 HTTP 请求次数。</li>\n</ol>\n<p>第三思路是，通过压缩响应资源，降低传输资源的大小，从而提高传输效率，所以应当选择更优秀的压缩算法。</p>\n<p>不管怎么优化 HTTP/1.1 协议都是有限的，不然也不会出现 HTTP/2 和 HTTP/3 协议，后续我们再来介绍 HTTP/2 和 HTTP/3 协议。</p>\n</blockquote>\n<p>12、既然有 HTTP 协议，为什么还要有 RPC</p>\n<p>1、只有TCP 的时候： TCP 是有三个特点，<strong>面向连接</strong>、<strong>可靠</strong>、基于<strong>字节流</strong>。但是由于基于字节流，就会导致 <strong>粘包问题</strong>，所以纯裸 TCP 是不能直接拿来用的，你需要在这个基础上加入一些<strong>自定义的规则</strong>，用于区分<strong>消息边界</strong>。</p>\n<p>2、<strong>TCP 是传输层的协议</strong>，而基于 TCP 造出来的 HTTP 和<strong>各类</strong> RPC 协议，它们都只是定义了不同消息格式的<strong>应用层协议</strong>而已。</p>\n<p>3、虽然大部分 RPC 协议底层使用 TCP，但实际上<strong>它们不一定非得使用 TCP，改用 UDP 或者 HTTP，其实也可以做到类似的功能。</strong></p>\n<p>4、<strong>HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构。但现在其实已经没分那么清了，B/S 和 C/S 在慢慢融合。*<em>很多软件同时支持多端，比如某度云盘，既要支持*<em>网页版</em></em>，还要支持</strong>手机端和 PC 端**，如果通信协议都用 HTTP 的话，那服务器只用同一套就够了。而 RPC 就开始退居幕后，一般用于公司内部集群里，各个微服务之间的通讯。</p>\n<p>5、本质：</p>\n<p>​\t1、区别</p>\n<p>​\t服务发现：首先要向某个服务器发起请求，你得先建立连接，而建立连接的前提是，你得知道 <strong>IP 地址和端口</strong>。这个找到服务对应的 IP 端口的过程，其实就是<strong>服务发现</strong>。在 <strong>HTTP</strong> 中，你知道服务的域名，就可以通过 <strong>DNS 服务</strong>去解析得到它背后的 IP 地址，默认 80 端口。而 <strong>RPC</strong> 的话，就有些区别，一般会有专门的<strong>中间服务</strong>去保存服务名和IP信息，比如 <strong>Consul 或者 Etcd，甚至是 Redis</strong>。想要访问某个服务，就去这些中间服务去获得 IP 和端口信息。由于 DNS 也是服务发现的一种，所以也有基于 DNS 去做服务发现的组件，比如<strong>CoreDNS</strong>。</p>\n<p>​\t底层连接形式：以主流的 <strong>HTTP/1.1</strong> 协议为例，其默认在建立底层 TCP 连接之后会一直保持这个连接（<strong>Keep Alive</strong>），之后的请求和响应都会复用这条连接。而 <strong>RPC</strong> 协议，也跟 HTTP 类似，也是通过建立 TCP 长链接进行数据交互，但不同的地方在于，RPC 协议一般还会再建个<strong>连接池</strong>，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，<strong>用完放回去，下次再复用</strong>，可以说非常环保。<strong>由于连接池有利于提升网络请求性能，所以不少编程语言的网络库里都会给 HTTP 加个连接池</strong></p>\n<p>​\t传输的内容：基于 TCP 传输的消息，说到底，无非都是<strong>消息头 Header 和消息体 Body。Header 是用于标记一些特殊信息，其中最重要的是</strong>消息体长度**。<strong>Body则是放我们真正需要传输的内容，而这些内容只能是二进制 01 串，毕竟计算机只认识这玩意。所以 TCP 传字符串和数字都问题不大，因为字符串可以转成编码再变成 01 串，而数字本身也能直接转为二进制。但结构体呢，我们得想个办法将它也转为二进制 01 串，这样的方案现在也有很多现成的，比如 <strong>Json，Protobuf。<strong>这个将结构体转为二进制数组的过程就叫</strong>序列化</strong>，反过来将二进制数组复原成结构体的过程叫</strong>反序列化**。而 RPC，因为它定制化程度更高，可以采用体积更小的 Protobuf 或其他序列化协议去保存结构体数据，同时也不需要像 HTTP 那样考虑各种浏览器行为，比如 302 重定向跳转啥的。<strong>因此性能也会更好一些，这也是在公司内部微服务中抛弃 HTTP，选择使用 RPC 的最主要原因。</strong></p>\n<p>13、既然有 HTTP 协议，为什么还要有 Socket</p>\n<p>1、<strong>怎么样才能在用户不做任何操作的情况下，网页能收到消息并发生变更。</strong></p>\n<p>​\t1.1、最常见的解决方案是，<strong>网页的前端代码里不断定时发 HTTP 请求到服务器，服务器收到请求后给客户端响应消息</strong></p>\n<p>​\t1.1.1、使用HTTP定时轮询</p>\n<p>​\t但这样，会有两个比较明显的问题：</p>\n<ul>\n<li>当你打开 F12 页面时，你会发现满屏的 HTTP 请求。虽然很小，但这其实也消耗带宽，同时也会增加下游服务器的负担。</li>\n<li>最坏情况下，用户在扫码后，需要等个 1~2 秒，正好才触发下一次 HTTP 请求，然后才跳转页面，用户会感到<strong>明显的卡顿</strong>。</li>\n</ul>\n<p>​\t1.1.2、长轮询</p>\n<p>​\t在较长时间内等待服务器响应的机制，就是所谓的<strong>长训轮机制</strong>。我们常用的消息队列 RocketMQ 中，消费者去取数据时，也用到了这种方式。在用户不感知的情况下，服务器将数据推送给浏览器的技术，就是所谓的<strong>服务器推送</strong>技术</p>\n<p>上面提到的两种解决方案（不断轮询和长轮询），本质上，其实还是客户端主动去取数据。对于像扫码登录这样的<strong>简单场景</strong>还能用用</p>\n<p>1.2、 <strong>WebSocket</strong></p>\n<p>但如果是网页游戏呢，游戏一般会有大量的数据需要从服务器主动推送到客户端。<strong>使用WebSocket</strong></p>\n<p>这是由于 HTTP 协议设计之初，考虑的是看看网页文本的场景，能做到<strong>客户端发起请求再由服务器响应</strong>，就够了，根本就没考虑网页游戏这种，客户端和服务器之间都要互相主动发大量数据的场景。所以，为了更好的支持这样的场景，我们需要另外一个<strong>基于TCP的新协议</strong>。于是新的应用层协议<strong>WebSocket</strong>就被设计出来了。</p>\n<p>浏览器在 <strong>TCP 三次握手</strong>建立连接之后，都<strong>统一使用 HTTP 协议</strong>先进行一次通信。</p>\n<ul>\n<li>如果此时是<strong>普通的 HTTP 请求</strong>，那后续双方就还是老样子继续用普通 HTTP 协议进行交互，这点没啥疑问。</li>\n<li>如果这时候是<strong>想建立 WebSocket 连接</strong>，就会在 HTTP 请求里带上一些<strong>特殊的header 头</strong></li>\n</ul>\n<blockquote>\n<p>“WebSocket 是基于HTTP的新协议”，<strong>其实这并不对</strong>，因为WebSocket只有在建立连接时才用到了HTTP，<strong>升级完成之后就跟HTTP没有任何关系了</strong></p>\n</blockquote>\n<p>使用场景：</p>\n<p>​\tWebSocket完美继承了 TCP 协议的<strong>全双工</strong>能力，并且还贴心的提供了解决粘包的方案。它适用于<strong>需要服务器和客户端（浏览器）频繁交互</strong>的大部分场景，比如网页/小程序游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。</p>\n<blockquote>\n<p>正因为各个浏览器都支持 HTTP协 议，所以 WebSocket 会先利用HTTP协议加上一些特殊的 header 头进行握手升级操作，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。</p>\n</blockquote>\n<h3 id=\"6、TCP四次挥手\">6、TCP四次挥手</h3>\n<p>1、为什么需要TCP协议</p>\n<p><code>IP</code> 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 <code>TCP</code> 协议来负责。因为 TCP 是一个工作在<strong>传输层</strong>的<strong>可靠</strong>数据传输的服务，它能确保接收端接收的网络包是<strong>无损坏、无间隔、非冗余和按序的。</strong></p>\n<p>2、特点</p>\n<p>TCP 是<strong>面向连接的、可靠的、基于字节流</strong>的传输层通信协议。</p>\n<ul>\n<li><strong>面向连接</strong>：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；</li>\n<li><strong>可靠的</strong>：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；</li>\n<li><strong>字节流</strong>：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。</li>\n</ul>\n<p>3、<strong>TCP 和 UDP 应用场景：</strong></p>\n<p>由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：</p>\n<ul>\n<li><code>FTP</code> 文件传输；</li>\n<li>HTTP / HTTPS；</li>\n</ul>\n<p>由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于：</p>\n<ul>\n<li>包总量较少的通信，如 <code>DNS</code> 、<code>SNMP</code> 等；</li>\n<li>视频、音频等多媒体通信；</li>\n<li>广播通信；</li>\n</ul>\n<p>4、过程</p>\n<ul>\n<li>客户端打算关闭连接，此时会发送一个 TCP 首部 <code>FIN</code> 标志位被置为 <code>1</code> 的报文，也即 <code>FIN</code> 报文，之后客户端进入 <code>FIN_WAIT_1</code> 状态。</li>\n<li>服务端收到该报文后，就向客户端发送 <code>ACK</code> 应答报文，接着服务端进入 <code>CLOSE_WAIT</code> 状态。</li>\n<li>客户端收到服务端的 <code>ACK</code> 应答报文后，之后进入 <code>FIN_WAIT_2</code> 状态。</li>\n<li>等待服务端处理完数据后，也向客户端发送 <code>FIN</code> 报文，之后服务端进入 <code>LAST_ACK</code> 状态。</li>\n<li>客户端收到服务端的 <code>FIN</code> 报文后，回一个 <code>ACK</code> 应答报文，之后进入 <code>TIME_WAIT</code> 状态</li>\n<li>服务端收到了 <code>ACK</code> 应答报文后，就进入了 <code>CLOSE</code> 状态，至此服务端已经完成连接的关闭。</li>\n<li>客户端在经过 <code>2MSL</code> 一段时间后，自动进入 <code>CLOSE</code> 状态，至此客户端也完成连接的关闭</li>\n</ul>\n<p>5、为什么挥手需要四次？</p>\n<p>再来回顾下四次挥手双方发 <code>FIN</code> 包的过程，就能理解为什么需要四次了。</p>\n<ul>\n<li>关闭连接时，客户端向服务端发送 <code>FIN</code> 时，仅仅表示客户端不再发送数据了但是还能接收数据。</li>\n<li>服务端收到客户端的 <code>FIN</code> 报文时，先回一个 <code>ACK</code> 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 <code>FIN</code> 报文给客户端来表示同意现在关闭连接。</li>\n</ul>\n<p>从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 <code>ACK</code> 和 <code>FIN</code> 一般都会分开发送，因此是需要四次挥手。</p>\n<p>第一次挥手丢失了，会发生什么？</p>\n<p>当客户端（主动关闭方）调用 close 函数后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 <code>FIN_WAIT_1</code> 状态。</p>\n<p>正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 <code>FIN_WAIT2</code>状态。</p>\n<p>如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 <code>tcp_orphan_retries</code> 参数控制。当客户端重传 FIN 报文的次数超过 <code>tcp_orphan_retries</code> 后，就不再发送 FIN 报文，则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，那么直接进入到 <code>close</code> 状态。</p>\n<p>第二次挥手丢失了，会发生什么？</p>\n<p>当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 <code>CLOSE_WAIT</code> 状态。</p>\n<p>在前面我们也提了，ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。</p>\n<p>第三次挥手丢失了，会发生什么？</p>\n<p>当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 <code>CLOSE_WAIT</code> 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。</p>\n<p>此时，内核是没有权利替代进程关闭连接，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。</p>\n<p>服务端处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。</p>\n<p>如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 <code>tcp_orphan_retrie</code>s 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。</p>\n<p>第四次挥手丢失了，会发生什么？</p>\n<p>当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 <code>TIME_WAIT</code> 状态。</p>\n<p>在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。</p>\n<p>然后，服务端（被动关闭方）没有收到 ACK 报文前，还是处于 LAST_ACK 状态。</p>\n<p>如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 <code>tcp_orphan_retries</code> 参数控制。</p>\n<p>为什么 TIME_WAIT 等待的时间是 2MSL？</p>\n<p><code>MSL</code> 是 Maximum Segment Lifetime，<strong>报文最大生存时间</strong>，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 <strong>MSL 应该要大于等于 TTL 消耗为 0 的时间</strong>，以确保报文已被自然消亡。TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以<strong>一来一回需要等待 2 倍的时间</strong>。可以看到 <strong>2MSL时长</strong> 这其实是相当于<strong>至少允许报文丢失一次</strong>。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。<code>2MSL</code> 的时间是从<strong>客户端接收到 FIN 后发送 ACK 开始计时的</strong>。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 <strong>2MSL 时间将重新计时</strong>。</p>\n<p>为什么需要 TIME_WAIT 状态？</p>\n<p>主动发起关闭连接的一方，才会有 <code>TIME-WAIT</code> 状态。</p>\n<p>需要 TIME-WAIT 状态，主要是两个原因：</p>\n<ul>\n<li>防止历史连接中的数据，被后面相同四元组的连接错误的接收；</li>\n<li>保证「被动关闭连接」的一方，能被正确的关闭</li>\n</ul>\n<p>如何优化 TIME_WAIT？</p>\n<p>这里给出优化 TIME-WAIT 的几个方式，都是有利有弊：</p>\n<ul>\n<li>打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；</li>\n<li>net.ipv4.tcp_max_tw_buckets</li>\n<li>程序中使用 SO_LINGER ，应用强制使用 RST 关闭。</li>\n</ul>\n<p>服务器出现大量 TIME_WAIT 状态的原因有哪些？</p>\n<p>首先要知道 TIME_WAIT 状态是主动关闭连接方才会出现的状态，所以如果服务器出现大量的 TIME_WAIT 状态的 TCP 连接，就是说明服务器主动断开了很多 TCP 连接。</p>\n<p>问题来了，<strong>什么场景下服务端会主动断开连接呢？</strong></p>\n<ul>\n<li>第一个场景：HTTP 没有使用长连接</li>\n<li>第二个场景：HTTP 长连接超时</li>\n<li>第三个场景：HTTP 长连接的请求数量达到上限</li>\n</ul>\n<p>服务器出现大量 CLOSE_WAIT 状态的原因有哪些？</p>\n<p>CLOSE_WAIT 状态是「被动关闭方」才会有的状态，而且如果「被动关闭方」没有调用 close 函数关闭连接，那么就无法发出 FIN 报文，从而无法使得 CLOSE_WAIT 状态的连接转变为 LAST_ACK 状态。</p>\n<p>所以，<strong>当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接</strong>。</p>\n<p><strong>第一个原因</strong>：第 2 步没有做，没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了。</p>\n<p>不过这种原因发生的概率比较小，这种属于明显的代码逻辑 bug，在前期 read view 阶段就能发现的了。</p>\n<p><strong>第二个原因</strong>： 第 3 步没有做，有新连接到来时没有调用 accpet 获取该连接的 socket，导致当有大量的客户端主动断开了连接，而服务端没机会对这些 socket 调用 close 函数，从而导致服务端出现大量 CLOSE_WAIT 状态的连接。</p>\n<p>发生这种情况可能是因为服务端在执行 accpet 函数之前，代码卡在某一个逻辑或者提前抛出了异常。</p>\n<p><strong>第三个原因</strong>：第 4 步没有做，通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了。</p>\n<p>发生这种情况可能是因为服务端在将已连接的 socket 注册到 epoll 之前，代码卡在某一个逻辑或者提前抛出了异常。之前看到过别人解决 close_wait 问题的实践文章，感兴趣的可以看看：<a href=\"https://mp.weixin.qq.com/s?__biz=MzU3Njk0MTc3Ng==&amp;mid=2247486020&amp;idx=1&amp;sn=f7cf41aec28e2e10a46228a64b1c0a5c&amp;scene=21#wechat_redirect\">一次 Netty 代码不健壮导致的大量 CLOSE_WAIT 连接原因分析(opens new window)</a></p>\n<p><strong>第四个原因</strong>：第 6 步没有做，当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等。</p>\n<p>可以发现，<strong>当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题，这时候我们需要针对具体的代码一步一步的进行排查和定位，主要分析的方向就是服务端为什么没有调用 close</strong></p>\n<p>如果已经建立了连接，但是客户端突然出现故障了怎么办？</p>\n<p>客户端出现故障指的是客户端的主机发生了宕机，或者断电的场景。发生这种情况的时候，如果服务端一直不会发送数据给客户端，那么服务端是永远无法感知到客户端宕机这个事件的，也就是服务端的 TCP 连接将一直处于 <code>ESTABLISH</code> 状态，占用着系统资源。</p>\n<p>为了避免这种情况，TCP 搞了个<strong>保活机制</strong>。这个机制的原理是这样的：定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p>\n<p>Socket中：accept 发生在三次握手的哪一步？</p>\n<p><strong>客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。</strong></p>\n<p><strong>TCP 四次挥手中，能不能把第二次的 ACK 报文， 放到第三次 FIN 报文一起发送？</strong></p>\n<p>虽然我们在学习 TCP 挥手时，学到的是需要四次来完成 TCP 挥手，但是<strong>在一些情况下， TCP 四次挥手是可以变成 TCP 三次挥手的</strong>。</p>\n<p>为什么 TCP 挥手需要四次呢</p>\n<p>服务器收到客户端的 FIN 报文时，内核会马上回一个 ACK 应答报文，<strong>但是服务端应用程序可能还有数据要发送，所以并不能马上发送 FIN 报文，而是将发送 FIN 报文的控制权交给服务端应用程序</strong>：</p>\n<ul>\n<li>如果服务端应用程序有数据要发送的话，就发完数据后，才调用关闭连接的函数；</li>\n<li>如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，</li>\n</ul>\n<p>从上面过程可知，**是否要发送第三次挥手的控制权不在内核，而是在被动关闭方（上图的服务端）的应用程序，因为应用程序可能还有数据要发送，由应用程序决定什么时候调用关闭连接的函数，当调用了关闭连接的函数，内核就会发送 FIN 报文了，**所以服务端的 ACK 和 FIN 一般都会分开发送。</p>\n<blockquote>\n<p>FIN 报文一定得调用关闭连接的函数，才会发送吗？ 不一定。 如果进程退出了，不管是不是正常退出，还是异常退出（如进程崩溃），内核都会发送 FIN 报文，与对方完成四次挥手。</p>\n</blockquote>\n<p>粗暴关闭 vs 优雅关闭</p>\n<p>前面介绍 TCP 四次挥手的时候，并没有详细介绍关闭连接的函数，其实关闭的连接的函数有两种函数：</p>\n<ul>\n<li>close 函数，同时 socket 关闭发送方向和读取方向，也就是 socket 不再有发送和接收数据的能力。如果有多进程/多线程共享同一个 socket，如果有一个进程调用了 close 关闭只是让 socket 引用计数 -1，并不会导致 socket 不可用，同时也不会发出 FIN 报文，其他进程还是可以正常读写该 socket，直到引用计数变为 0，才会发出 FIN 报文。</li>\n<li>shutdown 函数，可以指定 socket 只关闭发送方向而不关闭读取方向，也就是 socket 不再有发送数据的能力，但是还是具有接收数据的能力。如果有多进程/多线程共享同一个 socket，shutdown 则不管引用计数，直接使得该 socket 不可用，然后发出 FIN 报文，如果有别的进程企图使用该 socket，将会受到影响。</li>\n</ul>\n<p>如果客户端是用 close 函数来关闭连接，那么在 TCP 四次挥手过程中，如果收到了服务端发送的数据，由于客户端已经不再具有发送和接收数据的能力，所以客户端的内核会回 RST 报文给服务端，然后内核会释放连接，这时就不会经历完成的 TCP 四次挥手，所以我们常说，调用 close 是粗暴的关闭。</p>\n<p>当服务端收到 RST 后，内核就会释放连接，当服务端应用程序再次发起读操作或者写操作时，就能感知到连接已经被释放了：</p>\n<ul>\n<li>如果是读操作，则会返回 RST 的报错，也就是我们常见的Connection reset by peer。</li>\n<li>如果是写操作，那么程序会产生 SIGPIPE 信号，应用层代码可以捕获并处理信号，如果不处理，则默认情况下进程会终止，异常退出。</li>\n</ul>\n<p>相对的，shutdown 函数因为可以指定只关闭发送方向而不关闭读取方向，所以即使在 TCP 四次挥手过程中，如果收到了服务端发送的数据，客户端也是可以正常读取到该数据的，然后就会经历完整的 TCP 四次挥手，所以我们常说，调用 shutdown 是优雅的关闭。shutdown 函数也可以指定「只关闭读取方向，而不关闭发送方向」，但是这时候内核是不会发送 FIN 报文的，因为发送 FIN 报文是意味着我方将不再发送任何数据，而 shutdown 如果指定「不关闭发送方向」，就意味着 socket 还有发送数据的能力，所以内核就不会发送 FIN。</p>\n<p>什么情况会出现三次挥手</p>\n<p>当被动关闭方（上图的服务端）在 TCP 挥手过程中，「<strong>没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。</strong></p>\n<p>因为 TCP 延迟确认机制是默认开启的，所以导致我们抓包时，看见三次挥手的次数比四次挥手还多。</p>\n<blockquote>\n<p>什么是 TCP 延迟确认机制？</p>\n</blockquote>\n<p>当发送没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。 为了解决 ACK 传输效率低问题，所以就衍生出了 <strong>TCP 延迟确认</strong>。 TCP 延迟确认的策略：</p>\n<ul>\n<li>当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方</li>\n<li>当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送</li>\n<li>如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK</li>\n</ul>\n<blockquote>\n<p>当被动关闭方在 TCP 挥手过程中，如果「没有数据要发送」，同时「没有开启 TCP_QUICKACK（默认情况就是没有开启，没有开启 TCP_QUICKACK，等于就是在使用 TCP 延迟确认机制）」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。</p>\n<p><strong>所以，出现三次挥手现象，是因为 TCP 延迟确认机制导致的。</strong></p>\n</blockquote>\n<h3 id=\"7、TCP-重传、滑动窗口、流量控制、拥塞控制\">7、TCP 重传、滑动窗口、流量控制、拥塞控制</h3>\n<p>1、重传机制 ：  TCP 实现可靠传输的方式之一，是通过序列号与确认应答。所以 TCP 针对数据包丢失的情况，会用<strong>重传机制</strong>解决</p>\n<p>常见的重传机制：</p>\n<ul>\n<li>\n<p>超时重传：</p>\n<p>重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 <code>ACK</code> 确认应答报文，就会重发该数据，也就是我们常说的<strong>超时重传</strong></p>\n<p>TCP 会在以下两种情况发生超时重传：     数据包丢失、确认应答丢失</p>\n</li>\n<li>\n<p>快速重传：</p>\n<p>TCP 还有另外一种<strong>快速重传（Fast Retransmit）机制</strong>，它<strong>不以时间为驱动，而是以数据驱动重传</strong></p>\n</li>\n<li>\n<p>SACK</p>\n<p><code>SACK</code>（ Selective Acknowledgment）， <strong>选择性确认</strong>。</p>\n<p>这种方式需要在 TCP 头部「选项」字段里加一个 <code>SACK</code> 的东西，它<strong>可以将已收到的数据的信息发送给「发送方」</strong>，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以<strong>只重传丢失的数据</strong>。</p>\n</li>\n<li>\n<p>D-SACK</p>\n<p>Duplicate SACK 又称 <code>D-SACK</code>，其主要<strong>使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。</strong></p>\n</li>\n</ul>\n<p>2、滑动窗口</p>\n<p>窗口大小就是指<strong>无需等待确认应答，而可以继续发送数据的最大值</strong>。窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。</p>\n<p>窗口大小由哪一方决定？TCP 头里有一个字段叫 <code>Window</code>，也就是窗口大小。**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**所以，通常窗口的大小是由接收方的窗口大小来决定的。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。</p>\n<blockquote>\n<p>接收窗口和发送窗口的大小是相等的吗？</p>\n</blockquote>\n<p>并不是完全相等，接收窗口的大小是<strong>约等于</strong>发送窗口的大小的。</p>\n<p>因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。</p>\n<p>3、流量控制</p>\n<p>发送方不能无脑的发数据给接收方，要考虑接收方处理能力。</p>\n<p>如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。</p>\n<p>为了解决这种现象发生，<strong>TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。</strong></p>\n<p>TCP 通过让接收方指明希望从发送方接收的数据大小（窗口大小）来进行流量控制。</p>\n<p><strong>如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。</strong></p>\n<blockquote>\n<p>窗口关闭潜在的危险 ：  导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象</p>\n</blockquote>\n<blockquote>\n<p>TCP 是如何解决窗口关闭时，潜在的死锁现象呢？</p>\n</blockquote>\n<p>为了解决这个问题，TCP 为每个连接设有一个持续定时器，<strong>只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。</strong></p>\n<p>如果持续计时器超时，就会发送<strong>窗口探测 ( Window probe ) 报文</strong>，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。</p>\n<p>糊涂窗口综合症</p>\n<p>如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。</p>\n<p>到最后，<strong>如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症</strong>。</p>\n<p>4、拥塞控制</p>\n<blockquote>\n<p>为什么要有拥塞控制呀，不是有流量控制了吗？</p>\n</blockquote>\n<p>前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。</p>\n<p>一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。</p>\n<p><strong>在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大…</strong></p>\n<p>所以，TCP 不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP 会自我牺牲，降低发送的数据量。</p>\n<p>于是，就有了<strong>拥塞控制</strong>，控制的目的就是<strong>避免「发送方」的数据填满整个网络。</strong></p>\n<p>为了在「发送方」调节所要发送数据的量，定义了一个叫做「<strong>拥塞窗口</strong>」的概念。</p>\n<blockquote>\n<p>什么是拥塞窗口？和发送窗口有什么关系呢？</p>\n</blockquote>\n<p><strong>拥塞窗口 cwnd</strong>是发送方维护的一个的状态变量，它会根据<strong>网络的拥塞程度动态变化的</strong>。</p>\n<p>我们在前面提到过发送窗口 <code>swnd</code> 和接收窗口 <code>rwnd</code> 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。</p>\n<p>拥塞窗口 <code>cwnd</code> 变化的规则：</p>\n<ul>\n<li>只要网络中没有出现拥塞，<code>cwnd</code> 就会增大；</li>\n<li>但网络中出现了拥塞，<code>cwnd</code> 就减少；</li>\n</ul>\n<blockquote>\n<p>那么怎么知道当前网络是否出现了拥塞呢？</p>\n</blockquote>\n<p>其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是<strong>发生了超时重传，就会认为网络出现了拥塞。</strong></p>\n<blockquote>\n<p>拥塞控制有哪些控制算法？</p>\n</blockquote>\n<p>拥塞控制主要是四个算法：</p>\n<ul>\n<li>\n<p>慢启动： 慢启动的意思就是一点一点的提高发送数据包的数量，如果一上来就发大量的数据，这不是给网络添堵吗？慢启动的算法记住一个规则就行：<strong>当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。</strong></p>\n</li>\n<li>\n<p>拥塞避免： 当拥塞窗口 <code>cwnd</code> 「超过」慢启动门限 <code>ssthresh</code> 就会进入拥塞避免算法。那么进入拥塞避免算法后，它的规则是：<strong>每当收到一个 ACK 时，cwnd 增加 1/cwnd。</strong></p>\n</li>\n<li>\n<p>拥塞发生</p>\n<p>当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：</p>\n<ul>\n<li>超时重传</li>\n<li>快速重传</li>\n</ul>\n</li>\n<li>\n<p>快速恢复</p>\n<p>快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 <code>RTO</code> （超时重传时间）超时那么强烈。也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长。</p>\n</li>\n</ul>\n<p>解决粘包问题：</p>\n<p>粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。</p>\n<p>一般有三种方式分包的方式：</p>\n<ul>\n<li>固定长度的消息；</li>\n<li>特殊字符作为边界；</li>\n<li>自定义消息结构。</li>\n</ul>\n<p>TCP 协议有哪些缺陷？主要有四个方面：</p>\n<ul>\n<li>升级 TCP 的工作很困难；</li>\n<li>TCP 建立连接的延迟；</li>\n<li>TCP 存在队头阻塞问题；</li>\n<li>网络迁移需要重新建立 TCP 连接；</li>\n</ul>\n","_path":"post/e255a10a.html","_link":"http://rycan.top/post/e255a10a.html","_id":"clmhxgjgt0079p70p9a9e6jqx"}}