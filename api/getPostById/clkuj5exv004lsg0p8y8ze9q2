{"type":"getPostById","data":{"title":"单机redis基本概念","date":"2023-07-03T09:43:34.000Z","description":"单机模式下的redis基本介绍","categories":[{"name":"redis","_id":"clkuj5exq0031sg0pa7aigby6"}],"tags":[{"name":"redis","_id":"clkuj5exr0035sg0p99rvfeq8"}],"content":"<meta name=\"referrer\" content=\"no-referrer\">\n<h2 id=\"NoSQL的特点：\"><code>NoSQL</code>的特点：</h2>\n<ol>\n<li>\n<p>相对于<code>MySQL</code>这样的<code>关系型</code>数据库来说，<code>非关系型</code>的数据库是基于内存操作的，读写速度非常的快，性能好些，</p>\n</li>\n<li>\n<p>关系型数据库一般使用<code>主从集群</code>的模式保证数据的一致性，进行数据的备份，即为垂直扩展；<code>非关系型</code>数据库是将<code>数据进行拆分</code>，分别存储在不同的机器上，用来保存海量的数据，解决<code>内存大小受限的问题</code>，即为水平扩展</p>\n</li>\n</ol>\n<h2 id=\"resdis的基本数据类型\"><code>resdis</code>的基本数据类型</h2>\n<h3 id=\"String\"><code>String</code></h3>\n<ul>\n<li>\n<p>String 是 <code>Redis</code> 最基本的类型，一个 key 对应一个 value。</p>\n</li>\n<li>\n<p><code>String</code> 类型是二进制安全的。意味着 Redis 的 string 可以包含任何数据。比如 jpg 图片或者序列化的对象。</p>\n</li>\n<li>\n<p>String 类型是 Redis 最基本的数据类型，一个 Redis 中字符串 value 最多可以是 512M。</p>\n</li>\n<li>\n<p>value 的数据类型有<code>string  int  float</code>   底层的存储方式是<code>字节数组形式</code></p>\n</li>\n<li>\n<p>其基本编码方式是RAW，基于简单动态字符串（SDS）实现，存储上限为512mb。</p>\n</li>\n</ul>\n<h4 id=\"数据结构\">数据结构</h4>\n<ul>\n<li>\n<p>底层实现⽅式：动态字符串sds 或者 long</p>\n<ul>\n<li>\n<p>String的内部存储结构⼀般是sds（Simple Dynamic String，简单动态字符串），但是如果⼀个String类型的value的值是数字，那么Redis内部会把它转成long类型来存储，从⽽减少内存的使用。</p>\n</li>\n<li>\n<p>SDS 是  可以修改的字符串，内部结构实现上类似于 Java 的 ArrayList，采用<code>预分配冗余空间的方式</code>来减少内存的频繁分配.</p>\n</li>\n</ul>\n</li>\n<li>\n<p>如果存储的字符串是整数值，并且大小在LONG_MAX范围内，则会采用INT编码：直接将数据保存在RedisObject的ptr指针位置（刚好8字节），不再需要SDS了</p>\n</li>\n</ul>\n<h4 id=\"命令\">命令</h4>\n<ul>\n<li>\n<p><code>set  &lt;key&gt;&lt;value&gt;</code>           添加键值对</p>\n<ul>\n<li>*NX：当数据库中key不存在时，可以将key-value添加数据库</li>\n<li>*XX：当数据库中key存在时，可以将key-value添加数据库，与NX参数互斥</li>\n<li>*EX：key的超时秒数</li>\n<li>*PX：key的超时毫秒数，与EX互斥</li>\n</ul>\n</li>\n<li>\n<p><code>get   &lt;key&gt;    </code>查询对应键值</p>\n</li>\n<li>\n<p><code>append  &lt;key&gt;&lt;value&gt;</code>    将给定的<code>&lt;value&gt; </code>追加到原值的末尾</p>\n</li>\n<li>\n<p><code>strlen  &lt;key&gt;</code>                 获得值的长度</p>\n</li>\n<li>\n<p><code>setnx  &lt;key&gt;&lt;value&gt; </code>        只有在 key 不存在时才设置 key 的值</p>\n</li>\n<li>\n<p><code>incr  &lt;key&gt;</code>        将 key 中储存的数字值增1;只能对数字值操作，如果为空，新增值为1</p>\n</li>\n<li>\n<p><code>decr  &lt;key&gt;</code>        将 key 中储存的数字值减1;只能对数字值操作，如果为空，新增值为-1;</p>\n</li>\n<li>\n<p><code>incrby / decrby  &lt;key&gt;&lt;步长&gt;</code>       将 key 中储存的数字值增减。自定义步长。</p>\n</li>\n<li>\n<p><code>mset  &lt;key1&gt;&lt;value1&gt;&lt;key2&gt;&lt;value2&gt; ..... </code>       同时设置一个或多个 key-value对</p>\n</li>\n<li>\n<p><code>mget  &lt;key1&gt;&lt;key2&gt;&lt;key3&gt; ..... </code>      同时获取一个或多个 value</p>\n</li>\n<li>\n<p><code>msetnx &lt;key1&gt;&lt;value1&gt;&lt;key2&gt;&lt;value2&gt;.....   </code>     同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。</p>\n</li>\n<li>\n<p><code>getrange  &lt;key&gt;&lt;起始位置&gt;&lt;结束位置&gt;</code>      获得值的范围，类似java中的substring，前包，后包</p>\n</li>\n<li>\n<p><code>setrange  &lt;key&gt;&lt;起始位置&gt;&lt;value&gt;</code>      用 &lt;value&gt;  覆写&lt;key&gt;所储存的字符串值，从&lt;起始位置&gt;开始(索引从0开始)。</p>\n</li>\n<li>\n<p><code>setex  &lt;key&gt;&lt;过期时间&gt;&lt;value&gt;</code>       设置键值的同时，设置过期时间，单位秒。</p>\n</li>\n<li>\n<p><code>getset &lt;key&gt;&lt;value&gt;</code>       以新换旧，设置了新值同时获得旧值。</p>\n</li>\n</ul>\n<h3 id=\"hash\"><code>hash</code></h3>\n<ul>\n<li>\n<p>hash 是一个键值对集合; HashSet 的内部实现使用的是 HashMap，只不过所有的 value 都指向同一个对象&lt;可以解决 Bigkey 的问题 &gt;。</p>\n</li>\n<li>\n<p>与<code>Redis</code>中的<code>Zset</code>非常类似：</p>\n<ul>\n<li>都是键值存储</li>\n<li>都需求根据键获取值</li>\n<li>键必须唯一</li>\n<li><code>所有</code>的 value 都指向<code>同一个</code>内部值</li>\n</ul>\n</li>\n<li>\n<p>区别</p>\n<ul>\n<li><code>zset</code>的键是<code>member</code>，值是<code>score</code>；<code>hash</code>的键和值都是任意值</li>\n<li><code>zset</code>要根据<code>score</code>排序；<code>hash</code>则无需排序</li>\n</ul>\n</li>\n<li>\n<p>底层实现方式：压缩列表<code>ziplist</code> 或者<code> 字典dict</code>，当Hash中数据项比较少的情况下，Hash底层才⽤压缩列表<code>ziplist</code>进⾏存储数据，随着数据的增加，底层的<code>ziplist</code>就可能会转成<code>dict</code></p>\n</li>\n<li>\n<p>value 是一个无序字典,也是一个键值对，类似<code>Java</code>的 <code>HashMap</code></p>\n<ul>\n<li>应用： 可以针对每个字段做增删改查的操作    、 适合用于存储对象</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"数据结构-2\">数据结构</h4>\n<p>Hash 类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。当 field-value 长度较短且个数较少时，使用 ziplist，否则使用 hashtable。</p>\n<h4 id=\"命令-2\">命令</h4>\n<ul>\n<li><code>hset &lt;key&gt;&lt;field&gt;&lt;value&gt;</code>给&lt;key&gt;集合中的  &lt;field&gt;键赋值&lt;value&gt;</li>\n<li><code>hget &lt;key1&gt;&lt;field&gt;从&lt;key1&gt;</code>集合&lt;field&gt;取出 value</li>\n<li><code>hmset &lt;key1&gt;&lt;field1&gt;&lt;value1&gt;&lt;field2&gt;&lt;value2&gt;... </code>批量设置hash的值</li>\n<li><code>hexists&lt;key1&gt;&lt;field&gt;</code>查看哈希表 key 中，给定域 field 是否存在。</li>\n<li><code>hkeys &lt;key&gt;</code>列出该hash集合的所有field</li>\n<li><code>hvals &lt;key&gt;</code>列出该hash集合的所有value</li>\n<li><code>hincrby &lt;key&gt;&lt;field&gt;&lt;increment&gt;</code>为哈希表 key 中的域 field 的值加上增量 1   -1</li>\n<li><code>hsetnx &lt;key&gt;&lt;field&gt;&lt;value&gt;</code>将哈希表 key 中的域 field 的值设置为 value ，当且仅当域 field 不存在</li>\n</ul>\n<h3 id=\"list\"><code>list</code></h3>\n<ul>\n<li>\n<p>List结构类似一个双端链表，可以从首、尾操作列表中的元素：</p>\n</li>\n<li>\n<p>类似于<code>Java</code>中的<code>LinkedList</code> ,可以看成是一个双向链表的结构，可以<code>正向的检索</code>和<code>反向的检索  </code></p>\n<ul>\n<li>应用：<code>朋友圈点赞列表，评论列表</code></li>\n</ul>\n</li>\n</ul>\n<p>单键多值：Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。</p>\n<p>它的底层实际是个双向链表，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。</p>\n<h4 id=\"数据结构-3\">数据结构</h4>\n<p>List 的数据结构为快速链表 <code>quickList</code>。<br>\n首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 <code>ziplist</code>，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。<br>\n当数据量<code>比较多</code>的时候才会改成 <code>quicklist</code>。因为普通的链表需要的附加指针空间太大，会比较浪费空间。</p>\n<p>比如这个列表里存的只是 int 类型的数据，结构上还需要两个额外的<code>指针 </code> <code>prev 和 next</code>。</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042236127.png\" alt=\"image-20230313154703834\" style=\"zoom:33%;\">\nRedis 将链表和 ziplist 结合起来组成了 quicklist。也就是将多个 ziplist 使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。\n<h4 id=\"命令：\">命令：</h4>\n<ul>\n<li><code>lpush/rpush  &lt;key&gt;&lt;value1&gt;&lt;value2&gt;&lt;value3&gt; ....      </code>               从左边/右边插入一个或多个值。</li>\n<li><code>lpop/rpop  &lt;key&gt;</code>        从左边/右边吐出一个值。值在键在，值光键亡。</li>\n<li><code>rpop/lpush  &lt;key1&gt;&lt;key2&gt; </code>      从&lt;key1&gt;列表右边吐出一个值，插到&lt;key2&gt;列表左边。</li>\n<li><code>lrange &lt;key&gt;&lt;start&gt;&lt;stop&gt;</code>     按照索引下标获得元素(从左到右)；lrange mylist 0 -1   0左边第一个，-1右边第一个，（0-1表示获取所有）</li>\n<li><code>lindex &lt;key&gt;&lt;index&gt;</code>   按照索引下标获得元素(从左到右)</li>\n<li><code>llen &lt;key&gt; </code>     获得列表长度</li>\n<li><code>linsert &lt;key&gt;  before &lt;value&gt;&lt;newvalue&gt;</code>     在&lt;value&gt;的后面插入&lt;newvalue&gt;插入值</li>\n<li><code>lrem &lt;key&gt;&lt;n&gt;&lt;value&gt;</code>       从左边删除n个value(从左到右)</li>\n<li><code>lset&lt;key&gt;&lt;index&gt;&lt;value&gt;</code>       将列表key下标为index的值替换成value</li>\n</ul>\n<blockquote>\n<details><summary>常见的四种统计</summary>\n<pre>聚合统计       统计多个集合元素的聚合结果  <font color=\"red\">交差并等集合统计</font></pre>\n<pre>排序统计       在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议使用ZSet</pre>\n<pre>二值统计       集合元素的取值就只有0和1两种。在钉钉上签到打卡的场景中，我们只用记录有签到(1)或没有签单(0)</pre>\n<pre>基数统计       指统计一个集合中<font color=\"red\">不重复的元素个数</font>，就是对集合去重复后剩余元素的计算</pre>\n</details>\n</blockquote>\n<h3 id=\"set\"><code>set</code></h3>\n<ul>\n<li>\n<p>底层数据结构： <code>HashTable</code>，也就是Redis中的<code>Dict</code>，不过Dict是双列集合（可以存键、值对）</p>\n</li>\n<li>\n<p>为了查询效率和唯一性，set采用<code>HT编码（Dict）</code>。<code>Dict</code>中的key用来存储元素，value统一为null。</p>\n</li>\n<li>\n<p>当存储的所有数据都是整数，并且元素数量不超过<code>set-max-intset-entries</code>时，<code>Set</code>会采用<code>IntSet</code>编码，以节省内存</p>\n</li>\n<li>\n<p>类似于<code>hashset</code> ;内部实现相当于一个特殊的字典，字典中所有的value都是一个值NULL，可以看做是一个<code>value</code>为<code>null</code>的<code>HashMap</code></p>\n<ul>\n<li>应用： <code>微信抽奖小程序。（SRANDMEMBER） 微信朋友圈共友点赞。（SINTER）   QQ推荐可能认识的人。（SDIFF）</code></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"数据结构-4\">数据结构</h4>\n<p><code>Set </code>数据结构是<code> dict 字典</code>，字典是用<code>哈希表</code>实现的。<br>\nJava 中 <code>HashSet</code> 的内部实现使用的是 <code>HashMap</code>，只不过所有的 value 都指向同一个对象。Redis 的 set 结构也是一样，它的内部也使用 hash 结构，所有的 value 都指向同一个内部值。</p>\n<h4 id=\"命令-3\">命令</h4>\n<ul>\n<li><code>sadd &lt;key&gt;&lt;value1&gt;&lt;value2&gt; ..... </code>          将一个或多个 member 元素加入到集合 key 中，已经存在的 member 元素将被忽略</li>\n<li><code>smembers &lt;key&gt;</code>                                    取出该集合的所有值。</li>\n<li><code>sismember &lt;key&gt;&lt;value&gt;</code>                  判断集合&lt;key&gt;是否为含有该&lt;value&gt;值，有1，没有0</li>\n<li><code>scard&lt;key&gt;  </code>                                           返回该集合的元素个数。</li>\n<li><code>srem &lt;key&gt;&lt;value1&gt;&lt;value2&gt; ....         </code>              删除集合中的某个元素。</li>\n<li><code>spop &lt;key&gt;  </code>                                  随机从该集合中吐出一个值。</li>\n<li><code>srandmember &lt;key&gt;&lt;n&gt;</code>             随机从该集合中取出n个值。不会从集合中删除 。</li>\n<li><code>smove &lt;source&gt;&lt;destination&gt;value</code>                把集合中一个值从一个集合移动到另一个集合</li>\n<li><code>sinter &lt;key1&gt;&lt;key2&gt;</code>                返回两个集合的交集元素。</li>\n<li><code>sunion &lt;key1&gt;&lt;key2&gt;</code>                返回两个集合的并集元素。</li>\n<li><code>sdiff &lt;key1&gt;&lt;key2&gt;</code>                  返回两个集合的差集元素(key1中的，不包含key2中的)</li>\n</ul>\n<h3 id=\"SortSet-Zset\"><code>SortSet(Zset)</code></h3>\n<ul>\n<li>\n<p>底层数据结构：</p>\n<p><code>SkipList</code>：可以排序，并且可以同时存储score和ele值（member）</p>\n<p><code>HT（Dict</code>）：可以键值存储，并且可以根据key找value</p>\n</li>\n<li>\n<p><code>ziplist</code>本身没有排序功能，而且没有键值对的概念，因此需要有zset通过编码实现：</p>\n<ul>\n<li>ZipList是连续内存，因此score和element是紧挨在一起的两个entry， element在前，score在后</li>\n<li>score越小越接近队首，score越大越接近队尾，按照score值升序排列</li>\n</ul>\n</li>\n<li>\n<p>当元素数量不多时，HT和SkipList的优势不明显，而且更耗内存。因此zset还会采用ZipList结构来节省内存，不过需要同时满足两个条件：</p>\n<ul>\n<li>元素数量小于zset_max_ziplist_entries，默认值128</li>\n<li>每个元素都小于zset_max_ziplist_value字节，默认值64</li>\n</ul>\n</li>\n<li>\n<p>和<code>Set</code>的不同之处就是   有序集合的每个成员都关联了一个评分（score），这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了 。</p>\n</li>\n<li>\n<p>因为元素是有序的，所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。</p>\n</li>\n<li>\n<p>每一个元素都带有一个score属性，可以基于score属性对元素排序，底层的实现是一个跳表（SkipList）加 hash表,score的值可以是 整型 和浮点型并且可以重复</p>\n<ul>\n<li>应用：<code>排行榜</code></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"数据结构-5\">数据结构</h4>\n<ul>\n<li>\n<p>SortedSet (zset) 是 Redis 提供的一个非常特别的数据结构，</p>\n<ul>\n<li>一方面它等价于 Java 的数据结构<code> Map&lt;String,Double&gt;</code>，可以给每一个元素 <code>value</code> 赋予一个权重 <code>score</code>，</li>\n<li>另一方面它又类似于<code> TreeSet</code>，内部的元素会按照权重 <code>score</code> 进行排序，可以得到每个元素的名次，还可以通过 <code>score</code> 的范围来获取元素的列表。</li>\n</ul>\n</li>\n<li>\n<p>zset 底层使用了<code>两个数据结构</code>：</p>\n<ul>\n<li><code>hash</code>，hash 的作用就是关联元素 value 和权重 score，保障元素 value 的唯一性，可以通过元素 value 找到相应的 score 值。</li>\n<li><code>跳跃表</code>，跳跃表的目的在于给元素 value 排序，根据 score 的范围获取元素列表。</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"跳跃表\">跳跃表</h5>\n<h6 id=\"简介\">简介</h6>\n<p>对于有序集合的底层实现，可以用<code>数组、平衡树、链表</code>等。<code>数组</code>不便元素的插入、删除；<code>平衡树或红黑树</code>虽然效率高但结构复杂；<code>链表</code>查询需要遍历所有效率低。Redis 采用的是跳跃表，跳跃表效率堪比红黑树，实现远比红黑树简单。</p>\n<h6 id=\"使用举例\">使用举例</h6>\n<p>对比有序链表和跳跃表，从链表中查询出 51：</p>\n<ul>\n<li>有序链表</li>\n</ul>\n<p>​\t\t\t\t\t\t\t\t\t\t<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042310773.png\" alt=\"image-20230313155851093\" style=\"zoom:33%;\"><br>\n要查找值为 51 的元素，需要从第一个元素开始依次查找、比较才能找到。共需要 6 次比较。</p>\n<ul>\n<li>跳跃表</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042310006.png\" alt=\"image-20230313155905619\" style=\"zoom:33%;\">\n<p>从第 2 层开始，1 节点比 51 节点小，向后比较；</p>\n<p>21 节点比 51 节点小，继续向后比较，后面就是 NULL 了，所以从 21 节点向下到第 1 层；</p>\n<p>在第 1 层，41 节点比 51 节点小，继续向后，61 节点比 51 节点大，所以从 41 向下；</p>\n<p>在第 0 层，51 节点为要查找的节点，节点被找到，共查找 4 次。</p>\n<p>从此可以看出<code>跳跃表比有序链表效率要高</code>。</p>\n<h4 id=\"命令-4\">命令</h4>\n<ul>\n<li><code>zadd  &lt;key&gt;&lt;score1&gt;&lt;value1&gt;&lt;score2&gt;&lt;value2&gt;…</code> 将一个或多个 member 元素及其 score 值加入到有序集 key 当中。</li>\n<li><code>zrange &lt;key&gt;&lt;start&gt;&lt;stop&gt;  [WITHSCORES] </code>      返回有序集 key 中，下标在&lt;start&gt;&lt;stop&gt;之间的元素      带WITHSCORES，可以让分数一起和值返回到结果集。</li>\n<li><code>zrangebyscore key minmax [withscores] [limit offset count]</code><br>\n返回有序集 key 中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。</li>\n<li><code>zrevrangebyscore key maxmin [withscores] [limit offset count] </code><br>\n同上，改为从大到小排列。</li>\n<li><code>zincrby &lt;key&gt;&lt;increment&gt;&lt;value&gt;</code>      为元素的score加上增量</li>\n<li><code>zrem  &lt;key&gt;&lt;value&gt;</code>删除该集合下，指定值的元素</li>\n<li><code>zcount &lt;key&gt;&lt;min&gt;&lt;max&gt;</code>统计该集合，分数区间内的元素个数</li>\n<li><code>zrank &lt;key&gt;&lt;value&gt;</code>返回该值在集合中的排名，从0开始。</li>\n</ul>\n<h3 id=\"HyprLoglog\"><code>HyprLoglog</code></h3>\n<ul>\n<li>\n<p>一种概率数据结构，只会根据输入的元素来计算<code>计数</code>，<code>不会存储</code>输入的<code>元素本身</code></p>\n<ul>\n<li>应用： <code>网站文章的UV        网站某关键词的搜索数量        用户每天搜索的不同词条数目 </code></li>\n</ul>\n</li>\n<li>\n<p>什么是UV           Unique Visitor，独立访客，一般理解为客户端IP      <font color=\"red\">需要去重考虑</font></p>\n</li>\n<li>\n<p>什么是PV            Page View，页面浏览量        不用去重</p>\n</li>\n<li>\n<p>什么是DAU        Daily Active User，日活跃量用户，<font color=\"red\">登录或者使用了某个产品的用户数（去重复登录的用户）</font>    常用于反映网站、互联网应用或者网络游戏的运营情况</p>\n</li>\n<li>\n<p>什么是MAU        Monthly Active User，月活跃用户量</p>\n</li>\n</ul>\n<h4 id=\"HyprLoglog的引入：\">HyprLoglog的引入：</h4>\n<p>在工作当中，我们经常会遇到与<code>统计</code>相关的功能需求，比如统计网站 <code>PV</code>（PageView 页面访问量），可以使用 Redis 的<code> incr、incrby</code> 轻松实现</p>\n<p>但像<code> UV</code>（UniqueVisitor 独立访客)、独立 IP 数、搜索记录数等需要<code>去重和计数的问题如何解决</code>？这种<code>求集合中不重复元素个数的问题称为基数问题</code>。</p>\n<p>解决<code>基数(不重复)</code>问题有很多种方案：</p>\n<ul>\n<li>\n<p>数据存储在<code>MySQL</code>表中，使用 distinct count 计算不重复个数。</p>\n</li>\n<li>\n<p>使用 <code>Redis</code> 提供的 <code>hash</code>、<code>set</code>、<code>bitmaps</code> 等数据结构来处理。</p>\n</li>\n</ul>\n<p>​\t以上的方案<code>结果精确，但随着数据不断增加</code>，导致<code>占用空间越来越大</code>，对于<code>非常大的数据集</code>是不切实际的。</p>\n<blockquote>\n<p>能否能够降低一定的精度来平衡存储空间？Redis 推出了 <code>HyperLogLog</code>。</p>\n</blockquote>\n<p><code>Redis HyperLogLog</code> 是用来做基数统计的算法</p>\n<p><code>HyperLogLog</code> 的优点是：在输入元素的数量 或者 体积非常非常大时，计算基数所需的<code>空间总是固定的、并且是很小的</code>。</p>\n<p>在 Redis 里面，每个 <code>HyperLogLog</code> 键只需要花费 12 KB 内存，就可以计算接近 2<sup>64</sup> 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。</p>\n<p>但是，因为 <code>HyperLogLog</code> 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 <code>HyperLogLog</code> 不能像集合那样，返回输入的各个元素。</p>\n<h5 id=\"什么是基数？\">什么是基数？</h5>\n<p>比如数据集 {1, 3, 5, 7, 5, 7, 8}，那么这个数据集的基数集为 {1, 3, 5 ,7, 8}，基数 (不重复元素) 为 5。 基数估计就是在误差可接受的范围内，快速计算基数。</p>\n<ul>\n<li>去重方式\n<ul>\n<li>HashSet</li>\n<li>bitmap： 所占内存巨大；bitmaps还是不适用大数据量下(亿级)的基数计数场景，<font color=\"red\">但是bitmaps方法是精确计算的。</font></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"解决：\">解决：</h4>\n<ul>\n<li>概率算法\n<ul>\n<li><font color=\"red\">通过牺牲准确率来换取空间</font>，对于不要求<font color=\"blue\">绝对准确率</font>的场景下可以使用，因为<font color=\"red\">概率算法不直接存储数据本身</font>，通过一定的概率统计方法预估基数值，同时保证误差在一定范围内，由于又不储存数据故此可以大大节约内存.</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"原理\">原理</h4>\n<ul>\n<li>\n<p>只是进行不重复的基数统计，不是集合也不保存数据，只记录数量而不是具体内容</p>\n</li>\n<li>\n<p>有误差，但是很低 0.81% （<code>1.04/sqrt(16384)</code>）；HyperLogLog提供不精确的去重计数方案</p>\n</li>\n</ul>\n<h4 id=\"亿级UV的Redis设计方案\">亿级UV的Redis设计方案</h4>\n<h5 id=\"不可行的方案：\">不可行的方案：</h5>\n<ul>\n<li>MySQL   高并发下，3000万的数据就需要分库分表了</li>\n<li>redis的hash结构存储   太占内存了</li>\n</ul>\n<h5 id=\"可行的方案：\">可行的方案：</h5>\n<ul>\n<li>HyperLogLog   在Redis里面，每个HyperLogLog键只需要花费12KB内存，就可以计算接近2<sup>64</sup>个不同元素的基数</li>\n</ul>\n<blockquote>\n<p>为什么是只需要花费12Kb?</p>\n<p>Redist使用了2<sup>14</sup>=16384个桶，按照上面的标准差，误差为0.81%，精度相当高。Redis使用一个log型哈希值的前14个比特用来确定桶编号，剩下的50个比特用来做基数估计。而2<sup>6</sup>=64，所以只需要用6个比特表示下标值，在一般情况下，一个HyperLogLog数据结构(每个桶占6位)占用内存的大小为16384*6/8=12kB,Redis将这种情况称为密集(dense)存储。</p>\n</blockquote>\n<h4 id=\"命令-5\">命令</h4>\n<h5 id=\"pfadd\">pfadd</h5>\n<p>（1）格式</p>\n<p><code>pfadd &lt;key&gt;&lt; element&gt; [element ...]  </code> 添加指定元素到 HyperLogLog 中</p>\n<p>（2）实例</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307050003637.jpg\" style=\"zoom:33%;\">\n<blockquote>\n<p>将所有元素添加到指定HyperLogLog数据结构中。如果执行命令后HLL估计的近似基数发生变化，则返回1，否则返回0。</p>\n</blockquote>\n<h5 id=\"pfcount\">pfcount</h5>\n<p>（1）格式<br>\n<code>pfcount&lt;key&gt; [key ...]</code> 计算HLL的近似基数，可以计算多个HLL，比如用HLL存储每天的UV，计算一周的UV可以使用7天的UV合并计算即可</p>\n<p>（2）实例</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307050003096.jpg\" style=\"zoom:33%;\">\n<h5 id=\"pfmerge\">pfmerge</h5>\n<p>（1）格式<br>\n<code>pfmerge&lt;destkey&gt;&lt;sourcekey&gt; [sourcekey ...] </code> 将一个或多个HLL合并后的结果存储在另一个HLL中，比如每月活跃用户可以使用每天的活跃用户来合并计算可得</p>\n<p>（2）实例</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307050003841.jpg\" alt=\"img\" style=\"zoom:33%;\">\n<h3 id=\"Bitmap\"><code>Bitmap</code></h3>\n<ul>\n<li>\n<p>一种统计<code>二值状态</code>的数据类型，由多个二进制位组成，本质是数组，但是值只能是0和1，默认是 0;可以极大的节约存储空间, 每一个二进制位都对应一个偏移量</p>\n<ul>\n<li>应用：<code>打卡、签到     用户是否登陆过Y、N，比如软件的每日签到功能     电影、广告是否被点击播放过</code></li>\n</ul>\n</li>\n<li>\n<p>Bitmaps  可以实现对<code>位的操作</code>：Bitmaps 本身不是一种数据类型， 实际上它就是字符串（key-value） ， 但是它可以对字符串的位进行操作。</p>\n</li>\n<li>\n<p>Bitmaps 单独提供了一套命令， 所以在 Redis 中使用 Bitmaps 和使用字符串的方法不太相同。 可以把 Bitmaps 想象成一个以位为单位的数组， 数组的每个单元只能存储 0 和 1， 数组的下标在 Bitmaps 中叫做偏移量。</p>\n</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202303131617867.jpg\" alt=\"img\" style=\"zoom:33%;\">\n<h4 id=\"命令：-2\">命令：</h4>\n<h5 id=\"setbit\">setbit</h5>\n<p>（1）格式<br>\n<code>setbit&lt;key&gt;&lt;offset&gt;&lt;value&gt;</code>设置Bitmaps中某个偏移量的值（0或1）     *offset:偏移量从0开始</p>\n<p>（2）实例<br>\n每个独立用户是否访问过网站存放在Bitmaps中， 将访问的用户记做1， 没有访问的用户记做0， 用偏移量作为用户的id。设置键的第offset个位的值（从0算起） ， 假设现在有20个用户，userid=1， 6， 11， 15， 19的用户对网站进行了访问， 那么当前Bitmaps初始化结果如图</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042315887.jpg\" alt=\"img\" style=\"zoom:33%;\">\n<p>unique:users:20201106代表2020-11-06这天的<code>独立访问用户</code>的Bitmaps</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042315803.jpg\" style=\"zoom:33%;\">\n<blockquote>\n<p>注：很多应用的用户id以一个指定数字（例如10000） 开头， 直接将用户id和Bitmaps的偏移量对应势必会造成一定的浪费， 通常的做法是每次做setbit操作时将用户id减去这个指定数字。<br>\n在第一次初始化Bitmaps时， 假如偏移量非常大， 那么整个初始化过程执行会比较慢， 可能会造成redis的阻塞。</p>\n</blockquote>\n<h5 id=\"getbit\">getbit</h5>\n<p>（1）格式<br>\n<code>getbit&lt;key&gt;&lt;offset&gt;</code>获取Bitmaps中某个偏移量的值      获取键的第offset位的值（从0开始算）</p>\n<p>（2）实例<br>\n获取id=8的用户是否在2020-11-06这天访问过， 返回0说明没有访问过：</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042315474.jpg\" alt=\"img\" style=\"zoom:33%;\">\n<blockquote>\n<p>注：因为<code>100</code>根本不存在，所以也是返回<code>0</code></p>\n</blockquote>\n<h5 id=\"bitcount\">bitcount</h5>\n<p>统计字符串被设置为1的bit数。一般情况下，给定的整个字符串都会被进行计数，通过指定额外的 start 或 end 参数，可以让计数只在特定的位上进行。start 和 end 参数的设置，都可以使用负数值：比如 -1 表示最后一个位，而 -2 表示倒数第二个位，start、end 是指bit组的字节的下标数，二者皆包含。<br>\n（1）格式<br>\n<code>bitcount&lt;key&gt;[start end]</code>统计字符串从start字节到end字节比特值为1的数量</p>\n<p>（2）实例<br>\n计算2022-11-06这天的独立访问用户数量</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042315302.jpg\" alt=\"img\" style=\"zoom:33%;\">\n<p>start和end代表起始和结束字节数， 下面操作计算用户id在第1个字节到第3个字节之间的独立访问用户数， 对应的用户id是11， 15， 19。</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202303131620426.jpg\" alt=\"img\" style=\"zoom:33%;\">\n<p>举例： K1 【01000001 01000000  00000000 00100001】，对应【0，1，2，3】</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bitcount K1 1 2  ： </span><br><span class=\"line\">\t\t统计下标1、2字节组中bit=1的个数，</span><br><span class=\"line\">\t\t\t即01000000  00000000--&gt;bitcount K1 1 2 --&gt;1</span><br><span class=\"line\"></span><br><span class=\"line\">bitcount K1 1 3  ： </span><br><span class=\"line\">        统计下标1、2字节组中bit=1的个数，</span><br><span class=\"line\">        \t即01000000  00000000 00100001--&gt;bitcount K1 1 3 --&gt;3</span><br><span class=\"line\"></span><br><span class=\"line\">bitcount K1 0 -2  ： </span><br><span class=\"line\">        统计下标0到下标倒数第2，字节组中bit=1的个数，</span><br><span class=\"line\">        \t即01000001  01000000   00000000--&gt;bitcount K1 0 -2--&gt;3</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>注意：redis的setbit设置或清除的是bit位置，而bitcount计算的是byte位置。</p>\n</blockquote>\n<h5 id=\"bitop\">bitop</h5>\n<p>(1)格式<br>\n<code>bitop  and(or/not/xor) &lt;destkey&gt; [key…]</code></p>\n<p>bitop是一个复合操作， 它可以做多个Bitmaps的<code>and（交集） 、 or（并集） 、 not（非） 、 xor（异或）</code> 操作并将结果保存在destkey中。</p>\n<p>(2)实例<br>\n2020-11-04 日访问网站的userid=1,2,5,9。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setbit unique:users:20201104 1 1</span><br><span class=\"line\">setbit unique:users:20201104 2 1</span><br><span class=\"line\">setbit unique:users:20201104 5 1</span><br><span class=\"line\">setbit unique:users:20201104 9 1</span><br></pre></td></tr></table></figure>\n<p>2020-11-03 日访问网站的userid=0,1,4,9。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">setbit unique:users:20201103 0 1</span><br><span class=\"line\">setbit unique:users:20201103 1 1</span><br><span class=\"line\">setbit unique:users:20201103 4 1</span><br><span class=\"line\">setbit unique:users:20201103 9 1</span><br></pre></td></tr></table></figure>\n<p>计算出两天都访问过网站的用户数量</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bitop and unique:users:and:20201104_03</span><br><span class=\"line\"> unique:users:20201103unique:users:20201104</span><br></pre></td></tr></table></figure>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042315806.jpg\" alt=\"img\" style=\"zoom:33%;\">\n<p>计算出任意一天都访问过网站的用户数量（例如月活跃就是类似这种） ， 可以使用or求并集</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042315707.jpg\" alt=\"img\" style=\"zoom:33%;\">\n<h4 id=\"Bitmaps-与-set-对比\">Bitmaps 与 set 对比</h4>\n<p>假设网站有 1 亿用户， 每天独立访问的用户有 5 千万， 如果每天用集合类型和 Bitmaps 分别存储活跃用户可以得到表：</p>\n<p>​\t\t\t\t\t\t\t\t\t\t<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042315099.png\" alt=\"image-20230313162418827\" style=\"zoom:25%;\"><br>\n很明显， 这种情况下使用 Bitmaps 能节省很多的内存空间， 尤其是随着时间推移节省的内存还是非常可观的。</p>\n<p>​\t\t\t\t\t\t\t\t\t\t<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042315938.png\" alt=\"image-20230313162500728\" style=\"zoom:33%;\"></p>\n<p>但 Bitmaps 并不是万金油， 假如该网站每天的独立访问用户很少， 例如只有 10 万（大量的僵尸用户) ， 那么两者的对比如下表所示， 很显然， 这时候使用 Bitmaps 就不太合适了， 因为基本上大部分位都是 0。</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307042315338.png\" alt=\"image-20230313162539364\" style=\"zoom:33%;\">\n<h3 id=\"Geospatial-GEO\"><code>Geospatial(GEO)</code></h3>\n<p><code>GEO</code>，<code>Geographic</code>，<code>地理信息的缩写</code>。   类型是元素的 <code>2 维坐标</code>，在地图上就是经纬度。redis 基于该类型，提供了经纬度<code>设置，查询，范围查询，距离查询，经纬度 Hash </code>等常见操作。</p>\n<h4 id=\"命令-6\">命令</h4>\n<h5 id=\"geoadd\">geoadd</h5>\n<p>（1）格式<br>\n<code>geoadd&lt;key&gt;&lt; longitude&gt;&lt;latitude&gt;&lt;member&gt; [longitude latitude member...]</code> 添加地理位置（经度，纬度，名称）</p>\n<p>（2）实例\t\t\t\t<br>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307050009118.jpg\" alt=\"img\" style=\"zoom:33%;\"></p>\n<blockquote>\n<p>注意：</p>\n<p>两极无法直接添加，一般会下载城市数据，直接通过 Java 程序一次性导入。有效的经度从 -180 度到 180 度。有效的纬度从 -85.05112878 度到 85.05112878 度。当坐标位置超出指定范围时，该命令将会返回一个错误。已经添加的数据，是无法再次往里面添加的。</p>\n</blockquote>\n<h5 id=\"geopos\">geopos</h5>\n<p>（1）格式<br>\n<code>geopos  &lt;key&gt;&lt;member&gt; [member...]</code>获得指定地区的坐标值</p>\n<p>（2）实例</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202303131633010.jpg\" alt=\"img\" style=\"zoom:25%;\">\n<h6 id=\"geodist\">geodist</h6>\n<p>（1）格式<br>\n<code>geodist&lt;key&gt;&lt;member1&gt;&lt;member2&gt;  [m|km|ft|mi ]</code>  获取两个位置之间的直线距离</p>\n<p>（2）实例<br>\n获取两个位置之间的直线距离</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202303131633545.jpg\" alt=\"img\" style=\"zoom:33%;\">\n<p>单位：</p>\n<blockquote>\n<p>​\t\tm 表示单位为米[默认值]。</p>\n<p>​\t\tkm 表示单位为千米。</p>\n<p>​\t\tmi 表示单位为英里。</p>\n<p>​\t\tft 表示单位为英尺。</p>\n<p>如果用户没有显式地指定单位参数， 那么 <code>GEODIST</code> <code>默认</code>使用<code>米</code>作为单位</p>\n</blockquote>\n<h6 id=\"georadius\">georadius</h6>\n<p>（1）格式<br>\n<code>georadius&lt;key&gt;&lt; longitude&gt;&lt;latitude&gt;radius  m|km|ft|mi </code>  以给定的经纬度为中心，找出某一半径内的元素</p>\n<p>经度 纬度 距离 单位</p>\n<p>（2）实例</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202303131631535.jpg\" alt=\"img\" style=\"zoom:33%;\">\n<h3 id=\"Stream\"><code>Stream</code></h3>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307022236895.png\" alt></p>\n<ul>\n<li>流，可以使用<code>流</code>来<code>实时记录</code>和<code>同时聚合事件</code>,就是  <code>Redis</code> 版的<code>MQ消息中间件+阻塞队列</code> ,它支持消息的持久化、支持自动生成全局唯一ID、支持ack确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠。</li>\n</ul>\n<blockquote>\n<ul>\n<li>Message Content：消息内容</li>\n<li>Consumer group：消费组，通过<code>XGROUP CREATE </code>命令创建，同一个消费组可以有多个消费者</li>\n<li>Last_delivered_id：游标，每个消费组会有个游标<code> last_delivered_id</code>，任意一消费者读取了消息都会使</li>\n<li>游标 <code>last_delivered_id</code> 往前移动。</li>\n<li>Consumer：消费者，消费组中的消费者</li>\n<li>Pending_ids：消费者会有一个状态变量，用于记录被当前消费已读取但<code>未ack</code>的<code>消息Id</code>，如果客户端没有<code>ack</code>，这个变量里面的消息ID会越来越多，一旦某个消息被ack它就开始减少。这个<code>pending_ids</code>变量被官方称之为 <code>PEL(Pending Entries List)</code>，记录了当前已经被客户端读取的消息，但是还没有 ack (Acknowledge character：确认字符），它用来确保客户端至少消费了消息一次，而不会在网络传输的中途丢失了没处理</li>\n</ul>\n</blockquote>\n<h3 id=\"Bitfield\">Bitfield</h3>\n<ul>\n<li>将一个<code>redis</code>字符串看作是<strong>一个由二进制位组成的数组</strong> 并能对变长位宽和任意没有字节对齐的指定整型<code>位域进行寻址和修改</code></li>\n<li>主要作用 ： 它能够将很多<code>小的整数储存到一个长度较大的位图</code>中，又或者<code>将一个非常庞大的键分割为多个较小的键来进行储存</code>\n<ul>\n<li>位域修改</li>\n<li>溢出控制</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"持久化\">持久化</h2>\n<h3 id=\"RDB\">RDB</h3>\n<h4 id=\"font-color-red-定义-font\"><font color=\"red\">定义</font></h4>\n<ul>\n<li>将某一时刻的数据以快照&lt;全量快照——所有的数据&gt;的方式写到磁盘上，也就是在指定的时间间隔内将内存中的数据集写入磁盘。写的是二进制文件</li>\n<li>之后恢复的时候直接将硬盘中的快照文件读回内存即可</li>\n<li>默认情况下，redis 会将数据库快照保存在<code>dump.rdb</code> 的文件中，\n<ul>\n<li>随后 可以设置配置文件<code>自动保存</code>数据集，也可以<code>手动</code>&lt;<code>save   bgsave</code>&gt;的形式保存数据集</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"font-color-red-何时触发-font\"><font color=\"red\">何时触发</font></h4>\n<ul>\n<li>配置文件中默认的快照配置</li>\n<li>手动<code>save/bgsave</code>命令</li>\n<li>执行<code>flushdb/fulshall</code>命令也会产生dump.rdb文件，但是也会将命令记录到dump.rdb文件中，恢复后依旧是空，无意义</li>\n<li>执行<code>shutdown且没有</code>设置开启AOF持久化</li>\n<li>主从复制时，<code>主节点自动触发</code></li>\n</ul>\n<h4 id=\"font-color-red-优点-font\"><font color=\"red\">优点</font></h4>\n<ul>\n<li>适用于灾难恢复。  可以传输到远程数据中心或Amazon S3(可能已加密）的压缩文件</li>\n<li>提高了Redis 的性能。</li>\n<li>RDB在使用大数据集时仍能更快地重启。</li>\n<li>在副本上，RDB支持重启和故障转移后的部分重新同步。</li>\n<li>RDB文件非常适合备份。</li>\n<li>对数据完整性和一致性要求不高。</li>\n</ul>\n<h4 id=\"font-color-red-缺点-font\"><font color=\"red\">缺点</font></h4>\n<ul>\n<li>在一定间隔时间做一次备份，所以如果<code>redis</code>意外<code>down</code>掉的话，就会丢失从当前至最近一次快照期间的数据，<strong>快照之间的数据会丢失</strong></li>\n<li>内存数据的全量同步，如果数据量太大会导致<code>IO严重影响服务器性能</code></li>\n<li>RDB依赖于主进程的<code>fork</code>，在更大的数据集中，这可能会导致服务请求的瞬间延迟。fork的时候内存中的数据被克隆了一份，大致2倍的膨胀性，需要考虑，就是说   fork子进程、压缩、写出RDB文件都比较耗时</li>\n</ul>\n<h4 id=\"font-color-red-原理-font\"><font color=\"red\">原理</font></h4>\n<p>本质上是一种：<code>异步持久化</code> 的方式</p>\n<p><code>bgsave</code>开始时会<code>fork</code>主进程得到子进程，子进程共享主进程的内存数据。完成<code>fork</code>后读取内存数据并写入 <code>RDB</code> 文件。</p>\n<p><code>fork</code>采用的是<code>copy-on-write</code>技术：</p>\n<ul>\n<li>当主进程执行<code>读</code>操作时，访问<code>共享内存</code></li>\n<li>当主进程执行<code>写</code>操作时，则会<code>拷贝一份数据，执行写操作</code></li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307050048739.png\" alt=\"image-20230519161731774\" style=\"zoom:50%;\">\n<h5 id=\"RDB方式bgsave的基本流程？\">RDB方式bgsave的基本流程？</h5>\n<ul>\n<li>fork主进程得到一个子进程，共享内存空间</li>\n<li>子进程读取内存数据并写入新的RDB文件</li>\n<li>用新RDB文件替换 （是新的替换不是简单的修改）旧的RDB文件</li>\n</ul>\n<h5 id=\"RDB会在什么时候执行？\">RDB会在什么时候执行？</h5>\n<ul>\n<li>默认是<code>服务停止</code>时</li>\n</ul>\n<h5 id=\"配置文件中的save-60-1000代表什么含义？\">配置文件中的save 60 1000代表什么含义？</h5>\n<ul>\n<li>代表60秒内至少执行1000次修改则触发RDB</li>\n</ul>\n<h4 id=\"备份的执行流程\">备份的执行流程</h4>\n<p>Redis 会单独创建（fork）一个子进程来进行持久化，首先会将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何 IO 操作的，这就确保了极高的性能。</p>\n<p>如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比 AOF 方式更加的高效。</p>\n<p>RDB 的缺点是最后一次持久化后的数据可能丢失。</p>\n<h4 id=\"Fork\">Fork</h4>\n<ul>\n<li>\n<p>Fork 的<code>作用</code>是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程会作为原进程的子进程。</p>\n</li>\n<li>\n<p>在 Linux 程序中，fork () 会产生一个和父进程完全相同的子进程，但子进程在此后多会 exec 系统调用，出于效率考虑，Linux 中引入了 <code>写时复制技术</code>。</p>\n</li>\n<li>\n<p>一般情况 父进程和子进程会 共用同一段物理内存，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。</p>\n</li>\n</ul>\n<h4 id=\"RDB持久化流程图\">RDB持久化流程图</h4>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202303131730670.png\" alt=\"image-20230313173047534\" style=\"zoom:45%;\">\n<h3 id=\"AOF\">AOF</h3>\n<h4 id=\"font-color-red-定义-font-2\"><font color=\"red\">定义</font></h4>\n<ul>\n<li>\n<p><font color=\"red\">以日志的形式来记录每个写操作</font>，随后追加到文件缓冲区中，再根据配置文件将文件写到磁盘中</p>\n</li>\n<li>\n<p>之后redis重启的话就根据日志文件的内容将<code>写指令</code>  <code>从前到后执行一次</code>以完成数据的恢复工作</p>\n</li>\n<li>\n<p>默认情况下，redis是没有开启AOF的。开启AOF功能需要设置配置：<code>appendonly yes</code></p>\n</li>\n</ul>\n<h4 id=\"font-color-red-流程-font\"><font color=\"red\">流程</font></h4>\n<ol>\n<li>\n<p>Client作为命令的来源，会有多个源头以及源源不断的请求命令。</p>\n</li>\n<li>\n<p>在这些命令到达Redis Server 以后并不是直接写入AOF文件，会将这些命令先放入AOF缓存中进行保存。这里的AOF缓冲区存在的目的是当这些命令达到一定量以后再写入磁盘，避免频繁的磁盘IO操作。</p>\n</li>\n<li>\n<p>AOF缓冲会根据AOF缓冲区<strong>同步文件的三种写回策略</strong>将命令写入磁盘上的AOF文件。</p>\n</li>\n<li>\n<p>随着写入AOF内容的增加为避免文件膨胀，会根据规则进行命令的合并(<strong>又称AOF重写</strong>)，从而起到AOF文件压缩的目的。</p>\n</li>\n<li>\n<p>当Redis Server服务器重启的时候会对AOF文件载入数据。</p>\n</li>\n</ol>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202305251051356.png\" alt=\"image-20230525105157332\" style=\"zoom:53%;\">\n<h4 id=\"font-color-red-写回策略-3种同步频率-font\"><font color=\"red\">写回策略(3种同步频率)</font></h4>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\">配置项</th>\n<th style=\"text-align:center\">写回时机</th>\n<th style=\"text-align:center\">优点</th>\n<th style=\"text-align:center\">缺点</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><code>Always</code></td>\n<td style=\"text-align:center\">同步写回</td>\n<td style=\"text-align:center\">可靠性高，数据基本不丢失</td>\n<td style=\"text-align:center\">每个写命令都要同步记录，性能影响较大</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Everysec</code></td>\n<td style=\"text-align:center\">每秒写回</td>\n<td style=\"text-align:center\">性能适中</td>\n<td style=\"text-align:center\">宕机时丢失一秒内的数据</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>No</code></td>\n<td style=\"text-align:center\">操作系统控制的写回</td>\n<td style=\"text-align:center\">性能好</td>\n<td style=\"text-align:center\">宕机时丢失数据较多</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"font-color-red-变化-font\"><font color=\"red\">变化</font></h4>\n<ul>\n<li>\n<p>redis7之前 aof 文件有且只有一个</p>\n</li>\n<li>\n<p>redis7之后 aof文件变为了multi part</p>\n<ul>\n<li>\n<p><strong>BASE: 表示基础AOF</strong>，它一般由子进程通过重写产生，该文件<code>最多只有一个</code>。</p>\n</li>\n<li>\n<p><strong>INCR:表示增量AOF</strong>，它一般会在AOFRW开始执行时被创建，该文件<code>可能存在多个</code>。</p>\n</li>\n<li>\n<p><strong>HISTORY:表示历史AOF</strong>，它由<code>BASE</code>和<code>INCR</code>变化而来，每次<code>AOFRW</code>成功完成时，本次<code>AOFRW</code>之前对应的<code>BASE</code>和<code>INCR</code> 都将变为<code>HISTORY</code>，<code>HISTORY类型的AOF会被Redis自动删除</code>。</p>\n</li>\n</ul>\n</li>\n</ul>\n<p>为了管理这些AOF文件，我们引入了一个<code>manifest (清单)</code>文件来跟踪、管理这些AOF。</p>\n<h4 id=\"font-color-red-优点-font-2\"><font color=\"red\">优点</font></h4>\n<ul>\n<li>\n<p>使用AOF 持久化会使 Redis 更加持久。</p>\n</li>\n<li>\n<p>AOF 日志是一个仅附加日志，因此<code>不会出现寻道问题</code>，也<code>不会在断电时出现损坏问题</code>。</p>\n</li>\n<li>\n<p>当AOF 变得太大时，Redis 能够在<code>后台自动重写AOF</code>。</p>\n<ul>\n<li>重写是安全的，因为当 Redis继续附加到旧文件时，会使用创建当前数据集所需的最少操作集生成一个全新的文件，一旦第二个文件准备就绪，Redis 就会切换两者并开始附加到新的那一个。</li>\n</ul>\n</li>\n<li>\n<p>AOF<code>以易于理解和解析的格式</code>依次包含所有操作的日志。可以轻松导出AOF文件。</p>\n</li>\n</ul>\n<h4 id=\"font-color-red-缺点-font-2\"><font color=\"red\">缺点</font></h4>\n<ul>\n<li><code>相同数据集</code>的数据而言<code>AOF文件要远大于</code>RDB文件，<code>恢复速度</code> <code>慢</code>于RDB</li>\n<li>AOF运行效率要<code>慢于RDB</code>，每秒<code>同步策略效率较好</code>，<code>不同步效率和RDB相同</code></li>\n</ul>\n<h4 id=\"font-color-red-重写机制-font\"><font color=\"red\">重写机制</font></h4>\n<ul>\n<li>当AOF文件的大小超过所设定的峰值时，Redis就会**<code>自动</code>**启动AOF文件的<code>内容压缩</code>。只保留可以恢复数据的最小指令集。</li>\n</ul>\n<h5 id=\"何时触发：\">何时触发：</h5>\n<ul>\n<li>自动触发\n<ul>\n<li>满足配置文件中的选项后，Redis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的一倍且文件大于64M时</li>\n</ul>\n</li>\n<li><strong>手动触发</strong>\n<ul>\n<li>客户端向服务器发送<code>bgrewriteaof</code>命令</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>AOF文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的AOF文件</p>\n</blockquote>\n<h5 id=\"原理：\">原理：</h5>\n<ol>\n<li>在重写开始前，redis会创建一个“重写子进程”，这个子进程会读取现有的AOF文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。</li>\n<li>与此同时，主进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的AOF文件中（这样做是保证原有的AOF文件的可用性，避免在重写过程中出现意外。）</li>\n<li>当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新AOF文件中</li>\n<li>当追加结束后，redis就会用新AOF文件来代替旧AOF文件，之后再有新的写指令，就都会追加到新的AOF文件中</li>\n<li>重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似</li>\n</ol>\n<h5 id=\"重写流程\">重写流程</h5>\n<ul>\n<li>\n<p>bgrewriteaof 触发重写，判断是否当前有 bgsave 或 bgrewriteaof 在运行，如果有，则等待该命令结束后再继续执行；</p>\n</li>\n<li>\n<p>主进程 fork 出子进程执行重写操作，保证主进程不会阻塞；</p>\n</li>\n<li>\n<p>子进程遍历 redis 内存中数据到临时文件，客户端的写请求同时写入 aof_buf 缓冲区和 aof_rewrite_buf 重写缓冲区，保证原 AOF 文件完整以及新 AOF 文件生成期间的新的数据修改动作不会丢失；</p>\n</li>\n<li>\n<p>子进程写完新的 AOF 文件后，向主进程发信号，父进程更新统计信息。主进程把 aof_rewrite_buf 中的数据写入到新的 AOF 文件；</p>\n</li>\n<li>\n<p>使用新的 AOF 文件覆盖旧的 AOF 文件，完成 AOF 重写。</p>\n</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202303131819158.png\" alt=\"image-20230313181918100\" style=\"zoom:43%;\">\n<h4 id=\"持久化流程\">持久化流程</h4>\n<p>（1）客户端的请求写命令会被<code>append</code>追加到<code>AOF缓冲区</code>内；</p>\n<p>（2）AOF缓冲区根据AOF持久化策略[always,everysec,no]将操作<code>sync同步</code>到磁盘的AOF文件中；</p>\n<p>（3）AOF文件大小超过重写策略或手动重写时，会对AOF文件<code>rewrite</code>重写，压缩AOF文件容量；</p>\n<p>（4）Redis服务<code>重启</code>时，会<code>重新load加载</code>AOF文件中的写操作达到数据恢复的目的；</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202303131820297.png\" style=\"zoom:33%;\">\n<h3 id=\"混合模式持久化\">混合模式持久化</h3>\n<p>两者在同时开启，也就是混合模式下，重启只会加载 <code>aof</code> 文件</p>\n<h4 id=\"span-style-color-red-同时开启两种持久化方式-span\"><span style=\"color:red\">同时开启两种持久化方式</span></h4>\n<ul>\n<li>当redis重启的时候会<code>优先载入AOF文件</code>来恢复原始的数据，因为在通常情况下<code>AOF文件保存的数据集</code>要比RDB文件保存的数据集<code>要完整</code>。</li>\n<li>RDB的数据不是实时的，同时使用两者时服务器重启也只会找AOF文件。 redis  的 作者也不建议只使用AOF方式备份，因为<code>RDB更适合用于备份数据库</code>（AOF在不断的变化不好备份），留着RDB是为了作为一个以防万一的手段。</li>\n</ul>\n<blockquote>\n<p>推荐使用<code>两者混合使用</code></p>\n<ul>\n<li>\n<p>RDB镜像做<code>全量持久化</code>，AOF做<code>增量持久化</code></p>\n</li>\n<li>\n<p>建议<code>先</code>使用RDB进行快照存储，<code>然后</code>使用AOF持久化记录所有的写操作，当重写策略满足或手动触发重写的时候，将最新的数据存储为新的RDB记录。</p>\n</li>\n<li>\n<p>这样的话，重启服务的时候会从RDB和AOF两部分恢复数据，既保证了数据完整性，又提高了恢复数据的性能。</p>\n</li>\n<li>\n<p>简单来说:混合持久化方式产生的文件一部分是RDB格式，一部分是AOF格式。====&gt;    AOF包括了RDB头部+AOF混写</p>\n</li>\n</ul>\n</blockquote>\n<h3 id=\"纯缓存模式\">纯缓存模式</h3>\n<p><code>同时关闭</code>RDB+AOF，只用缓存</p>\n<h2 id=\"事务\">事务</h2>\n<p>本质是一组命令的集合，一个事务中的所有命令都会序列化，<code>按顺序地串行化执行而不会被其他命令插入，不许加塞</code></p>\n<h3 id=\"作用\">作用</h3>\n<p><code>串联多个命令</code>防止<code>别的命令</code>插队</p>\n<h3 id=\"font-color-red-特点-font\"><font color=\"red\">特点</font></h3>\n<table>\n<thead>\n<tr>\n<th>单独的隔离操作</th>\n<th>Redis的事务仅仅是保证事务里的操作会被连续独占的执行，redis命令执行是单线程架构，在执行完事务内所有指令前是不可能再去同时执行其他客户端的请求的</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>没有隔离级别的概念</td>\n<td>因为事务提交前任何指令都不会被实际执行，也就不存在”事务内的查询要看到事务里的更新，在事务外查询不能看到”这种问题了</td>\n</tr>\n<tr>\n<td>不保证原子性</td>\n<td>Redis的事务不保证原子性，也就是不保证所有指令同时成功或同时失败，只有决定是否开始执行全部指令的能力，没有执行到一半进行回滚的能力</td>\n</tr>\n<tr>\n<td>排它性</td>\n<td>Redis会保证一个事务内的命令依次执行，而不会被其它命令插入</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"font-color-red-流程-font-2\"><font color=\"red\">流程</font></h3>\n<p>（1）开启：以<code>MULTI</code>命令开启一个事务</p>\n<p>（2）入队：将多个命令加入到事务队列中，接到这些命令并<code>不会立即执行</code>。</p>\n<p>（3）执行：由<code>EXEC</code>命令执行事务队列中的命令。</p>\n<p>Redis 事务中有<code> Multi</code>、<code>Exec</code> 和 <code>discard</code> 三个指令，在 Redis 中，从输入 <code>Multi</code> 命令<code>开始</code>，输入的命令都会依次进入命令队列中，但不会执行，直到输入 <code>Exec</code> 后，Redis 会将之前的命令队列中的命令依次执行。而组队的过程中可以通过 <code>discard</code> 来<code>放弃组队</code>。</p>\n<p>​\t\t\t\t\t\t\t\t\t\t\t\t\t<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307050018228.jpg\" alt=\"img\" style=\"zoom: 23%;\"></p>\n<h3 id=\"事务错误的处理\">事务错误的处理</h3>\n<p>如果 <code>组队阶段时 某个命令</code>出现了报告错误，执行时整个的所有队列都会被取消。</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202303131657080.png\" alt=\"image-20230313165655298\" style=\"zoom:33%;\">\n<p>如果<code>执行阶段时 某个命令</code>报出了错误，则只有报错的命令不会被执行，而其他的命令都会执行，不会回滚。</p>\n<h3 id=\"事务冲突的解决\">事务冲突的解决</h3>\n<h4 id=\"悲观锁\">悲观锁</h4>\n<p>每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会 block 直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。</p>\n<h4 id=\"乐观锁\">乐观锁</h4>\n<p>每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以<code>提高吞吐量</code>。</p>\n<p>Redis 就是利用这种 <code>check-and-set</code> 机制实现事务的。</p>\n<h4 id=\"WATCH-key-key-…\">WATCH key [key …]</h4>\n<p>在执行 <code>multi</code> 之前，先执行 <code>watch key1 [key2]</code>，可以监视一个 (或多个) <code>key</code> ，如果在事务执行之前这个 (或这些) key 被其他命令所改动，那么事务将被打断。</p>\n<h4 id=\"unwatch\">unwatch</h4>\n<p>取消 <code>WATCH</code> 命令对所有 <code>key</code> 的监视。如果在执行 <code>WATCH</code> 命令之后，<code>EXEC</code> 命令或 <code>DISCARD</code> 命令先被执行了的话，那么就不需要再执行 <code>UNWATCH</code> 了。</p>\n<h2 id=\"管道-pipeline\">管道(pipeline)</h2>\n<ul>\n<li>\n<p>是什么： 客户端和redis服务器之间的进行建立连接的一种<code>双向通道</code>,它可以让客户端<code>在一次请求</code>中<code>发送多个命令</code>并<code>一次性</code>接收<code>多个命令的响应结果</code></p>\n</li>\n<li>\n<p>目的: 可以让客户端减少网络通信的次数，从而<code>提高</code> Redis 的<code>吞吐量和性能</code></p>\n</li>\n<li>\n<p>总结：</p>\n<ul>\n<li>Pipeline与原生批量命令(<code>mset</code>)对比：\n<ul>\n<li>原生批量命令（例如mset、mget）具有<code>原子性</code>，pipeline是<code>非原子性</code>。</li>\n<li>原生批量命令一次<code>只能执行一种命令</code>，pipeline<code>支持批量执行不同命令</code>。</li>\n<li>原生批命令是<code>redis服务端</code>实现，而pipeline需要<code>redis服务端和客户端</code>共同完成。</li>\n</ul>\n</li>\n<li>Pipeline与<code>事务</code>对比：\n<ul>\n<li>事务具有原子性，pipeline不具有原子性。</li>\n<li>pipeline<code>一次性</code>将命令发送给服务器，事务是<code>一条一条</code>的发，事务只有在接收到EXEC命令后才会执行。</li>\n<li>执行事务时会阻塞其他命令的执行，而执行管道中的命令不会。</li>\n</ul>\n</li>\n<li>使用Pipeline注意事项：\n<ul>\n<li>pipeline缓冲的指令只会<code>依次执行，不保证原子性</code>，如果执行中指令发生异常，还会继续执行后续的指令。</li>\n<li>使用pipeline传输的命令也不能太多，如果数据量大客户端的阻塞时间可能会过久，同时服务端此时也被迫回复一个队列答复，占用很多内存。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"发布订阅\">发布订阅</h2>\n<ul>\n<li>\n<p>发布和订阅（Publish/Subscribe，简称 Pub/Sub）是一种消息传递模式；</p>\n</li>\n<li>\n<p>发布者（Publisher）可以将消息发送到一个或多个频道（Channel），订阅者（Subscriber）可以订阅一个或多个频道，以接收发布者发送的消息。当发布者在某个频道上发布一条消息时，所有订阅该频道的订阅者都会收到这条消息。</p>\n</li>\n<li>\n<p><code>Redis Pub/Sub</code> 是基于消息传递的<code>异步通信模型</code>，可以用于构建实时系统、聊天室、实时广播等应用场景。</p>\n</li>\n</ul>\n<p>==注意==</p>\n<ul>\n<li><code>发布的消息</code>在Redis系统<code>不能持久化</code>，因此必须<code>先执行订阅</code>，再<code>等待消息发布</code>，如果先发布了消息且该消息<code>没有订阅者接收</code>，那么该消息被<code>直接丢弃</code>。</li>\n<li>消息只管发送，对于发布者而言消息是<code>即发即失</code>的，也<code>没有ACK机制</code>，无法保证消息是否消费成功。</li>\n<li>Redis5.0新增了<code>Stream数据结构，不但支持多播，还支持数据持久化，比Pub/Sub更加强大</code>。</li>\n</ul>\n<h2 id=\"BigKey\">BigKey</h2>\n<blockquote>\n<details>\n <summary>使用 <font color=\"red\">scan</font> 而不是 <font color=\"red\">keys *</font></summary>\n <pre>1.生产环境中使用 ： <font color=\"red\">keys * </font>这个指令有致命的弊端，在实际环境中最好不要使用；一般使用的是<font color=\"red\">Scan</font></pre>\n<pre>2.SCAN命令是一个基于<font color=\"red\">游标</font>的迭代器，每次被调用之后，都会向用户<font color=\"red\">返回一个新的游标</font>，<font color=\"red\">用户在下次迭代时需要使用这个新游标作为SCAN命令的游标参数</font>，以此来延续之前的迭代过程。</pre>\n     <pre>3.命令<font color=\"red\">SCAN cursor [MATCH pattern] [COUNT count]</font></pre>\n     <pre>3.1 cursor - 游标。</pre>\n     <pre>3.2 pattern - 匹配的模式。</pre>\n     <pre>3.3 count - 指定从数据集里返回多少元素，默认值为 10 。</pre>\n<pre><font color=\"red\" size=\"4\">4.SCAN的遍历顺序</font></pre>\n<pre><font color=\"red\">非常特别，它不是从第一维数组的第零位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏。</font></pre>\n<pre>5.返回值</pre>\n<pre>5.1 SCAN返回一个包含<font color=\"blue\">两个元素的数组</font></pre>\n<pre>5.2 第一个元素是用于进行下一次迭代的新游标，</pre>\n<pre>5.3 第二个元素则是一个数组，这个数组中包含了所有被迭代的元素。<font color=\"red\">如果新游标返回零表示迭代已结束。</font></pre></details>\n</blockquote>\n<h3 id=\"多大算BigKey\">多大算BigKey</h3>\n<ul>\n<li>\n<p>通常我们说的BigKey，不是在值的Key很大，而是指的Key对应的value很大</p>\n</li>\n<li>\n<p>list、hash、set和zset，value的实际上个数超过5000就是bigkey</p>\n</li>\n<li>\n<p>string是value，理论上最大是512MB，但是  实际上 ≥10KB就是bigkey</p>\n</li>\n<li>\n<p>非字符串的bigkey,不要使用del删除，使用<code>hscan、sscan、zscan</code>方式<code>渐进式删除</code>，同时要注意防止<code>bigkeyi过期时间自动删除问题</code></p>\n</li>\n</ul>\n<h3 id=\"危害\">危害</h3>\n<ul>\n<li>内存不均，集群迁移困难</li>\n<li>超时删除，大key删除作梗  ：对元素较多的hash、list、zset等做运算会耗时较旧，使主线程被阻塞</li>\n<li>网络流量阻塞 ：对BigKey执行读请求时，少量的QPS就可能导致带宽使用率被占满，导致Redis实例，乃至所在物理机变慢</li>\n<li>数据倾斜 ：   BigKey所在的Redis实例内存使用率远超其他实例，无法使数据分片的内存资源达到均衡</li>\n</ul>\n<h3 id=\"如何发现\">如何发现</h3>\n<ul>\n<li><font color=\"red\">–bigkeys参数 + （查询大于10kb的所有key）memory usage  [给出一个 <code>key</code> 和它的值在 内存 中所占用的字节数。] </font></li>\n</ul>\n<h3 id=\"如何删除\">如何删除</h3>\n<ul>\n<li>\n<p>String   一般用del，如果<code>过于庞大</code>使用<code>unlink key </code>删除</p>\n</li>\n<li>\n<p>hash    使用<code>hscan</code>每次获取少量<code>field-value</code>，再使用<code>hdel</code>删除每个<code>field</code></p>\n</li>\n<li>\n<p>list       使用<code>ltrim</code>渐进式逐步删除   [让列表只保留指定区间内的元素，不在指定区间之内的元素都将被除。]</p>\n</li>\n<li>\n<p>set      使用<code>sscan</code>每次获取部分元素，在使用<code>srem</code>命令删除每个元素</p>\n</li>\n<li>\n<p>zset     使用<code>zscan</code>每次获取部分元素，在使用<code>zremrangebyrank</code>命令删除每个元素</p>\n</li>\n</ul>\n<h3 id=\"生产调优-—-”惰性释放“\">生产调优   — ”惰性释放“</h3>\n<p>redis有两种删除的方式</p>\n<ul>\n<li><code> del</code>    阻塞型删除</li>\n</ul>\n<blockquote>\n<p>即 服务器停止处理新命令，以便以同步方式回收与对象关联的所有内存。</p>\n<ul>\n<li>\n<p>如果删除的键与一个小对象相关联，则执行DEL命令所需的时间非常短  ，Redis中的O(1)或O(Iog_N)命令。</p>\n</li>\n<li>\n<p>但是，如果键与包含数百万个元素的聚合值相关联，则服务器可能会阻塞很长时间（甚至几秒钟）才能完成操作。</p>\n</li>\n</ul>\n</blockquote>\n<ul>\n<li><code>unlink </code> 非阻塞型删除</li>\n</ul>\n<blockquote>\n<p>基于上述原因，Redis还提供了非阻塞删除原语，例如<code>UNLINK</code>(非阻塞DEL)以及<code>FLUSHALL</code>和<code>FLUSHDB</code>命令的<code>ASYNC</code>选项，以便在后台回收内存。这些命令在恒定时间内执行。另一个线程将尽可能快地逐步释放后台中的对象。<code>FLUSHALL</code>和<code>FLUSHDB</code>的<code>DEL</code>、<code>UNLINK</code>和<code>ASYNC</code>选项是用户控<br>\n制的。</p>\n</blockquote>\n<h3 id=\"优化配置\">优化配置</h3>\n<blockquote>\n<p><code>lazyfree-lazy-server-del        yes</code></p>\n<p><code>replica-lazy-flush              yes</code></p>\n<p><code>lazyfree-lazy-user-del          yes</code></p>\n</blockquote>\n<h2 id=\"布隆过滤器\">布隆过滤器</h2>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202305262258692.png\" alt=\"image-20230526225827642\" style=\"zoom:43%;\">\n<h3 id=\"font-color-red-是什么-font\"><font color=\"red\">是什么</font></h3>\n<ul>\n<li>由<code>一个初值都为零的bit数组</code>和<code>多个哈希函数构成</code>，用来快速判断集合中是否存在某个元素  <code>&lt;bit数组+hash函数&gt;</code></li>\n</ul>\n<h3 id=\"font-color-red-目的-font\"><font color=\"red\">目的</font></h3>\n<ul>\n<li>可以减少内存占用；因为他 <code>不保存数据信息</code>，只是在内存中做一个是否存在的标记flag</li>\n</ul>\n<h3 id=\"font-color-red-特点-font-2\"><font color=\"red\">特点</font></h3>\n<ul>\n<li>可以<code>高效地插入和查询</code>，占用空间少，返回的结果是不确定的</li>\n<li>一个元素的判断结果：判断结果为<code>存在</code>时，元素<code>不一定存在</code>，但是判断结果为<code>不存在</code>时，则<code>一定不存在</code></li>\n<li>布隆过滤器可以添加元素，但是<font color=\"red\">不能删除元素，</font>由于涉及<code>hashcode</code>判断依据，删除元素会导致误判率增加。</li>\n</ul>\n<h3 id=\"font-color-red-原理-font-2\"><font color=\"red\">原理</font></h3>\n<ul>\n<li>实质就是<font color=\"red\">一个大型位数组和几个不同的无偏hash函数</font>(无偏表示分布均匀)。由一个初值都为零的bit数组和多个哈希函数构成，用来快速判断某个数据是否存在。</li>\n<li>但是跟 HyperLogLog 一样，它也一样有那么一点不精确，也存在一定的误判概率</li>\n</ul>\n<h3 id=\"font-color-red-数据结构-font\"><font color=\"red\">数据结构</font></h3>\n<ul>\n<li>\n<p><font color=\"blue\">添加key时</font><br>\n使用<code>多个</code>hash函数对<code>key</code>进行<code>hash</code>运算得到一个整数索引值，对<code>位数组</code>长度进行<code>取模</code>运算得到一个位置，每个<code>hash函数</code>都会得到一个不同的位置，将这<code>几个位置</code>都置<code>1</code>就完成了<code>add</code>操作。</p>\n</li>\n<li>\n<p><font color=\"blue\">查询key时</font><br>\n只要有其中一位是零就表示这个key不存在，但如果都是1，则不一定存在对应的值</p>\n</li>\n</ul>\n<h3 id=\"数据不精准的原因分析\">数据不精准的原因分析</h3>\n<ul>\n<li>直接原因就在于 <code>哈希函数</code>会导致<code>哈希冲突</code></li>\n<li>当有变量被加入集合时，通过<code>N个映射函数</code>将这个变量映射成位图中的<code>N个点</code>,把它们都要置为 1，当查询某个变量的时候我们只要看看这些点是不是都是 <code>1</code>，就可以大概率知道集合中有没有它了；如果这些点，<font color=\"red\">有任何一个为零则被查询变量一定不在;</font>如果都是 1，则被查询变量很<font color=\"red\">可能存在</font>，<br>\n<font color=\"red\">为什么说是可能存在，而不是一定存在呢?那是因为<code>映射函数本身就是散列函数</code>，<code>散列函数是会有碰撞的</code>。</font></li>\n</ul>\n<blockquote>\n<p>正是基于布隆过滤器的<code>快速检测特性</code>，我们可以在把数据写入数据库时，使用布隆过滤器做个标记。</p>\n<p>当缓布缺失后，应用查询数据库时，可以通过查询布隆过滤器快速判断数据是否存在。</p>\n<p>如果不存在，就不用再去据库中查询了。</p>\n<p>这样一来，即使发生缓存穿透了，大量请求只会查询Redis和布隆过滤器，而不会积压到数据库，也就不会影响数据库的正常运行。</p>\n<p>布隆过滤器可以使用Redis实现，本身就能承担较大的并发访问压力</p>\n</blockquote>\n<h3 id=\"font-color-red-如何使用-font\"><font color=\"red\">如何使用</font></h3>\n<ul>\n<li>初始化bitmap       所有的值均设置为0</li>\n<li>添加数据                为了尽量使得地址不冲突，<font color=\"red\">会使用多个 hash 函数对 key 进行运算</font>，算得一个下标索引值，然后对位数组长度进行<font color=\"red\">取模运算</font>得到一个位置，每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为 1 就完成了 add 操作。</li>\n<li>判断是否存在         先把这个 key 通过相同的<font color=\"red\">多个 hash 函数进行运算</font>，查看对应的位置是否都为 1，<font color=\"red\">只要有一个位为零，那么说明布隆过滤器中这个 key 不存在；</font><font color=\"red\">如果这几个位置全都是 1，那么说明极有可能存在；</font></li>\n</ul>\n<h3 id=\"font-color-red-即使误判也不要删除-font\"><font color=\"red\">即使误判也不要删除</font></h3>\n<ul>\n<li>误判的根源在于相同的 bit 位被多次映射且置 1</li>\n<li>布隆过滤器的每一个 bit 并不是独占的，很有可能多个元素共享了某一位。如果我们直接删除这一位的话，会影响其他的元素</li>\n<li>删掉元素会导致误判率增加。</li>\n</ul>\n<h3 id=\"font-color-red-建议-font\"><font color=\"red\">建议</font></h3>\n<ul>\n<li>使用时最好不要让实际元素数量远大于初始化数量，最好避免扩容</li>\n<li>当实际元素数量超过初始化数量时，应该对布隆过滤器进行重建，重新分配一个size 更大的过滤器，再将所有的历史元素批量add到新分配的布隆过滤器中</li>\n</ul>\n<h3 id=\"font-color-red-使用场景-font\"><font color=\"red\"> 使用场景</font></h3>\n<ol>\n<li>\n<p><font color=\"red\"> 解决缓存穿透的问题，和redis结合bitmap使用</font></p>\n<ul>\n<li>\n<p>思路</p>\n<ul>\n<li>\n<p>把已存在数据的key存在布隆过滤器中，相当于redis前面挡着一个布隆过滤器。当有新的请求时，先到布隆过滤器中查询是否存在:</p>\n<p>如果布隆过滤器中<code>不存在</code>该条数据则直接返回;如果布隆过滤器中<code>已存在</code>，才去查询缓存redis，如果redis里没查询到则再查询Mysql数据库</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><font color=\"red\"> 黑名单校验，识别垃圾邮件</font></p>\n<ul>\n<li>思路\n<ul>\n<li>发现存在黑名单中的，就执行特定操作。比如:识别垃圾邮件，只要是邮箱在黑名单中的邮件，就识别为垃圾邮件。把所有黑名单都放在布隆过滤器中，在收到邮件时，判断邮件地址是否在布隆过滤器中即可。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"font-color-red-优点：-font\"><font color=\"red\">优点：</font></h3>\n<ul>\n<li>高效地插入和查询，内存中占用bit空间小</li>\n</ul>\n<h3 id=\"font-color-red-缺点：-font\"><font color=\"red\">缺点：</font></h3>\n<ul>\n<li><code>不能删除</code>元素[<code>布谷鸟过滤器</code>可以删除]，因为删除元素会导致误判率增加，因为hash冲突同一个位置可能存的东西是多个共有的</li>\n<li>存在误差，<code>不能精准过滤</code></li>\n</ul>\n<h2 id=\"IO多路复用\">IO多路复用</h2>\n<ul>\n<li>让一个线程检查多个文件描述符的就绪状态，可以使用<code> select  poll  epoll</code> 函数进行传入文件描述符，<code>只要有一个</code>文件描述符就绪就返回，否则就会阻塞直到超时。得到<code>就绪状态</code>之后就进行<code>真正的操作</code>，可以在一个线程里面执行也可以重新启动一个线程再执行(比如线程池)</li>\n</ul>\n<h2 id=\"Redis消息队列\">Redis消息队列</h2>\n<h3 id=\"消息队列\">消息队列</h3>\n<p>最简单的消息队列模型包括3个角色：</p>\n<ul>\n<li>消息队列：存储和管理消息，也被称为消息代理（Message Broker）</li>\n<li>生产者：发送消息到消息队列</li>\n<li>消费者：从消息队列获取消息并处理消息</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070213111.png\" alt=\"image-20230707021330053\" style=\"zoom:33%;\">\n<h3 id=\"基于List实现消息队列\">基于List实现消息队列</h3>\n<h4 id=\"基于List结构模拟消息队列\"><strong>基于List结构模拟消息队列</strong></h4>\n<p>而Redis的<code>list</code>数据结构是一个<code>双向链表</code>，很容易模拟出队列效果。</p>\n<p>队列是<code>入口和出口</code>不在一边，因此我们可以利用：<code>LPUSH 结合 RPOP、或者 RPUSH 结合 LPOP</code>来实现。<br>\n不过要注意的是，当队列中没有消息时<code>RPOP或LPOP</code>操作会<code>返回null</code>，并不像<code>JVM</code>的<code>阻塞队列</code>那样会<code>阻塞并等待</code>消息。因此这里应该使用<code>BRPOP</code>或者<code>BLPOP</code>来实现阻塞效果</p>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070216626.png\" alt></p>\n<h4 id=\"优点：\">优点：</h4>\n<ul>\n<li>利用Redis存储，不受限于JVM内存上限</li>\n<li>基于Redis的持久化机制，数据安全性有保证</li>\n<li>可以满足消息有序性</li>\n</ul>\n<h4 id=\"缺点：\">缺点：</h4>\n<ul>\n<li>无法避免消息丢失</li>\n<li>只支持单消费者</li>\n</ul>\n<h3 id=\"基于PubSub的消息队列\">基于PubSub的消息队列</h3>\n<p>顾名思义，消费者可以订阅一个或多个channel，生产者向对应channel发送消息后，所有<code>订阅者</code>都能收到相关消息。</p>\n<ul>\n<li><code> SUBSCRIBE channel [channel]</code> ：订阅一个或多个频道</li>\n<li><code>PUBLISH channel msg</code>：向一个频道发送消息</li>\n<li><code>PSUBSCRIBE pattern[pattern]</code>：订阅与pattern格式匹配的所有频道</li>\n</ul>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070217036.png\" alt></p>\n<p>优点：</p>\n<ul>\n<li>采用发布订阅模型，支持多生产、多消费</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>不支持数据持久化</li>\n<li>无法避免消息丢失</li>\n<li>消息堆积有上限，超出时数据丢失</li>\n</ul>\n<h3 id=\"基于Stream的消息队列\">基于Stream的消息队列</h3>\n<p>Stream 是 Redis 5.0 引入的一种新数据类型，可以实现一个功能非常完善的消息队列。</p>\n<h4 id=\"发送消息的命令：\">发送消息的命令：</h4>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070218442.png\" alt></p>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070219952.png\" alt></p>\n<h4 id=\"读取消息的方式之一：XREAD\">读取消息的方式之一：XREAD</h4>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070219729.png\" alt></p>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070219308.png\" alt></p>\n<h4 id=\"XREAD阻塞方式，读取最新的消息：\">XREAD阻塞方式，读取最新的消息：</h4>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070220560.png\" alt></p>\n<p>在业务开发中，我们可以循环的调用XREAD阻塞方式来查询最新消息，从而实现持续监听队列的效果</p>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070220734.png\" alt></p>\n<p>注意：当我们指定起始<code>ID为$</code>时，代表读取最新的消息，如果我们处理一条消息的过程中，又有超过1条以上的消息到达队列，则下次获取时也只能获取到最新的一条，会出现<code>漏读消息</code>的问题</p>\n<p><code>STREAM</code>类型消息队列的<code>XREAD</code>命令特点：</p>\n<ul>\n<li>消息<code>可回溯</code></li>\n<li>一个消息可以被<code>多个消费者读取</code></li>\n<li>可以阻塞读取</li>\n<li>有消息漏读的风险</li>\n</ul>\n<h3 id=\"基于Stream的消息队列-消费者组\">基于Stream的消息队列-消费者组</h3>\n<p>消费者组（Consumer Group）：将多个消费者划分到一个组中，监听同一个队列。具备下列特点：</p>\n<p><img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070222919.png\" alt></p>\n<h4 id=\"创建消费者组：\">创建消费者组：</h4>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">XGROUP CREATE key groupName ID [MKSTREAM]</span><br></pre></td></tr></table></figure>\n<ul>\n<li><code>key</code>：队列名称</li>\n<li><code>groupName</code>：消费者组名称</li>\n<li><code>ID</code>：起始ID标示，$代表队列中最后一个消息，0则代表队列中第一个消息</li>\n<li><code>MKSTREAM</code>：队列不存在时自动创建队列</li>\n</ul>\n<h4 id=\"其它常见命令：\">其它常见命令：</h4>\n<p><strong>删除指定的消费者组</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">XGROUP DESTORY key groupName</span><br></pre></td></tr></table></figure>\n<p><strong>给指定的消费者组添加消费者</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">XGROUP CREATECONSUMER key groupname consumername</span><br></pre></td></tr></table></figure>\n<p><strong>删除消费者组中的指定消费者</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">XGROUP DELCONSUMER key groupname consumername</span><br></pre></td></tr></table></figure>\n<p><strong>从消费者组读取消息：</strong></p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS key [key ...] ID [ID ...]</span><br></pre></td></tr></table></figure>\n<ul>\n<li>group：消费组名称</li>\n<li>consumer：消费者名称，如果消费者不存在，会自动创建一个消费者</li>\n<li>count：本次查询的最大数量</li>\n<li>BLOCK milliseconds：当没有消息时最长等待时间</li>\n<li>NOACK：无需手动ACK，获取到消息后自动确认</li>\n<li>STREAMS key：指定队列名称</li>\n<li>ID：获取消息的起始ID：\n<ul>\n<li>“&gt;”：从下一个未消费的消息开始</li>\n<li>其它：根据指定id从<code>pending-list</code>中获取已消费但未确认的消息，例如0，是从<code>pending-list</code>中的第一个消息开始</li>\n</ul>\n</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070224197.png\" alt=\"image-20230707022448134\" style=\"zoom:40%;\">\n<h4 id=\"STREAM类型消息队列的XREADGROUP命令特点：\">STREAM类型消息队列的XREADGROUP命令特点：</h4>\n<ul>\n<li>消息可回溯</li>\n<li>可以多消费者争抢消息，加快消费速度</li>\n<li>可以阻塞读取</li>\n<li>没有消息漏读的风险</li>\n<li>有消息确认机制，保证消息至少被消费一次</li>\n</ul>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202307070225351.png\" alt=\"image-20230707022550289\" style=\"zoom:47%;\">","_path":"post/691706ae.html","_link":"http://rycan.top/post/691706ae.html","_id":"clkuj5exv004lsg0p8y8ze9q2"}}