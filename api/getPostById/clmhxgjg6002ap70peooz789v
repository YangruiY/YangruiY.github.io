{"type":"getPostById","data":{"title":"ShardingSphere","date":"2023-09-13T15:49:40.000Z","description":"面试精选","categories":[{"name":"FaceToFace","_id":"clmhxgjfz000tp70pg45khpkv"}],"tags":[{"name":"ShardingSphere","_id":"clmhxgjgc004fp70p9ngo0j9j"}],"content":"<meta name=\"referrer\" content=\"no-referrer\">\n<hr>\n<h2 id=\"雪花算法\">雪花算法</h2>\n<blockquote>\n<p>背景：需要选择合适的方案去应对数据规模的增长，以应对逐渐增长的访问压力和数据量。数据库的扩展方式主要包括：<code>业务分库、主从复制、数据库分表</code>。</p>\n</blockquote>\n<h3 id=\"数据库分表\">数据库分表</h3>\n<p>对单表数据进行拆分&lt; 单表数据拆分有两种方式：垂直分表和水平分表 &gt;</p>\n<h4 id=\"垂直拆分：\">垂直拆分：</h4>\n<p>垂直分表适合将表中某些不常用且占了大量空间的列拆分出去。</p>\n<h4 id=\"水平分表\">水平分表</h4>\n<p>水平分表适合表行数特别大的表</p>\n<h3 id=\"全局唯一的数据id该如何处理\">全局唯一的数据id该如何处理</h3>\n<h4 id=\"1、主键自增\">1、主键自增</h4>\n<p>①以最常见的用户 ID 为例，可以按照 1000000 的范围大小进行分段，1 ~ 999999 放到表 1中，1000000 ~ 1999999 放到表2中，以此类推。</p>\n<p>②按照分段大小的选取。分段太小会导致切分后子表数量过多，增加维护复杂度；分段太大可能会导致单表依然存在性能问题，一般建议分段大小在 100 万至 2000 万之间，具体需要根据业务选取合适的分段大小。</p>\n<p>③优点：可以随着数据的增加平滑地扩充新的表。例如，现在的用户是 100 万，如果增加到 1000 万，只需要增加新的表就可以了，原有的数据不需要动。</p>\n<p>④缺点：分布不均匀。假如按照 1000 万来进行分表，有可能某个分段实际存储的数据量只有 1 条，而另外一个分段实际存储的数据量有 1000 万条。</p>\n<h4 id=\"2、取模\">2、取模</h4>\n<p>①同样以用户 ID 为例，假如我们一开始就规划了 10 个数据库表，可以简单地用 user_id % 10 的值来表示数据所属的数据库表编号</p>\n<p>②复杂点：初始表数量的确定。表数量太多维护比较麻烦，表数量太少又可能导致单表性能存在问题。</p>\n<p>③优点：表分布比较均匀。</p>\n<p>④缺点：扩充新的表很麻烦，所有数据都要重分布。</p>\n<h4 id=\"3、雪花算法\">3、雪花算法</h4>\n<p>雪花算法是由Twitter公布的分布式主键生成算法，它能够保证<code>不同表的主键的不重复性，以及相同表的主键的有序性</code>。</p>\n<p>①核心思想：由64位比特的二进制数字组成<code>0</code>：符号位   +       <code>1~41</code>：时间戳   +   <code> 42-52</code> ：节点ID   +   <code> 53~64</code>： 序列号，自增的值，单机器每毫秒最多生成 4096 唯一ID</p>\n<p>②优点：整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞，并且效率较高。</p>\n<p>③缺点：需要解决重复 ID 问题，会产生  时钟回拨问题   ： 如果机器的时钟发生了回拨，那么就会有可能生成重复的ID号，需要解决时钟回退的问题。</p>\n<ul>\n<li>解决：使用<a href=\"https://seata.io/zh-cn/blog/seata-analysis-UUID-generator.html\">Seata基于改良版雪花算法的分布式UUID生成器分析</a>；生成器只在初始化时获取了系统当前的时间戳，作为初始时间戳， 但之后就不再与系统时间戳保持同步了。它之后的递增，只由序列号的递增来驱动。调整了64位ID的位分配策略；将<code>   时间戳  和 节点ID 进行了 换序</code></li>\n</ul>\n<h1>ShardingSphere-Proxy(修改配置文件)</h1>\n<h1>ShardingSphere-JDBC(在spring的yml中配置)</h1>\n<p>解决了 : 针对海量数据导致的 单个数据库服务器 难以满足 业务的需要，需要考虑数据库集群的方式提升性能</p>\n<h3 id=\"高性能数据库的集群方式\">高性能数据库的集群方式</h3>\n<h4 id=\"1、读写分离\">1、<code>读写分离</code></h4>\n<p><strong>原理</strong>：将数据库的读写操作分散到不同的节点</p>\n<p><strong>基本实现</strong>：</p>\n<p>​\t1、<code>主库负责处理事务性的增删改操作，从库负责处理查询操作</code>，能够有效的避免由数据更新导致的行锁，使得整个系统的查询性能得到极大的改善。</p>\n<p>​\t2、读写分离是<code>根据 SQL 语义的分析</code>，<code>将读操作和写操作分别路由至主库与从库</code>。</p>\n<ul>\n<li>通过<code>一主多从</code>的配置方式，可以将查询请求均匀的分散到多个数据副本，能够进一步的提升系统的处理能力。</li>\n<li>使用<code>多主多从</code>的方式，不但能够提升系统的吞吐量，还能够提升系统的可用性，可以达到在任何一个数据库宕机，甚至磁盘物理损坏的情况下仍然不影响系统的正常运行。</li>\n</ul>\n<p><strong>问题</strong>： 分散了数据库读写操作的压力，但<code>没有分散存储</code>压力，为了满足业务数据存储的需求，就需要<code>将存储 分散到多台数据库服务器上</code>。</p>\n<h4 id=\"2、数据库分片\">2、<code>数据库分片</code></h4>\n<h5 id=\"数据分片\">数据分片</h5>\n<p>将存放在单一数据库中的数据<code>分散地存放</code>至多个数据库或表中，以达到提升性能瓶颈以及可用性的效果。数据分片的<code>有效手段</code>是对关系型数据库进行<code>分库和分表</code>。数据分片的拆分方式又分为<code>垂直分片和水平分片</code>。</p>\n<h6 id=\"垂直分片\">垂直分片</h6>\n<p>1、<strong>垂直分库</strong>：</p>\n<p>​\t1.1、按照<code>业务拆分</code>的方式称为垂直分片，又称为纵向拆分，它的核心理念是专库专用。拆分前：一个库由多个表构成，每个表对应着多个不同的业务。拆分之后，则是按照业务将表进行归类，分布到不同的数据库中，从而将压力分散至不同的数据库。</p>\n<p>​\t1.2、可以缓解数据量和访问量带来的问题，但无法根治。<code>如果垂直拆分之后，表中的数据量依然超过单节点所能承载的阈值，则需要水平分片来进一步处理。</code></p>\n<p>2、垂直分表</p>\n<p>​\t2.1、表的记录数量不多，但是<code>单条记录</code>的数据多、复杂，<code>占用的空间</code>比较大，此时可以进行垂直分表，将表中某些不常用的列，或者是占了大量空间的列拆分出去</p>\n<p>​\t2.2、垂直分表引入的复杂性主要体现在<code>表操作的数量要增加</code>,比如：原来可能只要一次查询，现在可能就需要多次了</p>\n<h6 id=\"水平分片\">水平分片</h6>\n<p>适用于：  <code>水平分表适合表  </code>行数<code> 特别多的表</code>,水平分片又称为横向拆分,是通过<code>某些字段</code> 或者<code> 某种规则</code>将数据分散至多个库或表中，每个分片仅包含数据的一部分。</p>\n<p>注意： 水平分片需要关注全局序列，因为不能简单的使用基于数据库的主键自增。可以使用 <code>MyBatisPlus的id策略  @TableId(type = IdType.ASSIGN_ID) </code>     或者 <code>ShardingSphere-JDBC的全局序列配置 spring.shardingsphere.rules.sharding.key-generators.alg_snowflake.type=SNOWFLAKE+ @TableId(type = IdType.AUTO)</code></p>\n<p>1、水平分表   就是 将  单表切分为多表后</p>\n<p>2、水平分库   如果单表拆分为多表后，单台服务器依然无法满足性能要求，那就需要将多个表分散在不同的数据库服务器中（类似于 同等级的主从库）</p>\n<blockquote>\n<p>单表行数超过 500万行或者单表容量超过 2GB，才推荐进行分库分表。</p>\n<p>分库分表的目的：解决高并发导致的读写缓慢甚至宕机 以及 数据量大导致的  查询缓慢的问题</p>\n</blockquote>\n<h4 id=\"3、读写分离和数据库分片组合使用\">3、读写分离和数据库分片组合使用</h4>\n<p>​\t1、方式1：代码封装：指在业务层 和 数据库集群之间  抽象一个<code>数据访问层（或中间层封装）</code>，实现  读写操作分离 和 数据库服务器连接的管理</p>\n<p>​\t2、方式2： 中间件：对于业务服务器来说，访问中间件和访问数据库<code>没有区别</code>，在业务服务器看来，中间件就是一个数据库服务器。</p>\n<h3 id=\"数据迁移\">数据迁移</h3>\n<p>​\t1、方式一：停机进行分库分表数据迁移</p>\n<p>​\t2、方式二：不停机进行分库分表数据迁移；一般数据库的拆分也是有一个过程的，一开始是单表，后面慢慢拆成多表。那么我们就看下如何平滑的从MySQL单表过度到MySQL的分库分表架构。</p>\n<p>​\t\t\t2.1、利用mysql+canal做<code>增量数据同步</code>，利用分库分表中间件，将数据路由到对应的新表中。</p>\n<p>​\t\t\t2.2、利用分库分表中间件，<code>全量数据</code>导入到对应的新表中。</p>\n<p>​\t\t\t2.3、通过<code>单表数据和分库分表数据</code>两两比较，<code>更新不匹配</code>的数据到新表中。</p>\n<p>​\t\t\t2.4、数据稳定后，将单表的配置切换到分库分表配置上。</p>\n<img src=\"https://gitee.com/Ryang1118/typora/raw/master/images/202305120102650.png\" alt=\"image-20230512010205576\" style=\"zoom:33%;\">\n<h3 id=\"MySQL主从同步\">MySQL主从同步</h3>\n<p>1、基本原理：从机通过监听并读取<code>binlog</code>日志来进行数据同步</p>\n<p>2、具体步骤：</p>\n<p>​\t<code>step1：</code>master将数据改变记录到<code>二进制日志（binary log）</code>中。</p>\n<p>​\t<code>step2：</code> 当slave上执行 <code>start slave</code> 命令之后，会创建一个 <code>IO 线程</code>用来连接master，请求master中的binlog。</p>\n<p>​\t<code>step3：</code>当slave连接master时，master会创建一个 <code>log dump 线程</code>，用于发送 binlog 的内容。在读取 binlog 的内容的操作中，会对主节点上的 binlog <code>加锁</code>，当读取完成并发送给从服务器后<code>解锁</code>。</p>\n<p>​\t<code>step4：</code> <code>IO 线程</code>接收主节点 binlog dump 进程发来的更新之后，保存到 <code>中继日志（relay log）</code> 中。</p>\n<p>​\t<code>step5：</code>slave的<code>SQL线程</code>，读取relay log日志，并解析成具体操作，从而实现主从操作一致，最终数据一致。</p>\n<h3 id=\"广播表\">广播表</h3>\n<p>1、指所有的分片数据源中都存在的表，表结构及其数据在每个数据库中均完全一致。 适用于<code>数据量不大且需要与海量数据的表进行关联查询</code>的场景，例如：字典表。</p>\n<p>2、广播具有以下特性：</p>\n<p>（1） 插入、更新操作会<code>实时在所有</code>节点上执行，保持各个分片的数据一致性</p>\n<p>（2）查询操作，只从一个节点获取</p>\n<p>（3）可以跟任何一个表进行 JOIN 操作</p>\n<h3 id=\"事务\">事务</h3>\n<p>shardingsphere支持本地事务、两阶段XA事务、seata柔性事务</p>\n<p>使用： 导入依赖：<code>&lt;artifactId&gt;sharding-transaction-spring-boot-starter&lt;/artifactId&gt;</code> +   添加注解<code>@ShardingTransactionType(TransactionType.XA)    @Transactional(rollbackFor = Exception.class)</code></p>\n<h3 id=\"原理\">原理</h3>\n<h5 id=\"Sharding-JDBC数据分片\">Sharding-JDBC数据分片</h5>\n<p>主要流程： SQL解析 <strong>→</strong>执行器优化 <strong>→</strong> SQL路由「根据用户配置的分片策略进行路由」 <strong>→</strong>SQL改写 <strong>→</strong>SQL执行 <strong>→</strong>结果归并</p>\n<p>数据分片的方式：</p>\n<p>​\t1、数据源分片</p>\n<p>​\t2、表分片</p>\n<p>数据分片的策略：分片键 + 分片算法</p>\n<p>​\t1、none：不分片策略，SQL会被发给所有节点去执行</p>\n<p>​\t2、inline：行表达时分片策略，只支持单分片键。对于简单的分片算法，可以通过简单的配置使用,algorithm-expression行表达式</p>\n<p>​\t3、根据实时 时间日期 - 按照标准规则分库分表，StrandardShardingStrategy只支持单分片键。提供PreciseShardingAlgorithm（必选）和RangeShardingAlgorithm两个分片算法。</p>\n<p>​\t4、ShardingSphere - 符合分片策略；对应接口：HintShardingStrategy。通过Hint而非SQL解析的方式分片的策略。</p>\n<p>​\t5、ShardingSphere - hint分片策略；ComplexShardingStrategy支持多分片键，由于多分片键之间的关系复杂，因此并未进行过多的封装，而是直接将分片键组合以及分片操作符透传至分片算法，完全由开发者自己实现，提供最大的灵活度。</p>\n<h3 id=\"场景应用\">场景应用</h3>\n<p>在数据库设计时候考虑垂直分库和垂直分表</p>\n<p>但是随着数据库数据量增加，不要马上考虑做水平切分，<code>首先考虑缓存处理，读写分离，使用索引</code>等方式，如果这些方式不能根本解决问题，再考虑做水平分库和水平分表</p>\n<h5 id=\"如何平滑的为数据库增加字段\">如何平滑的为数据库增加字段</h5>\n<p>​\t1：直接alter table add column,数据量大时不建议，（会产生写锁）</p>\n<p>​\t2：提前预留字段（不优雅：造成空间浪费，预留多少很难控制，拓展性差）</p>\n<p>​\t3：新增一张表，（增加字段），迁移原表数据，在重新命名新表作为原表。</p>\n<p>​\t4：放入extinfo（无法使用索引）</p>\n<p>​\t5:  提前设计，使用key/value方法存储，新增字段时 ，直接加一个key就好了（优雅）</p>\n","_path":"post/8bb3c4e2.html","_link":"http://rycan.top/post/8bb3c4e2.html","_id":"clmhxgjg6002ap70peooz789v"}}